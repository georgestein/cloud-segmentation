{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "24195ab3-3987-4275-8688-f08fc6fc378c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "from pathlib import Path\n",
    "\n",
    "import os\n",
    "os.environ['OPENBLAS_NUM_THREADS'] = '1'\n",
    "\n",
    "# construct_training_set = True\n",
    "construct_training_set = False\n",
    "\n",
    "# use_cloudaugment = True\n",
    "use_cloudaugment = False\n",
    "\n",
    "# create U-Net folder\n",
    "unet_model_dir = Path(\"../cloud_seg/models/unet/\")\n",
    "unet_model_dir.mkdir(parents=True, exist_ok=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "937c2f29-ecdd-4ae5-a145-9ba6ca150ff1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Things to add\n",
    "# https://pytorch-lightning.readthedocs.io/en/latest/common/lightning_cli.html"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "643ef70e-5beb-4911-94fa-05c566784dfb",
   "metadata": {},
   "source": [
    "### Model training script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "827e86eb-b91d-4571-b017-be6902894850",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting ../scripts/train_unet.py\n"
     ]
    }
   ],
   "source": [
    "%%file ../scripts/train_unet.py\n",
    "\n",
    "import shutil\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pandas_path as path\n",
    "from PIL import Image\n",
    "import torch\n",
    "import pytorch_lightning as pl\n",
    "import glob\n",
    "from pathlib import Path\n",
    "import argparse\n",
    "import os\n",
    "import datetime\n",
    "\n",
    "from pytorch_lightning import loggers as pl_loggers\n",
    "import albumentations as A\n",
    "\n",
    "from cloud_seg.models.unet.cloud_model import CloudModel\n",
    "from cloud_seg.utils.augmentations import CloudAugmentations\n",
    "\n",
    "DATA_DIR = Path.cwd().parent.resolve() / \"data/\"\n",
    "DATA_DIR_MODEL_TRAINING = DATA_DIR / \"model_training/\"\n",
    "DATA_DIR_CLOUDLESS = DATA_DIR / 'cloudless/tif/'\n",
    "DATA_DIR_CLOUDS = DATA_DIR / 'clouds/'\n",
    "\n",
    "TRAIN_FEATURES = DATA_DIR / \"train_features\"\n",
    "TRAIN_FEATURES_NEW = DATA_DIR / \"train_features_new\"\n",
    "\n",
    "TRAIN_LABELS = DATA_DIR / \"train_labels\"\n",
    "\n",
    "band_mean_std = np.load(DATA_DIR / 'measured_band_stats.npy', allow_pickle=True).item()\n",
    "\n",
    "def main(args):\n",
    "    \n",
    "    hparams = vars(args)\n",
    "    if hparams['verbose']: print(\"Parameters are: \", hparams)\n",
    "\n",
    "    pl.seed_everything(hparams['seed'], workers=True)\n",
    "    hparams['precision'] = 32\n",
    "\n",
    "    hparams['bands_use'] = sorted(hparams['bands'] + hparams['bands_new']) if hparams['bands_new'] is not None else hparams['bands']\n",
    "    \n",
    "    hparams['band_means'] = [band_mean_std[i]['mean'] for i in hparams['bands_use']]\n",
    "    hparams['band_stds'] = [band_mean_std[i]['std'] for i in hparams['bands_use']]\n",
    "    hparams['max_pixel_value'] = 1.0\n",
    "    if hparams['custom_feature_channels'] == \"true_color\":\n",
    "        hparams['bands_use'] = ['B04', 'B03', 'B02']\n",
    "        hparams['band_means'] = [0.485, 0.456, 0.406] # imagenet for now\n",
    "        hparams['band_stds'] = [0.229, 0.224, 0.225]      \n",
    "        hparams['max_pixel_value'] = 255\n",
    "\n",
    "\n",
    "    hparams['OUTPUT_DIR'] = os.path.join(hparams['OUTPUT_DIR'], hparams['segmentation_model'])\n",
    "    Path(hparams['OUTPUT_DIR']).mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    \n",
    "    # Set up transforms using Albumentations library\n",
    "    Augs = CloudAugmentations(hparams)\n",
    "    train_transforms, train_transforms_names = Augs.add_augmentations()\n",
    "    train_transforms = A.Compose(train_transforms)\n",
    "\n",
    "    augs_val = 'nr' if 'Normalize' in train_transforms_names else ''\n",
    "    val_transforms, val_transforms_names = Augs.add_augmentations(augs_val)\n",
    "    val_transforms = A.Compose(val_transforms)\n",
    "\n",
    "    print(train_transforms_names, val_transforms_names)\n",
    "    print(train_transforms, val_transforms)\n",
    "    \n",
    "    \n",
    "    # set up logger and model outputs to have meaningful name\n",
    "\n",
    "    dataset_str = 'originaldata'\n",
    "    if hparams['cloud_augment']:\n",
    "        dataset_str += '_cloudaugment'\n",
    "    curent_time = datetime.datetime.now().strftime(\"%Y-%m-%d\")#-%H:%M:%S\")\n",
    " \n",
    "    model_out_name = f\"{len(hparams['bands_use'])}band\"\n",
    "    model_out_name += f\"_{dataset_str}\"  \n",
    "    model_out_name += f\"_{hparams['encoder_name']}\"\n",
    "    model_out_name += f\"_{hparams['loss_function']}\"\n",
    "    model_out_name += f\"_{hparams['augmentations']}\"\n",
    "    model_out_name += f\"_customfeats_{hparams['custom_feature_channels']}\"\n",
    "    model_out_name += f\"_{curent_time}\"\n",
    "\n",
    "    hparams['model_training_name'] = model_out_name\n",
    "    if hparams['test_run']:\n",
    "        model_training_name = 'test'\n",
    "    \n",
    "    hparams['LOG_DIR'] = os.path.join(hparams['OUTPUT_DIR'], hparams['model_training_name'], hparams['LOG_DIR'])\n",
    "    hparams['MODEL_DIR'] = os.path.join(hparams['OUTPUT_DIR'], hparams['model_training_name'], hparams['MODEL_DIR'])\n",
    "                                      \n",
    "    Path(hparams['LOG_DIR']).mkdir(parents=True, exist_ok=True)\n",
    "    Path(hparams['MODEL_DIR']).mkdir(parents=True, exist_ok=True)\n",
    "    \n",
    "    # Load Data\n",
    "    val_x = pd.read_csv(DATA_DIR_MODEL_TRAINING / f\"validate_features_meta_cv{hparams['cross_validation_split']}.csv\")\n",
    "    val_y = pd.read_csv(DATA_DIR_MODEL_TRAINING / f\"validate_labels_meta_cv{hparams['cross_validation_split']}.csv\")\n",
    "    \n",
    "    # shuffle validation, such that each batch will have samples from different locations,\n",
    "    # as validation_dataloader has shuffle=False\n",
    "    val_x = val_x.sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "    val_y = val_y.sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "    \n",
    "    if hparams['verbose']: print(val_y.head())\n",
    "    \n",
    "    train_x = pd.read_csv(DATA_DIR_MODEL_TRAINING / f\"train_features_meta_cv{hparams['cross_validation_split']}.csv\")\n",
    "    train_y = pd.read_csv(DATA_DIR_MODEL_TRAINING / f\"train_labels_meta_cv{hparams['cross_validation_split']}.csv\")\n",
    "\n",
    "    if not hparams['cloud_augment']:\n",
    "        \n",
    "        df_cloudbank = None\n",
    "    \n",
    "    if hparams['cloud_augment']:\n",
    "\n",
    "        train_x_cloudless = pd.read_csv(DATA_DIR_MODEL_TRAINING / f\"train_features_cloudless_meta_cv{hparams['cross_validation_split']}.csv\", index=False)\n",
    "        train_y_cloudless = pd.read_csv(DATA_DIR_MODEL_TRAINING / f\"train_labels_cloudless_meta_cv{hparams['cross_validation_split']}.csv\", index=False)\n",
    "\n",
    "        train_y = train_y.append(train_y_cloudless, ignore_index=True)\n",
    "        train_x = train_x.append(train_x_cloudless, ignore_index=True)\n",
    "\n",
    "        df_cloudbank = pd.read_csv(DATA_DIR_MODEL_TRAINING / f\"cloudbank_meta_cv{hparams['cross_validation_split']}.csv\")\n",
    "\n",
    "    if hparams['test_run']:\n",
    "        nuse = hparams['test_run_nchips']\n",
    "\n",
    "        train_x = train_x.iloc[:nuse]\n",
    "        train_y = train_y.iloc[:nuse]\n",
    "\n",
    "        val_x = val_x.iloc[:nuse]\n",
    "        val_x = val_x.iloc[:nuse]\n",
    "\n",
    "        df_cloudbank = df_cloudbank.iloc[:nuse] if df_cloudbank is not None else None\n",
    "        \n",
    "\n",
    "    # Set up models and callbacks\n",
    "    cloud_model = CloudModel(\n",
    "        bands=hparams['bands_use'],\n",
    "        x_train=train_x,\n",
    "        y_train=train_y,\n",
    "        x_val=val_x,\n",
    "        y_val=val_y,\n",
    "        cloudbank=df_cloudbank,\n",
    "        train_transforms=train_transforms,\n",
    "        val_transforms=val_transforms,\n",
    "        hparams=hparams,\n",
    "    )\n",
    "\n",
    "    tb_logger = pl_loggers.TensorBoardLogger(\n",
    "        save_dir=hparams['LOG_DIR'],\n",
    "        name='log',\n",
    "    )\n",
    "\n",
    "    checkpoint_callback = pl.callbacks.ModelCheckpoint(\n",
    "        dirpath=hparams['MODEL_DIR'],\n",
    "        filename='{epoch}-{val_iou_epoch:.4f}',\n",
    "        monitor=\"val_iou_epoch\",\n",
    "        mode=\"max\",\n",
    "        verbose=True,\n",
    "        save_last=True,\n",
    "    )\n",
    "\n",
    "    early_stopping_callback = pl.callbacks.early_stopping.EarlyStopping(\n",
    "        monitor=\"val_iou_epoch\",\n",
    "        patience=(cloud_model.patience * 3),\n",
    "        mode=\"max\",\n",
    "        verbose=True,\n",
    "    )\n",
    "\n",
    "    lr_monitor = pl.callbacks.LearningRateMonitor(\n",
    "        logging_interval='epoch'\n",
    "    )\n",
    "\n",
    "    # Train model\n",
    "    # \"ddp_spawn\" needed for interactive jupyter, but best to use \"ddp\" if not\n",
    "    trainer = pl.Trainer(\n",
    "        gpus=-1,\n",
    "        # deterministic=True,\n",
    "        fast_dev_run=False,\n",
    "        # profiler=\"simple\",\n",
    "        # max_epochs=2,\n",
    "        # overfit_batches=1,\n",
    "        # auto_scale_batch_size=True,\n",
    "        check_val_every_n_epoch=1,\n",
    "        num_sanity_val_steps=2,\n",
    "        precision=hparams['precision'],\n",
    "        strategy=hparams['strategy'],\n",
    "        # plugins=DDPSpawnPlugin(find_unused_parameters=False),\n",
    "        callbacks=[checkpoint_callback, early_stopping_callback, lr_monitor],\n",
    "        logger=tb_logger,\n",
    "    )\n",
    "\n",
    "    # Fit the model\n",
    "    trainer.fit(model=cloud_model)\n",
    "    \n",
    "if __name__=='__main__':\n",
    "    \n",
    "    parser = argparse.ArgumentParser(description='runtime parameters')\n",
    "    \n",
    "    # Data and IO\n",
    "    parser.add_argument(\"--bands\", nargs='+' , default=[\"B02\", \"B03\", \"B04\", \"B08\"],\n",
    "                        help=\"bands desired\")\n",
    "    \n",
    "    parser.add_argument(\"--bands_new\", nargs='+', default=None,\n",
    "                        help=\"additional bands to use beyond original four\")\n",
    "    \n",
    "    parser.add_argument(\"-cv\", \"--cross_validation_split\", type=int, default=0,\n",
    "                        help=\"cross validation split to use for training\") \n",
    "\n",
    "    parser.add_argument(\"--OUTPUT_DIR\", type=str, default='../trained_models/',\n",
    "                        help=\"Directory to save logs and trained models model\")\n",
    "                                      \n",
    "    parser.add_argument(\"--LOG_DIR\", type=str, default='logs/',\n",
    "                        help=\"Sub-directory of OUTPUT_DIR to save logs\")\n",
    "    \n",
    "    parser.add_argument(\"--MODEL_DIR\", type=str, default='model/',\n",
    "                        help=\"Sub-directory of OUTPUT_DIR to save logs\")\n",
    "\n",
    "    parser.add_argument(\"--seed\", type=int , default=13579,\n",
    "                        help=\"random seed for train test split\")\n",
    "   \n",
    "    parser.add_argument(\"-v\", \"--verbose\", action=\"store_true\",\n",
    "                        help=\"increase output verbosity\")\n",
    "   \n",
    "\n",
    "    # Training (gpus, optimization, etc...)\n",
    "    parser.add_argument(\"--gpu\", action=\"store_true\",\n",
    "                        help=\"Use GPU\")\n",
    "    \n",
    "    parser.add_argument(\"--strategy\", type=str, default='ddp',\n",
    "                        help=\"Distributed training strategy\")\n",
    "        \n",
    "    parser.add_argument(\"--test_run\", action=\"store_true\",\n",
    "                        help=\"Subsample training and validation data\")\n",
    "    \n",
    "    parser.add_argument(\"--test_run_nchips\", type=int, default=512,\n",
    "                        help=\"Subsample training and validation data to this size\")\n",
    "\n",
    "    parser.add_argument(\"--num_workers\", type=int, default=3,\n",
    "                        help=\"number of data loader workers\")\n",
    "    \n",
    "    parser.add_argument(\"--persistent_workers\", action=\"store_false\",\n",
    "                        help=\"Persistent data loader workers\")\n",
    "    \n",
    "    parser.add_argument(\"--batch_size\", type=int, default=8,\n",
    "                        help=\"Batch size for model training\")\n",
    "    \n",
    "    parser.add_argument(\"--loss_function\", type=str, default='bce',\n",
    "                        help=\"loss_function to use\", choices=['bce', 'dice', 'jaccard'])\n",
    "      \n",
    "    parser.add_argument(\"--learning_rate\", type=float, default=1e-3,\n",
    "                        help=\"Learning rate for model optimization\")\n",
    "  \n",
    "    parser.add_argument(\"--optimizer\", type=str, default='ADAM',\n",
    "                        help=\"Optimizer to use\", choices=['ADAM', 'SGD', 'ADAMW'])\n",
    "    \n",
    "    parser.add_argument(\"--scheduler\", type=str, default='plateau',\n",
    "                        help=\"Learning rate scheduler to use\", choices=['plateau', 'exponential', 'cosine'])\n",
    "    \n",
    "    parser.add_argument(\"--plot_validation_images\", action=\"store_false\",\n",
    "                        help=\"Plot final batch to tensorboard\")\n",
    "                      \n",
    "    # Models and Augmentations\n",
    "    parser.add_argument(\"--segmentation_model\", type=str, default='unet',\n",
    "                        help=\"Encocoder architecture to use\", choices=['unet', 'DeepLabV3Plus'])\n",
    "  \n",
    "    parser.add_argument(\"--encoder_name\", type=str, default='resnet18',\n",
    "                        help=\"Encocoder architecture to use\", choices=['efficientnet-b0','efficientnet-b3','efficientnet-b5',\n",
    "                                                                       'resnet18', 'resnet34', 'resnet50',\n",
    "                                                                       'vgg19_bn',\n",
    "                                                                      'tu-efficientnetv2_m'])\n",
    "  \n",
    "    parser.add_argument(\"--augmentations\", type=str, default='vfrc',\n",
    "                        help=\"training augmentations to use\")\n",
    "    \n",
    "    parser.add_argument(\"--cloud_augment\", action=\"store_true\",\n",
    "                        help=\"Use cloud augmentation\")\n",
    "    \n",
    "    parser.add_argument(\"--custom_feature_channels\", type=str, default=None,\n",
    "                        help=\"Use cloud augmentation\", choices=['true_color', 'log_bands', 'ratios'])\n",
    "\n",
    "    \n",
    "    args = parser.parse_args()\n",
    "    \n",
    "    main(args)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2b5f1c8-e3ee-40a5-9d7d-5530fe9cba67",
   "metadata": {},
   "source": [
    "# Model predict script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1747b6a7-b25f-4e62-ab21-d936c56eb4b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting ../scripts/predict_unet.py\n"
     ]
    }
   ],
   "source": [
    "%%file ../scripts/predict_unet.py\n",
    "\n",
    "import shutil\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pandas_path as path\n",
    "from PIL import Image\n",
    "import torch\n",
    "import pytorch_lightning as pl\n",
    "import glob\n",
    "from pathlib import Path\n",
    "\n",
    "from typing import List\n",
    "# import typer\n",
    "import logging\n",
    "\n",
    "import os\n",
    "import argparse\n",
    "\n",
    "import albumentations as A\n",
    "\n",
    "from cloud_seg.models.unet.cloud_model import CloudModel\n",
    "from cloud_seg.models.unet.cloud_model import CloudDataset\n",
    "from cloud_seg.utils.augmentations import CloudAugmentations\n",
    "\n",
    "\n",
    "parser = argparse.ArgumentParser(description='runtime parameters')\n",
    "parser.add_argument(\"--bands\", nargs='+' , default=[\"B02\", \"B03\", \"B04\", \"B08\"],\n",
    "                    help=\"bands desired\")\n",
    "parser.add_argument(\"--bands_new\", nargs='+', default=None,\n",
    "                    help=\"additional bands to use beyond original four\")\n",
    "\n",
    "parser.add_argument(\"-cv\", \"--cross_validation_split\", type=int, default=0,\n",
    "                    help=\"cross validation split to use for training\") \n",
    "\n",
    "parser.add_argument(\"--batch_size\", type=int, default=8,\n",
    "                    help=\"Batch size for model inference\")\n",
    "\n",
    "parser.add_argument(\"--INPUT_DIR\", type=str, default='../trained_models/unet/4band_originaldata_efficientnet-b0_dice__Normalize_VerticalFlip_HorizontalFlip_RandomRotate90/',\n",
    "                    help=\"Directory to save logs and trained models model\")\n",
    "\n",
    "parser.add_argument(\"--LOG_DIR\", type=str, default='logs/',\n",
    "                    help=\"Sub-directory of OUTPUT_DIR to save logs\")\n",
    "\n",
    "parser.add_argument(\"--MODEL_DIR\", type=str, default='model/',\n",
    "                    help=\"Sub-directory of OUTPUT_DIR to save logs\")\n",
    "\n",
    "parser.add_argument(\"--OUTPUT_DIR\", type=str, default='predictions/',\n",
    "                    help=\"Directory to save logs and trained models model\")\n",
    "\n",
    "parser.add_argument(\"--gpu\", action=\"store_true\",\n",
    "                    help=\"Use GPU\")  \n",
    "                    \n",
    "parser.add_argument(\"-v\", \"--verbose\", action=\"store_true\",\n",
    "                    help=\"increase output verbosity\")\n",
    "                    \n",
    "parser.add_argument(\"--local_run\", action=\"store_true\",\n",
    "                    help=\"Whether running locally or on planetary computer\")\n",
    "                    \n",
    "parser.add_argument(\"--model_name\", type=str, default='cloud_model.pt',\n",
    "                    help=\"directory to save trained model\")\n",
    "\n",
    "parser.add_argument(\"--segmentation_model\", type=str, default='unet',\n",
    "                    help=\"Encocoder architecture to use\", choices=['unet', 'DeepLabV3Plus'])\n",
    "  \n",
    "parser.add_argument(\"--encoder_name\", type=str, default='resnet18',\n",
    "                    help=\"Architecture to use\", choices=['efficientnet-b0', 'efficientnet-b5', 'resnet18', 'resnet34'])\n",
    "\n",
    "parser.add_argument(\"--load_checkpoint\", action=\"store_true\",\n",
    "                    help=\"Whether loading weights from checkpoint (.ckpt) or just from saved weights state_dict (.pt)\")\n",
    "\n",
    "parser.add_argument(\"--augmentations\", type=str, default='',\n",
    "                        help=\"training augmentations to use\")\n",
    "    \n",
    "hparams = vars(parser.parse_args())\n",
    "hparams['weights'] = None\n",
    "hparams['bands_use'] = sorted(hparams['bands'] + hparams['bands_new']) if hparams['bands_new'] is not None else hparams['bands']\n",
    "         \n",
    "# hparams['INPUT_DIR'] = os.path.join(hparams['INPUT_DIR'], hparams['segmentation_model'], hparams['model_training_name'])\n",
    "# hparams['MODEL_DIR'] = os.path.join(hparams['INPUT_DIR'], hparams['model_training_name'], hparams['MODEL_DIR'])\n",
    "# hparams['LOG_DIR'] = os.path.join(hparams['INPUT_DIR'], hparams['model_training_name'], hparams['OUTPUT_DIR'], hparams['LOG_DIR'])\n",
    "# hparams['OUTPUT_DIR'] = os.path.join(hparams['INPUT_DIR'], hparams['model_training_name'], hparams['OUTPUT_DIR'])\n",
    "\n",
    "# Path(hparams['LOG_DIR']).mkdir(parents=True, exist_ok=True)\n",
    "# Path(hparams['OUTPUT_DIR']).mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "if hparams['local_run']:      \n",
    "    \n",
    "    ROOT_DIR = Path.cwd().parent.resolve()\n",
    "    ASSETS_DIR = Path(hparams['INPUT_DIR'])\n",
    "    MODEL_PATH = ASSETS_DIR / hparams['MODEL_DIR'] / \"last.ckpt\"\n",
    "                    \n",
    "    PREDICTIONS_DIR = ASSETS_DIR / hparams['OUTPUT_DIR']\n",
    "     \n",
    "    DATA_DIR = ROOT_DIR / \"data/\"\n",
    "    DATA_DIR_MODEL_TRAINING = DATA_DIR / \"model_training/\"\n",
    "    DATA_DIR_CLOUDLESS = DATA_DIR / 'cloudless/tif/'\n",
    "    DATA_DIR_CLOUDS = DATA_DIR / 'clouds/'\n",
    "\n",
    "    INPUT_IMAGES_DIR = DATA_DIR / \"train_features\"\n",
    "    INPUT_IMAGES_DIR_NEW = DATA_DIR / \"train_features_new\"\n",
    "\n",
    "    TRAIN_LABELS = DATA_DIR / \"train_labels\"\n",
    "\n",
    "    band_mean_std = np.load(DATA_DIR / 'measured_band_stats.npy', allow_pickle=True).item()\n",
    "       \n",
    "    logger = logging.getLogger(\"test_logger\")\n",
    "    fh = logging.FileHandler('test_logger.log')\n",
    "    ch = logging.StreamHandler()\n",
    "    \n",
    "    logger.addHandler(fh)\n",
    "    logger.addHandler(ch)\n",
    "\n",
    "    Path(PREDICTIONS_DIR).mkdir(parents=True, exist_ok=True)\n",
    "  \n",
    "else:\n",
    "    ROOT_DIR = Path(\"/codeexecution\")\n",
    "    PREDICTIONS_DIR = ROOT_DIR / \"predictions\"\n",
    "    ASSETS_DIR = ROOT_DIR / \"assets\"\n",
    "                    \n",
    "    DATA_DIR = ROOT_DIR / \"data\"\n",
    "    INPUT_IMAGES_DIR = DATA_DIR / \"test_features\"\n",
    "                    \n",
    "    # Set the pytorch cache directory and include cached models in your submission.zip\n",
    "    os.environ[\"TORCH_HOME\"] = str(ASSETS_DIRECTORY / \"assets/torch\")\n",
    "\n",
    "    MODEL_PATH = ASSETS_DIR / hparams['model_name']            \n",
    "\n",
    "logger = logging.getLogger()\n",
    "\n",
    "def get_metadata(features_dir: os.PathLike, bands: List[str]):\n",
    "    \"\"\"\n",
    "    Given a folder of feature data, return a dataframe where the index is the chip id\n",
    "    and there is a column for the path to each band's TIF image.\n",
    "\n",
    "    Args:\n",
    "        features_dir (os.PathLike): path to the directory of feature data, which should have\n",
    "            a folder for each chip\n",
    "        bands (list[str]): list of bands provided for each chip\n",
    "    \"\"\"\n",
    "    chip_metadata = pd.DataFrame(index=[f\"{band}_path\" for band in bands])\n",
    "    chip_ids = (\n",
    "        pth.name for pth in features_dir.iterdir() if not pth.name.startswith(\".\")\n",
    "    )\n",
    "\n",
    "    for chip_id in sorted(chip_ids):\n",
    "        chip_bands = [features_dir / chip_id / f\"{band}.tif\" for band in bands]\n",
    "        chip_metadata[chip_id] = chip_bands\n",
    "\n",
    "    return chip_metadata.transpose().reset_index().rename(columns={\"index\": \"chip_id\"})\n",
    "\n",
    "\n",
    "def make_predictions(\n",
    "    model: CloudModel,\n",
    "    x_paths: pd.DataFrame,\n",
    "    bands: List[str],\n",
    "    predictions_dir: os.PathLike,\n",
    "):\n",
    "    \"\"\"Predicts cloud cover and saves results to the predictions directory.\n",
    "\n",
    "    Args:\n",
    "        model (CloudModel): an instantiated CloudModel based on pl.LightningModule\n",
    "        x_paths (pd.DataFrame): a dataframe with a row for each chip. There must be a column for chip_id,\n",
    "                and a column with the path to the TIF for each of bands provided\n",
    "        bands (list[str]): list of bands provided for each chip\n",
    "        predictions_dir (os.PathLike): Destination directory to save the predicted TIF masks\n",
    "    \"\"\"\n",
    "    # Set up transforms using Albumentations library\n",
    "    Augs = CloudAugmentations(hparams)\n",
    "    predict_transforms, _transforms_names = Augs.add_augmentations()\n",
    "    predict_transforms = A.Compose(predict_transforms)\n",
    "\n",
    "    predict_dataset = CloudDataset(\n",
    "        x_paths=x_paths,\n",
    "        bands=bands,\n",
    "        transforms=predict_transforms,\n",
    "    )\n",
    "    \n",
    "    predict_dataloader = torch.utils.data.DataLoader(\n",
    "        predict_dataset,\n",
    "        batch_size=model.batch_size,\n",
    "        num_workers=model.num_workers,\n",
    "        shuffle=False,\n",
    "        drop_last=False,\n",
    "        pin_memory=True,\n",
    "    )\n",
    "    \n",
    "    for batch_index, batch in enumerate(predict_dataloader):\n",
    "        print(\"Running on batch: \", batch_index)\n",
    "        logger.debug(f\"Predicting batch {batch_index} of {len(predict_dataloader)}\")\n",
    "       \n",
    "        x = batch[\"chip\"]\n",
    "        if model.gpu:\n",
    "            x = x.cuda(non_blocking=True)\n",
    "        \n",
    "        preds = model.forward(x)\n",
    "        preds = torch.sigmoid(preds)\n",
    "        \n",
    "        if not hparams['local_run']:\n",
    "            preds = (preds > 0.5) * 1\n",
    "            \n",
    "        preds = preds.detach()\n",
    "        \n",
    "        if model.gpu:\n",
    "            preds = preds.to(\"cpu\").numpy()\n",
    "            \n",
    "        if not hparams['local_run']:\n",
    "            preds = preds.astype(\"uint8\")\n",
    "\n",
    "        for chip_id, pred in zip(batch[\"chip_id\"], preds):\n",
    "            chip_pred_path = predictions_dir / f\"{chip_id}.tif\"\n",
    "            chip_pred_im = Image.fromarray(pred)\n",
    "            chip_pred_im.save(chip_pred_path)\n",
    "\n",
    "\n",
    "def main(\n",
    "    bands: List[str] = [\"B02\", \"B03\", \"B04\", \"B08\"],\n",
    "    fast_dev_run: bool = False,\n",
    "):\n",
    "    \"\"\"\n",
    "    Generate predictions for the chips in features_dir using the model saved at\n",
    "    model_path.\n",
    "\n",
    "    Predictions are saved in predictions_dir. The default paths to all three files are based on\n",
    "    the structure of the code execution runtime.\n",
    "\n",
    "    Args:\n",
    "        model_weights_path (os.PathLike): Path to the weights of a trained CloudModel.\n",
    "        features_dir (os.PathLike, optional): Path to the features for the data. Defaults\n",
    "            to 'data/test_features' in the same directory as main.py\n",
    "        predictions_dir (os.PathLike, optional): Destination directory to save the predicted TIF masks\n",
    "            Defaults to 'predictions' in the same directory as main.py\n",
    "        bands (List[str], optional): List of bands provided for each chip\n",
    "    \"\"\"\n",
    "    if not INPUT_IMAGES_DIR.exists():\n",
    "        raise ValueError(\n",
    "            f\"The directory for feature images must exist and {INPUT_IMAGES_DIR} does not exist\"\n",
    "        )\n",
    "    PREDICTIONS_DIR.mkdir(exist_ok=True, parents=True)\n",
    "\n",
    "    print('RUNNING')\n",
    "    logger.info(\"Loading model\")\n",
    "    print('RUNNING')\n",
    "    \n",
    "    # Load with gpu=False, then put on GPU\n",
    "    hparams['gpu'] = False\n",
    "    model = CloudModel(\n",
    "        bands=hparams['bands_use'],\n",
    "        hparams=hparams\n",
    "    )\n",
    "   \n",
    "    print('Constructed base model')\n",
    "    # load model from disk\n",
    "    if not hparams['load_checkpoint']:\n",
    "        # directly load weights\n",
    "        model.load_state_dict(torch.load(MODEL_PATH))\n",
    "        \n",
    "    if hparams['load_checkpoint']:\n",
    "        # load weights from checkpoint\n",
    "        checkpoint = torch.load(MODEL_PATH)\n",
    "        model.load_state_dict(checkpoint['state_dict'])\n",
    "    print('Loaded model weights')\n",
    "    \n",
    "    hparams['gpu'] = True\n",
    "    if hparams['gpu']:\n",
    "        model = model.cuda()\n",
    "        model.gpu = True\n",
    "\n",
    "             \n",
    "    # Load metadata\n",
    "    logger.info(\"Loading metadata\")\n",
    "    metadata = get_metadata(INPUT_IMAGES_DIR, bands=bands)\n",
    "    if fast_dev_run:\n",
    "        metadata = metadata.head()\n",
    "    logger.info(f\"Found {len(metadata)} chips\")\n",
    "    \n",
    "    \n",
    "    print('Loaded metadata')\n",
    "    # Make predictions and save to disk\n",
    "    logger.info(\"Generating predictions in batches\")\n",
    "    make_predictions(model, metadata, bands, PREDICTIONS_DIR)\n",
    "\n",
    "    logger.info(f\"\"\"Saved {len(list(PREDICTIONS_DIR.glob(\"*.tif\")))} predictions\"\"\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # if hparams['local_run']:              \n",
    "    #     main()\n",
    "    # else:\n",
    "        #typer.run(main)\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "51b867f4-7c47-4574-ae10-b09864c90319",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '../../trained_models/unet/test/epoch=21-val_iou_epoch=0.84.ckpt'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_167082/3729074797.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mMODEL_PATH\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'../../trained_models/unet/test/epoch=21-val_iou_epoch=0.84.ckpt'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mcheckpoint\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mMODEL_PATH\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmap_location\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'cpu'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcheckpoint\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/torch/serialization.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(f, map_location, pickle_module, **pickle_load_args)\u001b[0m\n\u001b[1;32m    592\u001b[0m         \u001b[0mpickle_load_args\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'encoding'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'utf-8'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    593\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 594\u001b[0;31m     \u001b[0;32mwith\u001b[0m \u001b[0m_open_file_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'rb'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mopened_file\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    595\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0m_is_zipfile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopened_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    596\u001b[0m             \u001b[0;31m# The zipfile reader is going to advance the current file position.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/torch/serialization.py\u001b[0m in \u001b[0;36m_open_file_like\u001b[0;34m(name_or_buffer, mode)\u001b[0m\n\u001b[1;32m    228\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_open_file_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    229\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0m_is_path\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname_or_buffer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 230\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_open_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    231\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    232\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;34m'w'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/torch/serialization.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, name, mode)\u001b[0m\n\u001b[1;32m    209\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0m_open_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_opener\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    210\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 211\u001b[0;31m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_open_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    212\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    213\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__exit__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '../../trained_models/unet/test/epoch=21-val_iou_epoch=0.84.ckpt'"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "MODEL_PATH = '../../trained_models/unet/test/epoch=21-val_iou_epoch=0.84.ckpt'\n",
    "checkpoint = torch.load(MODEL_PATH, map_location=torch.device('cpu'))\n",
    "for k, v in checkpoint.items():\n",
    "    print(k)\n",
    "# model.load_state_dict(checkpoint['model'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "27f52214-c423-4af7-87ba-a061e59158a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting ../cloud_seg/models/unet/cloud_dataset.py\n"
     ]
    }
   ],
   "source": [
    "%%file {unet_model_dir}/cloud_dataset.py\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import rasterio\n",
    "import torch\n",
    "from typing import Optional, List\n",
    "import torchvision\n",
    "\n",
    "import cloud_seg.utils.band_normalizations as band_normalizations\n",
    "\n",
    "class CloudDataset(torch.utils.data.Dataset):\n",
    "    \"\"\"Reads in images, transforms pixel values, and serves a\n",
    "    dictionary containing chip ids, image tensors, and\n",
    "    label masks (where available).\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        x_paths: pd.DataFrame,\n",
    "        bands: List[str],\n",
    "        y_paths: Optional[pd.DataFrame] = None,\n",
    "        cloudbank: Optional[pd.DataFrame] = None,\n",
    "        transforms: Optional[list] = None,\n",
    "        custom_feature_channels: str = None,\n",
    "    ):\n",
    "        \"\"\"\n",
    "        Instantiate the CloudDataset class.\n",
    "\n",
    "        Args:\n",
    "            x_paths (pd.DataFrame): a dataframe with a row for each chip. There must be a column for chip_id,\n",
    "                and a column with the path to the TIF for each of bands\n",
    "            bands (list[str]): list of the bands included in the data\n",
    "            y_paths (pd.DataFrame, optional): a dataframe with a row for each chip and columns for chip_id\n",
    "                and the path to the label TIF with ground truth cloud cover\n",
    "            cloudbank (pd.DataFrame, optional): a dataframe with a row for each cloud chip, columns for chip_id\n",
    "                and the path to the cloud band TIFs and label TIF with ground truth cloud cover.\n",
    "            transforms (list, optional): list of transforms to apply to the feature data (eg augmentations)\n",
    "            \n",
    "            custom_feature_channels (str, optional): use difference of channels, ratios, etc, rather than just bands\n",
    "        \"\"\"\n",
    "        self.data  = x_paths\n",
    "        self.label = y_paths\n",
    "        self.cloudbank = cloudbank\n",
    "        if cloudbank is not None:\n",
    "            self.len_cloudbank = len(cloudbank)\n",
    "        \n",
    "        self.transforms = transforms\n",
    "        self.custom_feature_channels = custom_feature_channels\n",
    "        \n",
    "        if custom_feature_channels == 'true_color':\n",
    "            # overwrite input bands to use true color bands\n",
    "            self.bands = ['B04', 'B03', 'B02']\n",
    "        else:\n",
    "            self.bands = bands\n",
    "       \n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx: int):\n",
    "        # Loads an n-channel image from a chip-level dataframe\n",
    "        img = self.data.loc[idx]\n",
    "        band_arrs = []\n",
    "        for band in self.bands:\n",
    "            with rasterio.open(img[f\"{band}_path\"]) as b:\n",
    "                band_arr = b.read(1).astype(\"float32\")\n",
    "            band_arrs.append(band_arr)\n",
    "            \n",
    "        x_arr = np.stack(band_arrs, axis=-1) # images in (B, H, W, C)\n",
    "\n",
    "        # Load label if available\n",
    "        if self.label is not None:\n",
    "            label_path = self.label.loc[idx].label_path\n",
    "            if label_path != 'None':\n",
    "                with rasterio.open(label_path) as lp:\n",
    "                    y_arr = lp.read(1).astype(\"float32\")\n",
    "            else:\n",
    "                # This is a cloudless image, so sample a random cloud chip from cloudbank\n",
    "                # load in new cloud label, and add cloud band data to x_arr bands\n",
    "                idx_cloud = np.random.randint(0, self.len_cloudbank)\n",
    "                cloud_paths = self.cloudbank.loc[idx_cloud]\n",
    "                \n",
    "                # load label\n",
    "                with rasterio.open(cloud_paths.label_path) as lp:\n",
    "                    y_arr = lp.read(1).astype(\"float32\")  \n",
    "                    \n",
    "                # load cloud bands\n",
    "                band_arrs = []\n",
    "                for band in self.bands:\n",
    "                    with rasterio.open(cloud_paths[f\"{band}_path\"]) as b:\n",
    "                        band_arr = b.read(1).astype(\"float32\")\n",
    "                    band_arrs.append(band_arr)\n",
    "                    \n",
    "                # add clouds to cloudless image\n",
    "                x_arr += np.stack(band_arrs, axis=-1)\n",
    "\n",
    "        if self.custom_feature_channels is not None:\n",
    "            # modify x_arr (N,H,W,C) from band data to custom designed features\n",
    "            if self.custom_feature_channels == 'true_color':\n",
    "                for iband in range(len(self.bands)):\n",
    "                    x_arr[..., iband] = band_normalizations.true_color_band(x_arr[..., iband])\n",
    "                                \n",
    "            if self.custom_feature_channels == 'log_bands':\n",
    "                # for ichan in range(x_arr.shape[-1]):\n",
    "                #     x_arr[..., ichan] = np.log(x_arr\n",
    "                x_arr = np.clip(x_arr, 1., np.inf)\n",
    "                x_arr = np.log(x_arr)\n",
    "                \n",
    "            if self.custom_feature_channels == 'ratios':\n",
    "                # Intensity, B03-B08, B02-B04, B08-B04,\n",
    "                x_arr = np.clip(x_arr, 1., np.inf)\n",
    "\n",
    "                B02 = x_arr[..., 0].copy()\n",
    "                B04 = x_arr[..., 2].copy()\n",
    "\n",
    "                x_arr[..., 0] = np.mean(x_arr, axis=-1)/2000.\n",
    "                x_arr[..., 1] = (x_arr[..., 1] - x_arr[..., -1])/(x_arr[..., 1] + x_arr[..., -1])\n",
    "                x_arr[..., 2] = (B02 - x_arr[..., 2])/(B02 + x_arr[..., 2])\n",
    "                x_arr[..., 3] = (x_arr[..., -1] - B04)/(x_arr[..., -1] + B04)\n",
    "                \n",
    "        # Prepare dictionary for item\n",
    "        item = {}\n",
    "        item[\"chip_id\"] = img.chip_id\n",
    "        \n",
    "        # Apply data augmentations, if provided\n",
    "        if self.label is not None:\n",
    "            # Apply same data augmentations to the label\n",
    "            if self.transforms:\n",
    "                transformed = self.transforms(image=x_arr, mask=y_arr)\n",
    "                x_arr = transformed[\"image\"]\n",
    "                y_arr = transformed[\"mask\"]\n",
    "                \n",
    "            item[\"label\"] = y_arr\n",
    "            \n",
    "        if self.label is None:\n",
    "            if self.transforms:\n",
    "                x_arr = self.transforms(image=x_arr)[\"image\"]\n",
    "                \n",
    "        x_arr = np.transpose(x_arr, [2, 0, 1]) # put images in (B, C, H, W)\n",
    "\n",
    "        item[\"chip\"] = x_arr\n",
    "        \n",
    "        return item"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "919ac2db-5a78-46be-a4a9-3106e694adeb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting ../cloud_seg/models/unet/losses.py\n"
     ]
    }
   ],
   "source": [
    "%%file {unet_model_dir}/losses.py\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "from typing import Sequence, Optional, Union\n",
    "\n",
    "def intersection_and_union(pred, true):\n",
    "    \"\"\"\n",
    "    Calculates intersection and union for a batch of images.\n",
    "\n",
    "    Args:\n",
    "        pred (torch.Tensor): a tensor of predictions\n",
    "        true (torc.Tensor): a tensor of labels\n",
    "\n",
    "    Returns:\n",
    "        intersection (int): total intersection of pixels\n",
    "        union (int): total union of pixels\n",
    "    \"\"\"\n",
    "    # valid_pixel_mask = true.ne(255)  # valid pixel mask\n",
    "    # true = true.masked_select(valid_pixel_mask).to(\"cpu\")\n",
    "    # pred = pred.masked_select(valid_pixel_mask).to(\"cpu\")\n",
    "\n",
    "    # Intersection and union totals\n",
    "    pred_flattened = pred.view(-1)\n",
    "    true_flattened = true.view(-1)\n",
    "\n",
    "    intersection = torch.logical_and(true_flattened, pred_flattened)\n",
    "    union = torch.logical_or(true_flattened, pred_flattened)\n",
    "    \n",
    "    return torch.sum(intersection).float(), torch.sum(union).float()#, torch.sum(intersection) / torch.sum(union)\n",
    "\n",
    "def dice_loss(pred, true, smooth=1e-6):\n",
    "    \"\"\"\n",
    "    pred: prediction logits - so map to probability with sigmoid\n",
    "    true: true label\n",
    "    \"\"\"\n",
    "    pred_flattened = pred.view(-1)\n",
    "    true_flattened = true.view(-1)\n",
    "\n",
    "    intersection = (pred_flattened * true_flattened).sum()\n",
    "    \n",
    "    return 1 - ((2. * intersection + dice_smooth) /\n",
    "              (pred_flattened.sum() + true_flattened.sum() + dice_smooth))\n",
    "\n",
    "def power_jaccard(pred, true, power_val=1.75, smooth=1.):\n",
    "    \"\"\"\n",
    "    pred: prediction logits - so map to probability with sigmoid\n",
    "    true: true label\n",
    "    \"\"\"\n",
    "    pred_flattened = pred.view(-1)\n",
    "    true_flattened = true.view(-1)\n",
    "\n",
    "    intersection = (pred_flattened * true_flattened).sum()\n",
    "                                   \n",
    "    total = (pred_flattened**power_val + true_flattened**power_val).sum()                            \n",
    "        \n",
    "    jacc = (intersection + smooth)/(total - intersection + smooth)\n",
    "                \n",
    "    return 1 - jacc\n",
    "\n",
    "class DiceLoss(torch.nn.Module):\n",
    "    def __init__(self, weight=None, size_average=True):\n",
    "        super(DiceLoss, self).__init__()\n",
    "\n",
    "    def forward(self, inputs, targets, smooth=1):\n",
    "                \n",
    "        #flatten label and prediction tensors\n",
    "        inputs = inputs.view(-1)\n",
    "        targets = targets.view(-1)\n",
    "        \n",
    "        intersection = (inputs * targets).sum()                            \n",
    "        dice = (2.*intersection + smooth)/(inputs.sum() + targets.sum() + smooth)  \n",
    "        \n",
    "        return 1 - dice\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7cfeb53a-c77b-495d-b996-9be1b42bd1e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting ../cloud_seg/models/unet/metrics.py\n"
     ]
    }
   ],
   "source": [
    "%%file {unet_model_dir}/metrics.py\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import torchmetrics\n",
    "\n",
    "class Intersection(torchmetrics.Metric):\n",
    "    def __init__(self, dist_sync_on_step=False):\n",
    "        super().__init__(dist_sync_on_step=dist_sync_on_step)\n",
    "\n",
    "        self.add_state(\"intersection\", default=torch.tensor(0), dist_reduce_fx=\"sum\")\n",
    "        self.add_state(\"total\", default=torch.tensor(0), dist_reduce_fx=\"sum\")\n",
    "\n",
    "    def update(self, preds: torch.Tensor, target: torch.Tensor):\n",
    "        preds, target = self._input_format(preds, target)\n",
    "        assert preds.shape == target.shape\n",
    "\n",
    "        self.intersection += torch.logical_and(preds.view(-1), target.view(-1))\n",
    "        # self.correct += torch.sum(preds == target)\n",
    "        # self.total += target.numel()\n",
    "\n",
    "    def compute(self):\n",
    "        return self.intersection.float()\n",
    "        # return self.correct.float() / self.total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "25dae48a-620e-4621-9649-5b8aa40b0443",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting ../cloud_seg/models/unet/callbacks.py\n"
     ]
    }
   ],
   "source": [
    "%%file {unet_model_dir}/callbacks.py\n",
    "\n",
    "# Adapted from https://github.com/PyTorchLightning/Lightning-Bolts/blob/master/pl_bolts/callbacks/vision/confused_logit.py#L20-L167\n",
    "from typing import Sequence\n",
    "\n",
    "import torch\n",
    "from pytorch_lightning import Callback, LightningModule, Trainer\n",
    "from torch import Tensor, nn\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "from matplotlib.axes import Axes\n",
    "from matplotlib.figure import Figure\n",
    "\n",
    "# from pytorch_lightning.utilities import rank_zero_only\n",
    "# @rank_zero_only\n",
    "class DisplayChipsCallback(Callback):  # pragma: no cover\n",
    "    \"\"\"Takes the input chip, true label, and label prediction\n",
    "        trainer = Trainer(callbacks=[DisplayChips()])\n",
    "    .. note:: Whenever called, this model will look for ``self.last_batch`` and ``self.last_logits``\n",
    "              in the LightningModule.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        num_images_plot: int=4,\n",
    "    ):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            top_k: How many  images we should plot\n",
    "   \n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        self.num_images_plot = num_images_plot\n",
    "\n",
    "    def on_validation_epoch_end(\n",
    "        self,\n",
    "        trainer: Trainer,\n",
    "        pl_module: LightningModule,\n",
    "        # outputs: Sequence,\n",
    "        # batch: Sequence,\n",
    "        # batch_idx: int,\n",
    "        # dataloader_idx: int,\n",
    "    ) -> None:\n",
    "        # show images only every 20 batches\n",
    "        # if batch_idx != 0:\n",
    "        #     return\n",
    "\n",
    "        # pick the last batch and logits\n",
    "        # x, y = batch[\"chip\"], batch[\"label\"]\n",
    "        try:\n",
    "            x = pl_module.last_x.to(\"cpu\")\n",
    "            y = pl_module.last_y.to(\"cpu\")\n",
    "            pred = pl_module.last_pred.to(\"cpu\")\n",
    "            \n",
    "        except AttributeError as err:\n",
    "            m = \"\"\"please track the last_pred in the validation_step like so:\n",
    "                def validation_step(...):\n",
    "                    self.last_pred = your_pred\n",
    "            \"\"\"\n",
    "            raise AttributeError(m) from err\n",
    "\n",
    "        print(pred)\n",
    "        self._plot(x, y, pred, trainer, pl_module)\n",
    "\n",
    "    def _plot(\n",
    "        self,\n",
    "        x: Tensor,\n",
    "        y: Tensor,\n",
    "        pred: Tensor,\n",
    "        trainer: Trainer,\n",
    "        model: LightningModule,\n",
    "    ) -> None:\n",
    "\n",
    "        batch_size, c, w, h = x.size()\n",
    "\n",
    "        # final batch may not be full size\n",
    "        nimg_plt = self.min(batch_size, self.num_images_plot)\n",
    "        \n",
    "        fig, axarr = plt.subplots(nrows=nimg_plt, ncols=3, figsize=(15, 5*))\n",
    "       \n",
    "        for img_i in range(nimg_plt):\n",
    "            xi = x[img_i].to(\"cpu\")\n",
    "            yi = y[img_i].to(\"cpu\")\n",
    "            predi = pred[img_i].to(\"cpu\")\n",
    "            \n",
    "            self.__draw_data_sample(fig, axarr, img_i, 0, xi[0], \"Chip\")\n",
    "            self.__draw_label_sample(fig, axarr, img_i, 1, yi, \"True label\")\n",
    "            self.__draw_label_sample(fig, axarr, img_i, 2, predi, \"Prediction\")\n",
    "            \n",
    "        # model.logger.experiment.add_figure(\"validation_predictions\", fig, global_step=trainer.global_step)\n",
    "        # trainer.logger.experiment[0].add_image(\"validation_predictions\", fig, global_step=trainer.global_step)\n",
    "        # model.log(\"validation_predictions\", fig, global_step=trainer.global_step)\n",
    "\n",
    "    @staticmethod\n",
    "    def __draw_data_sample(fig: Figure, axarr: Axes, row_idx: int, col_idx: int, img: Tensor, title: str) -> None:\n",
    "        im = axarr[row_idx, col_idx].imshow(img)\n",
    "        axarr[row_idx, col_idx].set_title(title, fontsize=20)\n",
    "        \n",
    "    @staticmethod\n",
    "    def __draw_label_sample(fig: Figure, axarr: Axes, row_idx: int, col_idx: int, img: Tensor, title: str) -> None:\n",
    "        im = axarr[row_idx, col_idx].imshow(img, vmin=0., vmax=1.)\n",
    "        axarr[row_idx, col_idx].set_title(title, fontsize=20)\n",
    "        \n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "80fab01d-4d82-436a-b219-41913e5357a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting ../cloud_seg/models/unet/plotting_tools.py\n"
     ]
    }
   ],
   "source": [
    "%%file {unet_model_dir}/plotting_tools.py\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch import Tensor\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "import xarray\n",
    "import xrspatial.multispectral as ms\n",
    "\n",
    "# from pytorch_lightning.utilities import rank_zero_only\n",
    "# @rank_zero_only\n",
    "\n",
    "def to_xarray(im_arr):\n",
    "    \"\"\"Put images in xarray.DataArray format\"\"\"\n",
    "\n",
    "    return xarray.DataArray(im_arr, dims=[\"y\", \"x\"])\n",
    "\n",
    "def true_color_img(img, normalized=True):\n",
    "    \"\"\"Given the path to the directory of Sentinel-2 chip feature images,\n",
    "    plots the true color image\"\"\"\n",
    "    \n",
    "    band_mean_std = {'B02': {'mean': 2848.064112016446,\n",
    "    'std': 3156.9268464765087,\n",
    "    'min': 0,\n",
    "    'max': 27600},\n",
    "    'B03': {'mean': 2839.0871485290295,\n",
    "    'std': 2899.280144509762,\n",
    "    'min': 0,\n",
    "    'max': 26096},\n",
    "    'B04': {'mean': 2741.2891076425326,\n",
    "    'std': 2789.961608891907,\n",
    "    'min': 0,\n",
    "    'max': 23104},\n",
    "    'B08': {'mean': 3657.9092112857143,\n",
    "    'std': 2424.18942846055,\n",
    "    'min': 0,\n",
    "    'max': 19568}}\n",
    "\n",
    "    if normalized:\n",
    "        img[2] = img[2]*band_mean_std['B04']['std'] + band_mean_std['B04']['mean']\n",
    "        img[1] = img[1]*band_mean_std['B03']['std'] + band_mean_std['B03']['mean']\n",
    "        img[0] = img[0]*band_mean_std['B02']['std'] + band_mean_std['B02']['mean']\n",
    "        \n",
    "    red = to_xarray(img[2])\n",
    "    green = to_xarray(img[1])\n",
    "    blue = to_xarray(img[0])\n",
    "    \n",
    "    return ms.true_color(r=red, g=green, b=blue)\n",
    "\n",
    "def intersection_over_union(pred, true, smooth=1):\n",
    "    \"\"\"\n",
    "    Calculates intersection over union for an image.\n",
    "\n",
    "    Args:\n",
    "        pred (torch.Tensor): a tensor of predictions\n",
    "        true (torc.Tensor): a tensor of labels\n",
    "\n",
    "    Returns:\n",
    "        intersection (int): total intersection of pixels\n",
    "        union (int): total union of pixels\n",
    "    \"\"\"\n",
    "    # Intersection and union totals\n",
    "    pred_flattened = pred.view(-1)\n",
    "    true_flattened = true.view(-1)\n",
    "\n",
    "    intersection = torch.logical_and(true_flattened, pred_flattened)\n",
    "    union = torch.logical_or(true_flattened, pred_flattened)\n",
    "    \n",
    "    return (torch.sum(intersection).float() + smooth)/ (torch.sum(union).float() + smooth)\n",
    "\n",
    "def plot_prediction_grid(\n",
    "    x: Tensor,\n",
    "    y: Tensor,\n",
    "    pred: Tensor,\n",
    "    chip_id,\n",
    "    custom_feature_channels = None,\n",
    "    num_images_plot: int = 4,\n",
    "    fontsize=18):\n",
    "\n",
    "        batch_size, c, w, h = x.size()\n",
    "        \n",
    "        nimg_plt = min(batch_size, num_images_plot)\n",
    "\n",
    "        fig, axarr = plt.subplots(nrows=nimg_plt, ncols=3, figsize=(15, 5*nimg_plt))\n",
    "       \n",
    "        for img_i in range(nimg_plt):\n",
    "            \n",
    "            chip_idi = chip_id[img_i]\n",
    "            \n",
    "            if custom_feature_channels is None:\n",
    "                xi = true_color_img(x[img_i].to(\"cpu\").numpy().astype(np.float32), normalized=True)\n",
    "                \n",
    "            if custom_feature_channels == \"true_color\":\n",
    "                xi = x[img_i].to(\"cpu\").numpy().astype(np.float32)\n",
    "                xi = np.transpose(xi, [1, 2, 0]).astype(np.uint8)\n",
    "            else:\n",
    "                xi = x[img_i][0].to(\"cpu\").numpy().astype(np.float32)\n",
    "\n",
    "            yi = y[img_i].to(\"cpu\")\n",
    "            predi = pred[img_i].to(\"cpu\")\n",
    "            \n",
    "            IoU = intersection_over_union(yi, predi)\n",
    "            \n",
    "            axarr[img_i, 0].imshow(xi)\n",
    "            axarr[img_i, 0].set_title(f\"{chip_idi}\", fontsize=fontsize)\n",
    "            \n",
    "            axarr[img_i, 1].imshow(yi, vmin=0., vmax=1.)\n",
    "            axarr[img_i, 1].set_title(\"True label\", fontsize=fontsize)\n",
    "            \n",
    "            axarr[img_i, 2].imshow(predi, vmin=0., vmax=1.)\n",
    "            axarr[img_i, 2].set_title(f\"Pred: IoU={IoU:.3f}\", fontsize=fontsize)\n",
    "            \n",
    "        plt.close(fig)\n",
    "        \n",
    "        return fig\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ded66935-219f-435c-af56-0be0315dd518",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting ../cloud_seg/models/unet/cloud_model.py\n"
     ]
    }
   ],
   "source": [
    "%%file {unet_model_dir}/cloud_model.py\n",
    "\n",
    "from typing import Optional, List\n",
    "\n",
    "import pandas as pd\n",
    "import pytorch_lightning as pl\n",
    "import pl_bolts \n",
    "import segmentation_models_pytorch as smp\n",
    "import torch\n",
    "import torchmetrics\n",
    "\n",
    "# from pytorch_lightning.utilities import rank_zero_only\n",
    "# from pytorch_lightning.loggers.base import rank_zero_experiment\n",
    "\n",
    "from .cloud_dataset import CloudDataset\n",
    "from .losses import intersection_and_union\n",
    "from .losses import dice_loss, power_jaccard\n",
    "from .plotting_tools import plot_prediction_grid\n",
    "\n",
    "\n",
    "class CloudModel(pl.LightningModule):\n",
    "    def __init__(\n",
    "        self,\n",
    "        bands: List[str],\n",
    "        x_train: Optional[pd.DataFrame] = None,\n",
    "        y_train: Optional[pd.DataFrame] = None,\n",
    "        x_val: Optional[pd.DataFrame] = None,\n",
    "        y_val: Optional[pd.DataFrame] = None,\n",
    "        cloudbank: Optional[pd.DataFrame] = None,\n",
    "        train_transforms = None,\n",
    "        val_transforms = None,\n",
    "        hparams: dict = {},\n",
    "    ):\n",
    "        \"\"\"\n",
    "        Instantiate the CloudModel class based on the pl.LightningModule\n",
    "        (https://pytorch-lightning.readthedocs.io/en/latest/common/lightning_module.html).\n",
    "\n",
    "        Args:\n",
    "            bands (list[str]): Names of the bands provided for each chip\n",
    "            x_train (pd.DataFrame, optional): a dataframe of the training features with a row for each chip.\n",
    "                There must be a column for chip_id, and a column with the path to the TIF for each of bands.\n",
    "                Required for model training\n",
    "            y_train (pd.DataFrame, optional): a dataframe of the training labels with a for each chip\n",
    "                and columns for chip_id and the path to the label TIF with ground truth cloud cover.\n",
    "                Required for model training\n",
    "            x_val (pd.DataFrame, optional): a dataframe of the validation features with a row for each chip.\n",
    "                There must be a column for chip_id, and a column with the path to the TIF for each of bands.\n",
    "                Required for model training\n",
    "            y_val (pd.DataFrame, optional): a dataframe of the validation labels with a for each chip\n",
    "                and columns for chip_id and the path to the label TIF with ground truth cloud cover.\n",
    "                Required for model training\n",
    "            cloudbank (pd.DataFrame, optional): a dataframe of paths to additional clouds to sample from. \n",
    "                Optional for model training, but required if using chips where label_path=='None'\n",
    "            hparams (dict, optional): Dictionary of additional modeling parameters.\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        self.hparams.update(hparams)\n",
    "        self.save_hyperparameters()\n",
    "\n",
    "        # required\n",
    "        self.bands = bands\n",
    "        self.num_channels = len(bands)\n",
    "        \n",
    "        # optional modeling params\n",
    "        self.segmentation_model = self.hparams.get(\"segmentation_model\", \"unet\")\n",
    "        self.encoder_name = self.hparams.get(\"encoder_name\", \"efficientnet-b0\")\n",
    "        self.weights = self.hparams.get(\"weights\", None)\n",
    "        \n",
    "        self.custom_feature_channels = self.hparams.get(\"custom_feature_channels\", None)\n",
    "                                                        \n",
    "        self.loss_function = self.hparams.get(\"loss_function\", \"BCE\")        \n",
    "        self.optimizer = self.hparams.get(\"optimizer\", \"ADAM\")\n",
    "        self.scheduler = self.hparams.get(\"scheduler\", \"PLATEAU\")\n",
    "        \n",
    "        self.learning_rate = self.hparams.get(\"learning_rate\", 1e-3)\n",
    "        self.momentum = self.hparams.get(\"momentum\", 0.9)\n",
    "        self.T_0 = self.hparams.get(\"T_0\", 10)\n",
    "        self.eta_min = self.hparams.get(\"eta_min\", 1e-5)\n",
    "      \n",
    "        self.reduce_learning_rate_factor = self.hparams.get(\"reduce_learning_rate_factor\", 0.1)\n",
    "\n",
    "        self.patience = self.hparams.get(\"patience\", 10)\n",
    "        self.learning_rate_patience = self.hparams.get(\"learning_rate_patience\", 5)\n",
    "        self.batch_size = self.hparams.get(\"batch_size\", 8)\n",
    "\n",
    "        self.num_workers = self.hparams.get(\"num_workers\", 2)\n",
    "        self.pin_memory = self.hparams.get(\"pin_memory\", True)\n",
    "        self.persistent_workers = self.hparams.get(\"persistent_workers\", False)\n",
    "        \n",
    "        self.gpu = self.hparams.get(\"gpu\", False)\n",
    "        \n",
    "        self.log_on_step = self.hparams.get(\"log_on_step\", False)\n",
    "        self.progress_bar = self.hparams.get(\"progress_bar\", False)\n",
    "        \n",
    "        self.plot_validation_images = self.hparams.get(\"plot_validation_images\", True)\n",
    "        self.num_images_plot = self.hparams.get(\"num_images_plot\", self.batch_size)\n",
    "\n",
    "        self.train_transform = train_transforms\n",
    "        self.val_transform = val_transforms\n",
    "\n",
    "        # Instantiate datasets, model, and trainer params if provided\n",
    "        self.train_dataset = CloudDataset(\n",
    "            x_paths=x_train,\n",
    "            bands=self.bands,\n",
    "            y_paths=y_train,\n",
    "            cloudbank=cloudbank,\n",
    "            transforms=self.train_transform,\n",
    "            custom_feature_channels=self.custom_feature_channels,\n",
    "        )\n",
    "        self.val_dataset = CloudDataset(\n",
    "            x_paths=x_val,\n",
    "            bands=self.bands,\n",
    "            y_paths=y_val,\n",
    "            transforms=self.val_transform,\n",
    "            custom_feature_channels=self.custom_feature_channels,\n",
    "        )\n",
    "        \n",
    "        # define some performance metrics using torchmetrics\n",
    "        # self.train_accuracy = torchmetrics.Accuracy()\n",
    "        # self.val_intersection = mymetrics.Intersection()\n",
    "        self.val_IoU = torchmetrics.IoU(num_classes=2)\n",
    "        self.train_IoU = torchmetrics.IoU(num_classes=2)\n",
    "\n",
    "        self.model = self._prepare_model()\n",
    "\n",
    "    ## Required LightningModule methods ##\n",
    "    def forward(self, image: torch.Tensor):\n",
    "        \"\"\"\n",
    "        Forward pass\n",
    "        output of model is (B, 1, H, W), so remove axis=1\n",
    "        return raw logits in order to use BCEWithLogitsLoss which is more stable than BCE:\n",
    "        https://pytorch.org/docs/stable/generated/torch.nn.BCEWithLogitsLoss.html#torch.nn.BCEWithLogitsLoss\n",
    "        \"\"\"\n",
    "        return self.model(image).view(-1, 512, 512)\n",
    "\n",
    "    def calculate_loss(self, chip, label, preds):\n",
    "        if self.loss_function.upper()==\"BCE\":\n",
    "            loss = torch.nn.BCEWithLogitsLoss(reduction=\"none\")(preds, label.float()).mean()\n",
    "            \n",
    "        if self.loss_function.upper()==\"DICE\":\n",
    "            loss = dice_loss(preds, label)\n",
    "            \n",
    "        if self.loss_function.upper()==\"JACCARD\":\n",
    "            loss = power_jaccard(preds, label, power_val=1.)\n",
    "\n",
    "        return loss\n",
    "\n",
    "    def training_step(self, batch: dict, batch_idx: int):\n",
    "        \"\"\"\n",
    "        Training step.\n",
    "\n",
    "        Args:\n",
    "            batch (dict): dictionary of items from CloudDataset of the form\n",
    "                {'chip_id': list[str], 'chip': list[torch.Tensor], 'label': list[torch.Tensor]}\n",
    "            batch_idx (int): batch number\n",
    "        \"\"\"\n",
    "        if self.train_dataset.data is None:\n",
    "            raise ValueError(\n",
    "                \"x_train and y_train must be specified when CloudModel is instantiated to run training\"\n",
    "            )\n",
    "\n",
    "        # Switch on training mode\n",
    "        self.model.train()\n",
    "        torch.set_grad_enabled(True)\n",
    "\n",
    "        # Load images and labels\n",
    "        x = batch[\"chip\"]\n",
    "        y = batch[\"label\"].long()\n",
    "        if self.gpu:\n",
    "            x, y = x.cuda(non_blocking=True), y.cuda(non_blocking=True)\n",
    "\n",
    "        # Forward pass\n",
    "        preds = self.forward(x)\n",
    "\n",
    "        if self.loss_function == 'BCE':\n",
    "            loss = self.calculate_loss(x, y, preds)\n",
    "\n",
    "        preds = torch.sigmoid(preds)\n",
    "        \n",
    "        if self.loss_function != 'BCE':\n",
    "            loss = self.calculate_loss(x, y, preds)\n",
    "\n",
    "        preds = (preds > 0.5) * 1  # convert to int\n",
    "\n",
    "        # batch_intersection, batch_union = intersection_and_union(preds, y)\n",
    "    \n",
    "        self.train_IoU(preds, y)\n",
    "\n",
    "        self.log(\n",
    "            \"train_performance\", \n",
    "            {\"iou\": self.train_IoU},\n",
    "            on_step=self.log_on_step,\n",
    "            on_epoch=True,\n",
    "            prog_bar=self.progress_bar,\n",
    "        )\n",
    "        self.log(\n",
    "            \"train_loss\",\n",
    "            loss,\n",
    "            on_step=self.log_on_step,\n",
    "            on_epoch=True,\n",
    "            prog_bar=self.progress_bar,\n",
    "        )\n",
    "        \n",
    "        # keep seperate to use for early stopping\n",
    "        self.log(\"train_iou\", self.train_IoU, on_step=True, on_epoch=True, prog_bar=self.progress_bar)\n",
    "\n",
    "        return loss\n",
    "\n",
    "    def validation_step(self, batch: dict, batch_idx: int):\n",
    "        \"\"\"\n",
    "        Validation step.\n",
    "\n",
    "        Args:\n",
    "            batch (dict): dictionary of items from CloudDataset of the form\n",
    "                {'chip_id': list[str], 'chip': list[torch.Tensor], 'label': list[torch.Tensor]}\n",
    "            batch_idx (int): batch number\n",
    "        \"\"\"\n",
    "        if self.val_dataset.data is None:\n",
    "            raise ValueError(\n",
    "                \"x_val and y_val must be specified when CloudModel is instantiated to run validation\"\n",
    "            )\n",
    "\n",
    "        # Switch on validation mode\n",
    "        self.model.eval()\n",
    "        torch.set_grad_enabled(False)\n",
    "\n",
    "        # Load images and labels\n",
    "        x = batch[\"chip\"]\n",
    "        y = batch[\"label\"].long()\n",
    "        chip_id = batch[\"chip_id\"]\n",
    "        if self.gpu:\n",
    "            x, y = x.cuda(non_blocking=True), y.cuda(non_blocking=True)\n",
    "\n",
    "        preds = self.forward(x)\n",
    "\n",
    "        loss = self.calculate_loss(x, y, preds)\n",
    "\n",
    "        preds = torch.sigmoid(preds)\n",
    "        preds = (preds > 0.5) * 1  # convert to int\n",
    "\n",
    "        if self.plot_validation_images:\n",
    "            # keep to pass to validation_epoch_end and plot\n",
    "            self.last_x = x\n",
    "            self.last_y = y\n",
    "            self.last_pred = preds\n",
    "            self.last_chip_id = chip_id\n",
    "\n",
    "        # Log batch IOU\n",
    "        batch_intersection, batch_union = intersection_and_union(preds, y)\n",
    "        self.val_IoU(preds, y)\n",
    "\n",
    "        self.log(\"val_performance\", \n",
    "                 {\"iou\": self.val_IoU},\n",
    "                 on_step=self.log_on_step, on_epoch=True, prog_bar=self.progress_bar)\n",
    "                 \n",
    "        self.log(\"val_loss\", loss, on_step=self.log_on_step, on_epoch=True, prog_bar=self.progress_bar)\n",
    "        \n",
    "        # keep seperate to use for early stopping\n",
    "        self.log(\"val_iou\", self.val_IoU, on_step=True, on_epoch=True, prog_bar=self.progress_bar)\n",
    "\n",
    "        return {\"loss\": loss}#, \"x\": x, \"y\": y, \"pred\": preds}\n",
    "\n",
    "#     def validation_step_end(self, batch_parts):\n",
    "#         gpu_use = 0\n",
    "#         # print(batch_parts['x'][gpu_use].size())\n",
    "#         return {\"x\": batch_parts[\"x\"][gpu_use], \"y\": batch_parts[\"y\"][gpu_use], \"pred\": batch_parts[\"pred\"][gpu_use]}\n",
    "\n",
    "    # @rank_zero_only\n",
    "    # @rank_zero_experiment\n",
    "    \n",
    "    def validation_epoch_end(self, outputs):\n",
    "        # idevice = self.last_x.get_device()\n",
    "        # if idevice == 0:\n",
    "        # if self.global_rank==0:\n",
    "        if self.plot_validation_images:\n",
    "            # self.logger[0].experiment.add_figure(\"chip_label_prediction\", \n",
    "            self.logger.experiment.add_figure(\"chip_label_prediction\", \n",
    "                                                 plot_prediction_grid(\n",
    "                                                     self.last_x,\n",
    "                                                     self.last_y,\n",
    "                                                     self.last_pred,\n",
    "                                                     self.last_chip_id,\n",
    "                                                     custom_feature_channels=self.custom_feature_channels,\n",
    "                                                     num_images_plot=self.num_images_plot,\n",
    "                                                 ),\n",
    "                                              self.current_epoch,\n",
    "                                             )\n",
    "\n",
    "        # if batch_idx == 0:\n",
    "            # print(out)\n",
    "            # for out in validation_step_outputs[:1]:\n",
    "            #     # output from each gpu\n",
    "            #     print(out)\n",
    "            \n",
    "    def train_dataloader(self):\n",
    "        # DataLoader class for training\n",
    "        return torch.utils.data.DataLoader(\n",
    "            self.train_dataset,\n",
    "            batch_size=self.batch_size|self.hparams.batch_size,\n",
    "            num_workers=self.num_workers,\n",
    "            shuffle=True,\n",
    "            pin_memory=self.pin_memory,\n",
    "            persistent_workers=self.persistent_workers,\n",
    "        )\n",
    "\n",
    "    def val_dataloader(self):\n",
    "        # DataLoader class for validation\n",
    "        return torch.utils.data.DataLoader(\n",
    "            self.val_dataset,\n",
    "            batch_size=self.batch_size,\n",
    "            num_workers=self.num_workers,\n",
    "            shuffle=False,\n",
    "            drop_last=self.plot_validation_images, # if plotting last batch images ensure full last batch\n",
    "            pin_memory=self.pin_memory,\n",
    "            persistent_workers=self.persistent_workers,\n",
    "        )\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        \n",
    "        if self.optimizer.upper()==\"ADAM\":\n",
    "            optimizer = torch.optim.Adam(\n",
    "                self.model.parameters(),\n",
    "                lr=self.learning_rate,\n",
    "            )\n",
    "            \n",
    "        if self.optimizer.upper()==\"ADAMW\":\n",
    "            optimizer = torch.optim.AdamW(\n",
    "                self.model.parameters(),\n",
    "                lr=self.learning_rate,\n",
    "                weight_decay=0.05,\n",
    "            )\n",
    "            # sch = torch.optim.lr_scheduler.CosineAnnealingLR(opt, T_max=10)\n",
    "\n",
    "        if self.optimizer.upper()==\"SGD\":\n",
    "            optimizer = torch.optim.SGD(\n",
    "                self.model.parameters(),\n",
    "                lr=self.learning_rate,\n",
    "                momentum=self.momentum,\n",
    "            )\n",
    "        \n",
    "        if self.scheduler.upper()==\"EXPONENTIAL\":\n",
    "            scheduler = torch.optim.lr_scheduler.ExponentialLR(\n",
    "                optimizer,\n",
    "                gamma=0.95,\n",
    "            )\n",
    "            \n",
    "        if self.scheduler.upper()==\"COSINE\":\n",
    "            # scheduler = torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(\n",
    "            #     optimizer,\n",
    "            #     T_0=self.T_0,\n",
    "            #     eta_min=self.eta_min,\n",
    "            # ) \n",
    "\n",
    "            scheduler = pl_bolts.optimizers.lr_scheduler.LinearWarmupCosineAnnealingLR(\n",
    "                optimizer,\n",
    "                warmup_epochs=10,\n",
    "                max_epochs=50,\n",
    "            ) \n",
    "  \n",
    "\n",
    "        if self.scheduler.upper()==\"PLATEAU\":\n",
    "            scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(\n",
    "                optimizer,\n",
    "                'max',\n",
    "                factor=self.reduce_learning_rate_factor,\n",
    "                patience=self.learning_rate_patience,\n",
    "            )\n",
    "            \n",
    "            return {\"optimizer\": optimizer, \n",
    "                    \"lr_scheduler\": {\n",
    "                        \"scheduler\": scheduler,\n",
    "                        \"monitor\": \"val_iou\",\n",
    "                    },\n",
    "            }\n",
    "                                       \n",
    "        return [optimizer], [scheduler]\n",
    "                \n",
    "    ## Convenience Methods ##\n",
    "    def _prepare_model(self):\n",
    "        \n",
    "        if self.segmentation_model.upper()==\"UNET\":\n",
    "            # Instantiate U-Net model\n",
    "            unet_model = smp.Unet(\n",
    "                encoder_name=self.encoder_name,\n",
    "                encoder_weights=self.weights,\n",
    "                in_channels=self.num_channels,\n",
    "                classes=1,\n",
    "            )\n",
    "            if self.gpu:\n",
    "                unet_model.cuda()\n",
    "                \n",
    "        if self.segmentation_model.upper()==\"DEEPLABV3PLUS\":\n",
    "            # Instantiate DeepLabV3Plus model (https://arxiv.org/abs/1802.02611v3)\n",
    "            unet_model = smp.DeepLabV3Plus(\n",
    "                encoder_name=self.encoder_name,\n",
    "                encoder_weights=self.weights,\n",
    "                in_channels=self.num_channels,\n",
    "                classes=1,\n",
    "            )\n",
    "            if self.gpu:\n",
    "                unet_model.cuda()\n",
    "\n",
    "        return unet_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbaadbe6-6104-4df7-8f09-2dbb8a191b6b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ccc27136-8b37-4293-b1f4-36925ab32a92",
   "metadata": {},
   "source": [
    "## Original training loop, with 2 output classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9f3de93-1300-448d-bbfb-0b2a94055e6c",
   "metadata": {},
   "outputs": [],
   "source": [
    " def forward(self, image: torch.Tensor):\n",
    "        # Forward pass\n",
    "        return self.model(image)\n",
    "\n",
    "    def training_step(self, batch: dict, batch_idx: int):\n",
    "        \"\"\"\n",
    "        Training step.\n",
    "\n",
    "        Args:\n",
    "            batch (dict): dictionary of items from CloudDataset of the form\n",
    "                {'chip_id': list[str], 'chip': list[torch.Tensor], 'label': list[torch.Tensor]}\n",
    "            batch_idx (int): batch number\n",
    "        \"\"\"\n",
    "        if self.train_dataset.data is None:\n",
    "            raise ValueError(\n",
    "                \"x_train and y_train must be specified when CloudModel is instantiated to run training\"\n",
    "            )\n",
    "\n",
    "        # Switch on training mode\n",
    "        self.model.train()\n",
    "        torch.set_grad_enabled(True)\n",
    "\n",
    "        # Load images and labels\n",
    "        x = batch[\"chip\"]\n",
    "        y = batch[\"label\"].long()\n",
    "        if self.gpu:\n",
    "            x, y = x.cuda(non_blocking=True), y.cuda(non_blocking=True)\n",
    "\n",
    "        # Forward pass\n",
    "        preds = self.forward(x)\n",
    "\n",
    "        # Log batch loss\n",
    "        loss = torch.nn.CrossEntropyLoss(reduction=\"none\")(preds, y).mean()\n",
    "        self.log(\n",
    "            \"loss\",\n",
    "            loss,\n",
    "            on_step=True,\n",
    "            on_epoch=True,\n",
    "            prog_bar=True,\n",
    "            logger=True,\n",
    "        )\n",
    "        return loss\n",
    "\n",
    "    def validation_step(self, batch: dict, batch_idx: int):\n",
    "        \"\"\"\n",
    "        Validation step.\n",
    "\n",
    "        Args:\n",
    "            batch (dict): dictionary of items from CloudDataset of the form\n",
    "                {'chip_id': list[str], 'chip': list[torch.Tensor], 'label': list[torch.Tensor]}\n",
    "            batch_idx (int): batch number\n",
    "        \"\"\"\n",
    "        if self.val_dataset.data is None:\n",
    "            raise ValueError(\n",
    "                \"x_val and y_val must be specified when CloudModel is instantiated to run validation\"\n",
    "            )\n",
    "\n",
    "        # Switch on validation mode\n",
    "        self.model.eval()\n",
    "        torch.set_grad_enabled(False)\n",
    "\n",
    "        # Load images and labels\n",
    "        x = batch[\"chip\"]\n",
    "        y = batch[\"label\"].long()\n",
    "        if self.gpu:\n",
    "            x, y = x.cuda(non_blocking=True), y.cuda(non_blocking=True)\n",
    "\n",
    "        # Forward pass & softmax\n",
    "        preds = self.forward(x)\n",
    "        preds = torch.softmax(preds, dim=1)[:, 1]\n",
    "        preds = (preds > 0.5) * 1  # convert to int\n",
    "\n",
    "        # Log batch IOU\n",
    "        batch_iou = intersection_over_union(preds, y)\n",
    "        self.log(\n",
    "            \"iou\", batch_iou, on_step=True, on_epoch=True, prog_bar=True, logger=True\n",
    "        )\n",
    "        return batch_iou"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc7c551a-7cb9-4602-985e-845add2e7a44",
   "metadata": {},
   "source": [
    "## Cloud model backup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "93a11ff9-739d-4511-b586-2a6eb46feacc",
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "attempted relative import with no known parent package",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_82122/2238648553.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;31m# from pytorch_lightning.loggers.base import rank_zero_experiment\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mcloud_dataset\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mCloudDataset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mlosses\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mintersection_and_union\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mlosses\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdice_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpower_jaccard\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mImportError\u001b[0m: attempted relative import with no known parent package"
     ]
    }
   ],
   "source": [
    "# %%file {unet_model_dir}/cloud_model.py\n",
    "\n",
    "from typing import Optional, List\n",
    "\n",
    "import pandas as pd\n",
    "import pytorch_lightning as pl\n",
    "import segmentation_models_pytorch as smp\n",
    "import torch\n",
    "import torchmetrics\n",
    "# from pytorch_lightning.utilities import rank_zero_only\n",
    "# from pytorch_lightning.loggers.base import rank_zero_experiment\n",
    "\n",
    "from .cloud_dataset import CloudDataset\n",
    "from .losses import intersection_and_union\n",
    "from .losses import dice_loss, power_jaccard\n",
    "from .plotting_tools import plot_prediction_grid\n",
    "\n",
    "\n",
    "class CloudModel(pl.LightningModule):\n",
    "    def __init__(\n",
    "        self,\n",
    "        bands: List[str],\n",
    "        x_train: Optional[pd.DataFrame] = None,\n",
    "        y_train: Optional[pd.DataFrame] = None,\n",
    "        x_val: Optional[pd.DataFrame] = None,\n",
    "        y_val: Optional[pd.DataFrame] = None,\n",
    "        cloudbank: Optional[pd.DataFrame] = None,\n",
    "        train_transforms = None,\n",
    "        val_transforms = None,\n",
    "        hparams: dict = {},\n",
    "    ):\n",
    "        \"\"\"\n",
    "        Instantiate the CloudModel class based on the pl.LightningModule\n",
    "        (https://pytorch-lightning.readthedocs.io/en/latest/common/lightning_module.html).\n",
    "\n",
    "        Args:\n",
    "            bands (list[str]): Names of the bands provided for each chip\n",
    "            x_train (pd.DataFrame, optional): a dataframe of the training features with a row for each chip.\n",
    "                There must be a column for chip_id, and a column with the path to the TIF for each of bands.\n",
    "                Required for model training\n",
    "            y_train (pd.DataFrame, optional): a dataframe of the training labels with a for each chip\n",
    "                and columns for chip_id and the path to the label TIF with ground truth cloud cover.\n",
    "                Required for model training\n",
    "            x_val (pd.DataFrame, optional): a dataframe of the validation features with a row for each chip.\n",
    "                There must be a column for chip_id, and a column with the path to the TIF for each of bands.\n",
    "                Required for model training\n",
    "            y_val (pd.DataFrame, optional): a dataframe of the validation labels with a for each chip\n",
    "                and columns for chip_id and the path to the label TIF with ground truth cloud cover.\n",
    "                Required for model training\n",
    "            cloudbank (pd.DataFrame, optional): a dataframe of paths to additional clouds to sample from. \n",
    "                Optional for model training, but required if using chips where label_path=='None'\n",
    "            hparams (dict, optional): Dictionary of additional modeling parameters.\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        self.hparams.update(hparams)\n",
    "        self.save_hyperparameters()\n",
    "\n",
    "        # required\n",
    "        self.bands = bands\n",
    "        self.num_channels = len(bands)\n",
    "        \n",
    "        # optional modeling params\n",
    "        self.segmentation_model = self.hparams.get(\"segmentation_model\", \"unet\")\n",
    "        self.encoder_name = self.hparams.get(\"encoder_name\", \"efficientnet-b0\")\n",
    "        self.weights = self.hparams.get(\"weights\", None)\n",
    "        \n",
    "        self.custom_feature_channels = self.hparams.get(\"custom_feature_channels\", None)\n",
    "                                                        \n",
    "        self.loss_function = self.hparams.get(\"loss_function\", \"BCE\")        \n",
    "        self.optimizer = self.hparams.get(\"optimizer\", \"ADAM\")\n",
    "        self.scheduler = self.hparams.get(\"scheduler\", \"PLATEAU\")\n",
    "        \n",
    "        self.learning_rate = self.hparams.get(\"learning_rate\", 1e-3)\n",
    "        self.momentum = self.hparams.get(\"momentum\", 0.9)\n",
    "        self.T_0 = self.hparams.get(\"T_0\", 10)\n",
    "        self.eta_min = self.hparams.get(\"eta_min\", 1e-5)\n",
    "      \n",
    "        self.reduce_learning_rate_factor = self.hparams.get(\"reduce_learning_rate_factor\", 0.1)\n",
    "\n",
    "        self.patience = self.hparams.get(\"patience\", 10)\n",
    "        self.learning_rate_patience = self.hparams.get(\"learning_rate_patience\", 5)\n",
    "        self.batch_size = self.hparams.get(\"batch_size\", 8)\n",
    "\n",
    "        self.num_workers = self.hparams.get(\"num_workers\", 2)\n",
    "        self.pin_memory = self.hparams.get(\"pin_memory\", True)\n",
    "        self.persistent_workers = self.hparams.get(\"persistent_workers\", False)\n",
    "        \n",
    "        self.gpu = self.hparams.get(\"gpu\", False)\n",
    "        \n",
    "        self.log_on_step = self.hparams.get(\"log_on_step\", False)\n",
    "        self.progress_bar = self.hparams.get(\"progress_bar\", False)\n",
    "        \n",
    "        self.plot_validation_images = self.hparams.get(\"plot_validation_images\", True)\n",
    "        self.num_images_plot = self.hparams.get(\"num_images_plot\", self.batch_size)\n",
    "\n",
    "        self.train_transform = train_transforms\n",
    "        self.val_transform = val_transforms\n",
    "\n",
    "        # Instantiate datasets, model, and trainer params if provided\n",
    "        self.train_dataset = CloudDataset(\n",
    "            x_paths=x_train,\n",
    "            bands=self.bands,\n",
    "            y_paths=y_train,\n",
    "            cloudbank=cloudbank,\n",
    "            transforms=self.train_transform,\n",
    "            custom_feature_channels=self.custom_feature_channels,\n",
    "        )\n",
    "        self.val_dataset = CloudDataset(\n",
    "            x_paths=x_val,\n",
    "            bands=self.bands,\n",
    "            y_paths=y_val,\n",
    "            transforms=self.val_transform,\n",
    "            custom_feature_channels=self.custom_feature_channels,\n",
    "        )\n",
    "        \n",
    "        # define some performance metrics using torchmetrics\n",
    "        # self.train_accuracy = torchmetrics.Accuracy()\n",
    "        # self.val_intersection = mymetrics.Intersection()\n",
    "        self.val_IoU = torchmetrics.IoU(num_classes=2)\n",
    "        self.train_IoU = torchmetrics.IoU(num_classes=2)\n",
    "\n",
    "        self.model = self._prepare_model()\n",
    "\n",
    "    ## Required LightningModule methods ##\n",
    "    def forward(self, image: torch.Tensor):\n",
    "        \"\"\"\n",
    "        Forward pass\n",
    "        output of model is (B, 1, H, W), so remove axis=1\n",
    "        return raw logits in order to use BCEWithLogitsLoss which is more stable than BCE:\n",
    "        https://pytorch.org/docs/stable/generated/torch.nn.BCEWithLogitsLoss.html#torch.nn.BCEWithLogitsLoss\n",
    "        \"\"\"\n",
    "        return self.model(image).view(-1, 512, 512)\n",
    "\n",
    "    def calculate_loss(self, chip, label, preds):\n",
    "        if self.loss_function.upper()==\"BCE\":\n",
    "            loss = torch.nn.BCEWithLogitsLoss(reduction=\"none\")(preds, label.float()).mean()\n",
    "            \n",
    "        if self.loss_function.upper()==\"DICE\":\n",
    "            loss = dice_loss(preds, label)\n",
    "            \n",
    "        if self.loss_function.upper()==\"JACCARD\":\n",
    "            loss = power_jaccard(preds, label, power_val=1.)\n",
    "\n",
    "        return loss\n",
    "\n",
    "    def training_step(self, batch: dict, batch_idx: int):\n",
    "        \"\"\"\n",
    "        Training step.\n",
    "\n",
    "        Args:\n",
    "            batch (dict): dictionary of items from CloudDataset of the form\n",
    "                {'chip_id': list[str], 'chip': list[torch.Tensor], 'label': list[torch.Tensor]}\n",
    "            batch_idx (int): batch number\n",
    "        \"\"\"\n",
    "        if self.train_dataset.data is None:\n",
    "            raise ValueError(\n",
    "                \"x_train and y_train must be specified when CloudModel is instantiated to run training\"\n",
    "            )\n",
    "\n",
    "        # Switch on training mode\n",
    "        self.model.train()\n",
    "        torch.set_grad_enabled(True)\n",
    "\n",
    "        # Load images and labels\n",
    "        x = batch[\"chip\"]\n",
    "        y = batch[\"label\"].long()\n",
    "        if self.gpu:\n",
    "            x, y = x.cuda(non_blocking=True), y.cuda(non_blocking=True)\n",
    "\n",
    "        # Forward pass\n",
    "        preds = self.forward(x)\n",
    "\n",
    "        if self.loss_function == 'BCE':\n",
    "            loss = self.calculate_loss(x, y, preds)\n",
    "\n",
    "        preds = torch.sigmoid(preds)\n",
    "        \n",
    "        if self.loss_function != 'BCE':\n",
    "            loss = self.calculate_loss(x, y, preds)\n",
    "\n",
    "        preds = (preds > 0.5) * 1  # convert to int\n",
    "\n",
    "        # batch_intersection, batch_union = intersection_and_union(preds, y)\n",
    "    \n",
    "        self.train_IoU(preds, y)\n",
    "\n",
    "        self.log(\n",
    "            \"train_performance\", \n",
    "            {\"iou\": self.train_IoU},\n",
    "            on_step=self.log_on_step,\n",
    "            on_epoch=True,\n",
    "            prog_bar=self.progress_bar,\n",
    "        )\n",
    "        self.log(\n",
    "            \"train_loss\",\n",
    "            loss,\n",
    "            on_step=self.log_on_step,\n",
    "            on_epoch=True,\n",
    "            prog_bar=self.progress_bar,\n",
    "        )\n",
    "        \n",
    "        # keep seperate to use for early stopping\n",
    "        self.log(\"train_iou\", self.train_IoU, on_step=True, on_epoch=True, prog_bar=self.progress_bar)\n",
    "\n",
    "        return loss\n",
    "\n",
    "    def validation_step(self, batch: dict, batch_idx: int):\n",
    "        \"\"\"\n",
    "        Validation step.\n",
    "\n",
    "        Args:\n",
    "            batch (dict): dictionary of items from CloudDataset of the form\n",
    "                {'chip_id': list[str], 'chip': list[torch.Tensor], 'label': list[torch.Tensor]}\n",
    "            batch_idx (int): batch number\n",
    "        \"\"\"\n",
    "        if self.val_dataset.data is None:\n",
    "            raise ValueError(\n",
    "                \"x_val and y_val must be specified when CloudModel is instantiated to run validation\"\n",
    "            )\n",
    "\n",
    "        # Switch on validation mode\n",
    "        self.model.eval()\n",
    "        torch.set_grad_enabled(False)\n",
    "\n",
    "        # Load images and labels\n",
    "        x = batch[\"chip\"]\n",
    "        y = batch[\"label\"].long()\n",
    "        chip_id = batch[\"chip_id\"]\n",
    "        if self.gpu:\n",
    "            x, y = x.cuda(non_blocking=True), y.cuda(non_blocking=True)\n",
    "\n",
    "        preds = self.forward(x)\n",
    "\n",
    "        loss = self.calculate_loss(x, y, preds)\n",
    "\n",
    "        preds = torch.sigmoid(preds)\n",
    "        preds = (preds > 0.5) * 1  # convert to int\n",
    "\n",
    "        if self.plot_validation_images:\n",
    "            # keep to pass to validation_epoch_end and plot\n",
    "            self.last_x = x\n",
    "            self.last_y = y\n",
    "            self.last_pred = preds\n",
    "            self.last_chip_id = chip_id\n",
    "\n",
    "        # Log batch IOU\n",
    "        batch_intersection, batch_union = intersection_and_union(preds, y)\n",
    "        self.val_IoU(preds, y)\n",
    "\n",
    "        self.log(\"val_performance\", \n",
    "                 {\"iou\": self.val_IoU},\n",
    "                 on_step=self.log_on_step, on_epoch=True, prog_bar=self.progress_bar)\n",
    "                 \n",
    "        self.log(\"val_loss\", loss, on_step=self.log_on_step, on_epoch=True, prog_bar=self.progress_bar)\n",
    "        \n",
    "        # keep seperate to use for early stopping\n",
    "        self.log(\"val_iou\", self.val_IoU, on_step=True, on_epoch=True, prog_bar=self.progress_bar)\n",
    "\n",
    "        return {\"loss\": loss}#, \"x\": x, \"y\": y, \"pred\": preds}\n",
    "\n",
    "#     def validation_step_end(self, batch_parts):\n",
    "#         gpu_use = 0\n",
    "#         # print(batch_parts['x'][gpu_use].size())\n",
    "#         return {\"x\": batch_parts[\"x\"][gpu_use], \"y\": batch_parts[\"y\"][gpu_use], \"pred\": batch_parts[\"pred\"][gpu_use]}\n",
    "\n",
    "    # @rank_zero_only\n",
    "    # @rank_zero_experiment\n",
    "    \n",
    "    def validation_epoch_end(self, outputs):\n",
    "        # idevice = self.last_x.get_device()\n",
    "        # if idevice == 0:\n",
    "        # if self.global_rank==0:\n",
    "        if self.plot_validation_images:\n",
    "            # self.logger[0].experiment.add_figure(\"chip_label_prediction\", \n",
    "            self.logger.experiment.add_figure(\"chip_label_prediction\", \n",
    "                                                 plot_prediction_grid(\n",
    "                                                     self.last_x,\n",
    "                                                     self.last_y,\n",
    "                                                     self.last_pred,\n",
    "                                                     self.last_chip_id,\n",
    "                                                     custom_feature_channels=self.custom_feature_channels,\n",
    "                                                     num_images_plot=self.num_images_plot,\n",
    "                                                 ),\n",
    "                                              self.current_epoch,\n",
    "                                             )\n",
    "\n",
    "        # if batch_idx == 0:\n",
    "            # print(out)\n",
    "            # for out in validation_step_outputs[:1]:\n",
    "            #     # output from each gpu\n",
    "            #     print(out)\n",
    "            \n",
    "    def train_dataloader(self):\n",
    "        # DataLoader class for training\n",
    "        return torch.utils.data.DataLoader(\n",
    "            self.train_dataset,\n",
    "            batch_size=self.batch_size|self.hparams.batch_size,\n",
    "            num_workers=self.num_workers,\n",
    "            shuffle=True,\n",
    "            pin_memory=self.pin_memory,\n",
    "            persistent_workers=self.persistent_workers,\n",
    "        )\n",
    "\n",
    "    def val_dataloader(self):\n",
    "        # DataLoader class for validation\n",
    "        return torch.utils.data.DataLoader(\n",
    "            self.val_dataset,\n",
    "            batch_size=self.batch_size,\n",
    "            num_workers=self.num_workers,\n",
    "            shuffle=False,\n",
    "            drop_last=self.plot_validation_images, # if plotting last batch images ensure full last batch\n",
    "            pin_memory=self.pin_memory,\n",
    "            persistent_workers=self.persistent_workers,\n",
    "        )\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        \n",
    "        if self.optimizer.upper()==\"ADAM\":\n",
    "            optimizer = torch.optim.Adam(\n",
    "                self.model.parameters(),\n",
    "                lr=self.learning_rate,\n",
    "            )\n",
    "            \n",
    "        if self.optimizer.upper()==\"ADAMW\":\n",
    "            optimizer = torch.optim.AdamW(\n",
    "                self.model.parameters(),\n",
    "                lr=self.learning_rate,\n",
    "            )\n",
    "            # sch = torch.optim.lr_scheduler.CosineAnnealingLR(opt, T_max=10)\n",
    "\n",
    "        if self.optimizer.upper()==\"SGD\":\n",
    "            optimizer = torch.optim.SGD(\n",
    "                self.model.parameters(),\n",
    "                lr=self.learning_rate,\n",
    "                momentum=self.momentum,\n",
    "            )\n",
    "        \n",
    "        if self.scheduler.upper()==\"EXPONENTIAL\":\n",
    "            scheduler = torch.optim.lr_scheduler.ExponentialLR(\n",
    "                optimizer,\n",
    "                gamma=0.95,\n",
    "            )\n",
    "            \n",
    "        if self.scheduler.upper()==\"COSINE\":\n",
    "            scheduler = torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(\n",
    "                optimizer,\n",
    "                T_0=self.T_0,\n",
    "                eta_min=self.eta_min,\n",
    "            ) \n",
    "  \n",
    "        if self.scheduler.upper()==\"PLATEAU\":\n",
    "            scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(\n",
    "                optimizer,\n",
    "                'max',\n",
    "                factor=self.reduce_learning_rate_factor,\n",
    "                patience=self.learning_rate_patience,\n",
    "            )\n",
    "            \n",
    "            return {\"optimizer\": optimizer, \n",
    "                    \"lr_scheduler\": {\n",
    "                        \"scheduler\": scheduler,\n",
    "                        \"monitor\": \"val_iou\",\n",
    "                    },\n",
    "            }\n",
    "                                       \n",
    "        return [optimizer], [scheduler]\n",
    "                \n",
    "    ## Convenience Methods ##\n",
    "    def _prepare_model(self):\n",
    "        \n",
    "        if self.segmentation_model.upper()==\"UNET\":\n",
    "            # Instantiate U-Net model\n",
    "            unet_model = smp.Unet(\n",
    "                encoder_name=self.encoder_name,\n",
    "                encoder_weights=self.weights,\n",
    "                in_channels=self.num_channels,\n",
    "                classes=1,\n",
    "            )\n",
    "            if self.gpu:\n",
    "                unet_model.cuda()\n",
    "                \n",
    "        if self.segmentation_model.upper()==\"DEEPLABV3PLUS\":\n",
    "            # Instantiate DeepLabV3Plus model (https://arxiv.org/abs/1802.02611v3)\n",
    "            unet_model = smp.DeepLabV3Plus(\n",
    "                encoder_name=self.encoder_name,\n",
    "                encoder_weights=self.weights,\n",
    "                in_channels=self.num_channels,\n",
    "                classes=1,\n",
    "            )\n",
    "            if self.gpu:\n",
    "                unet_model.cuda()\n",
    "\n",
    "        return unet_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2ad5a6b-0512-4d58-ac78-cea97c4bafd1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d105217-8e8c-4a74-ac12-15e95286e388",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f9b5cea6-786f-4183-9f93-de59acd75ec8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1.3033, 0.8767, 0.8793]) tensor([0., 1., 1.])\n",
      "tensor([0.7864, 0.7061, 0.7067]) tensor([1.5436, 0.3480, 0.3472])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "inp = torch.randn(3)\n",
    "target = torch.empty(3).random_(2)\n",
    "print(inp, target)\n",
    "\n",
    "loss = torch.nn.BCEWithLogitsLoss(reduction=\"none\")(inp, target)\n",
    "print(torch.sigmoid(inp), loss, )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be41711c-7c07-4aaa-8cb0-b6ae3f638ac0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab78b2f3-8eb6-4c81-9e1f-80402e0f98ca",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbaf9947-5324-479f-abd4-cfc29c556a4e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d8da26b9-408f-4227-9d29-cc52e0604e21",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'cloud_model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_20946/1422955332.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mmodel_weight_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msubmission_assets_dir\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;34m\"cloud_model.pt\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcloud_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_weight_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'cloud_model' is not defined"
     ]
    }
   ],
   "source": [
    "# save the model\n",
    "submission_assets_dir = submission_dir / \"assets\"\n",
    "submission_assets_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "model_weight_path = submission_assets_dir / \"cloud_model.pt\"\n",
    "torch.save(cloud_model.state_dict(), model_weight_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "5995f904-7e4b-45f8-abd0-22960e22791a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "benchmark_src\n",
      " __pycache__\n",
      "  main.cpython-38.pyc\n",
      " main.py\n",
      "\n",
      "1 directory, 2 files\n"
     ]
    }
   ],
   "source": [
    "!tree benchmark_src\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f74855c-3bb6-4ad4-8780-629800b79ebf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Zip submission\n",
    "!cd unet_src && zip -r ../submission.zip *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "1c0d7d79-817b-4261-86bf-dbdee7bd764c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "84M\tsubmission.zip\n"
     ]
    }
   ],
   "source": [
    "!du -h submission.zip\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea250baf-494f-4c8e-9698-91f1c27f6bfe",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "CloudCover",
   "language": "python",
   "name": "cloud_cover"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
