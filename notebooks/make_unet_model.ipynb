{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "24195ab3-3987-4275-8688-f08fc6fc378c",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "from pathlib import Path\n",
    "\n",
    "import os\n",
    "os.environ['OPENBLAS_NUM_THREADS'] = '1'\n",
    "\n",
    "# construct_training_set = True\n",
    "construct_training_set = False\n",
    "\n",
    "# use_cloudaugment = True\n",
    "use_cloudaugment = False\n",
    "\n",
    "# create U-Net folder\n",
    "unet_model_dir = Path(\"../cloud_seg/models/unet/\")\n",
    "unet_model_dir.mkdir(parents=True, exist_ok=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "937c2f29-ecdd-4ae5-a145-9ba6ca150ff1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Things to add\n",
    "# https://pytorch-lightning.readthedocs.io/en/latest/common/lightning_cli.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "441d4673-4049-4d50-9d33-3fd9898a3254",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting ../cloud_seg/utils/augmentations.py\n"
     ]
    }
   ],
   "source": [
    "%%file ../cloud_seg/utils/augmentations.py\n",
    "import albumentations as A\n",
    "import numpy as np\n",
    "\n",
    "class CloudAugmentations:\n",
    "    def __init__(self, params):\n",
    "\n",
    "        self.params = params\n",
    "\n",
    "        # Dictionary to convert between abbreviation and full augmentation string                              \n",
    "        self.aug_to_name = {\n",
    "            'vf': 'VerticalFlip',\n",
    "            'hf': 'HorizontalFlip',\n",
    "            'rr': 'RandomRotate90',\n",
    "            'nr': 'Normalize',\n",
    "            # 'ss': 'SizeScale',\n",
    "            # 'gb': 'GaussianBlur',\n",
    "            # 'gn': 'GaussianNoise',\n",
    "        }\n",
    "\n",
    "        self.aug_to_func = {\n",
    "            'vf': self.add_VerticalFlip,\n",
    "            'hf': self.add_HorizontalFlip,\n",
    "            'rr': self.add_RandomRotate90,\n",
    "            'nr': self.add_Normalize,\n",
    "            # 'ss': self.add_SizeScale,\n",
    "            # 'gb': self.add_GaussianBlur,\n",
    "            # 'gn': self.add_GaussianNoise,\n",
    "        }\n",
    "        \n",
    "    # Augmentation functions are listed in the order that they (mostly) should be called   \n",
    "    def add_VerticalFlip(self):\n",
    "        self.augmentations_names.append(self.aug_to_name['vf'])\n",
    "        self.augmentations.append(A.VerticalFlip(p=0.5))\n",
    "\n",
    "    def add_HorizontalFlip(self):\n",
    "        self.augmentations_names.append(self.aug_to_name['hf'])\n",
    "        self.augmentations.append(A.HorizontalFlip(p=0.5))\n",
    "\n",
    "    def add_RandomRotate90(self):\n",
    "        self.augmentations_names.append(self.aug_to_name['rr'])\n",
    "        self.augmentations.append(A.RandomRotate90(p=0.5))\n",
    "        \n",
    "    def add_Normalize(self):\n",
    "        self.augmentations_names.append(self.aug_to_name['nr'])\n",
    "        self.augmentations.append(\n",
    "            A.Normalize(\n",
    "                mean=self.params['band_means'],\n",
    "                std=self.params['band_stds'],\n",
    "                max_pixel_value=1.0,\n",
    "                p=1.0,\n",
    "            )\n",
    "        )        \n",
    "    def add_augmentations(self, augs_manual: str=None):\n",
    "        self.augmentations = []\n",
    "        self.augmentations_names = []\n",
    "\n",
    "        # split every two characters                                                                           \n",
    "        if augs_manual is None:\n",
    "            augmentations_use = self.params['augmentations']\n",
    "        if augs_manual is not None:\n",
    "            augmentations_use = augs_manual\n",
    "\n",
    "        augs = [augmentations_use[i:i+2] for i in range(0, len(augmentations_use), 2)]\n",
    "\n",
    "        for aug in augs:\n",
    "            if aug not in self.aug_to_func.keys():\n",
    "                sys.exit(f\"Augmentation abbreviation {aug} is not an available key. Choose from\", self.aug_to_name.key())\n",
    "\n",
    "            self.aug_to_func[aug]() # () required to actually call function                                    \n",
    "\n",
    "        if self.params['verbose']:\n",
    "            print(f\"\\nUsing augmentations \\n{self.augmentations_names}\\n {self.augmentations}\")\n",
    "\n",
    "        return self.augmentations, self.augmentations_names\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "b602a320-a101-40da-9392-cd32ffdc9ebe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'a_b_c'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_transforms_names = ['a', 'b', 'c']\n",
    "string"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "643ef70e-5beb-4911-94fa-05c566784dfb",
   "metadata": {},
   "source": [
    "### Model training script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "827e86eb-b91d-4571-b017-be6902894850",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting ../scripts/train_unet.py\n"
     ]
    }
   ],
   "source": [
    "%%file ../scripts/train_unet.py\n",
    "\n",
    "import shutil\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pandas_path as path\n",
    "from PIL import Image\n",
    "import torch\n",
    "import pytorch_lightning as pl\n",
    "import glob\n",
    "from pathlib import Path\n",
    "import argparse\n",
    "import os\n",
    "\n",
    "from pytorch_lightning import loggers as pl_loggers\n",
    "import albumentations as A\n",
    "\n",
    "from cloud_seg.models.unet.cloud_model import CloudModel\n",
    "from cloud_seg.utils.augmentations import CloudAugmentations\n",
    "\n",
    "DATA_DIR = Path.cwd().parent.resolve() / \"data/\"\n",
    "DATA_DIR_MODEL_TRAINING = DATA_DIR / \"model_training/\"\n",
    "DATA_DIR_CLOUDLESS = DATA_DIR / 'cloudless/tif/'\n",
    "DATA_DIR_CLOUDS = DATA_DIR / 'clouds/'\n",
    "\n",
    "TRAIN_FEATURES = DATA_DIR / \"train_features\"\n",
    "TRAIN_FEATURES_NEW = DATA_DIR / \"train_features_new\"\n",
    "\n",
    "TRAIN_LABELS = DATA_DIR / \"train_labels\"\n",
    "\n",
    "band_mean_std = np.load(DATA_DIR / 'measured_band_stats.npy', allow_pickle=True).item()\n",
    "\n",
    "def main(args):\n",
    "    \n",
    "    hparams = vars(args)\n",
    "    if hparams['verbose']: print(\"Parameters are: \", hparams)\n",
    "\n",
    "    pl.seed_everything(hparams['seed'], workers=True)\n",
    "\n",
    "    hparams['bands_use'] = sorted(hparams['bands'] + hparams['bands_new']) if hparams['bands_new'] is not None else hparams['bands']\n",
    "    hparams['precision'] = 32\n",
    "    \n",
    "    hparams['band_means'] = [band_mean_std[i]['mean'] for i in hparams['bands_use']]\n",
    "    hparams['band_stds'] = [band_mean_std[i]['std'] for i in hparams['bands_use']]\n",
    "    hparams['OUTPUT_DIR'] = os.path.join(hparams['OUTPUT_DIR'], hparams['segmentation_model'])\n",
    "    Path(hparams['OUTPUT_DIR']).mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    \n",
    "    # Set up transforms using Albumentations library\n",
    "    Augs = CloudAugmentations(hparams)\n",
    "    train_transforms, train_transforms_names = Augs.add_augmentations()\n",
    "    train_transforms = A.Compose(train_transforms)\n",
    "\n",
    "    augs_val = ''\n",
    "    val_transforms, val_transforms_names = Augs.add_augmentations(augs_val)\n",
    "    val_transforms = A.Compose(val_transforms)\n",
    "\n",
    "    print(train_transforms_names, val_transforms_names)\n",
    "    print(train_transforms, val_transforms)\n",
    "    \n",
    "    \n",
    "    # set up logger and model outputs to have meaningful name\n",
    "    augmentations_used_string = '_'.join([name for name in train_transforms_names]) \n",
    "\n",
    "    dataset_str = 'originaldata'\n",
    "    if hparams['cloud_augment']:\n",
    "        dataset_str += '_cloudaugment'\n",
    "    \n",
    "    hparams['model_training_name'] = f\"{len(hparams['bands_use'])}band_{dataset_str}_{hparams['encoder_name']}_{hparams['loss_function']}_{augmentations_used_string}\"\n",
    "    if hparams['test_run']:\n",
    "        model_training_name = 'test'\n",
    "    \n",
    "    hparams['LOG_DIR'] = os.path.join(hparams['OUTPUT_DIR'], hparams['model_training_name'], hparams['LOG_DIR'])\n",
    "    hparams['MODEL_DIR'] = os.path.join(hparams['OUTPUT_DIR'], hparams['model_training_name'], hparams['MODEL_DIR'])\n",
    "                                      \n",
    "    Path(hparams['LOG_DIR']).mkdir(parents=True, exist_ok=True)\n",
    "    Path(hparams['MODEL_DIR']).mkdir(parents=True, exist_ok=True)\n",
    "    \n",
    "\n",
    "    # Load Data\n",
    "    val_x = pd.read_csv(DATA_DIR_MODEL_TRAINING / f\"validate_features_meta_cv{hparams['cross_validation_split']}.csv\")\n",
    "    val_y = pd.read_csv(DATA_DIR_MODEL_TRAINING / f\"validate_labels_meta_cv{hparams['cross_validation_split']}.csv\")\n",
    "    \n",
    "    # shuffle validation, such that each batch will have samples from different locations,\n",
    "    # as validation_dataloader has shuffle=False\n",
    "    val_x = val_x.sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "    val_y = val_y.sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "    \n",
    "    if hparams['verbose']: print(val_y.head())\n",
    "    \n",
    "    train_x = pd.read_csv(DATA_DIR_MODEL_TRAINING / f\"train_features_meta_cv{hparams['cross_validation_split']}.csv\")\n",
    "    train_y = pd.read_csv(DATA_DIR_MODEL_TRAINING / f\"train_labels_meta_cv{hparams['cross_validation_split']}.csv\")\n",
    "\n",
    "    if not hparams['cloud_augment']:\n",
    "        \n",
    "        df_cloudbank = None\n",
    "    \n",
    "    if hparams['cloud_augment']:\n",
    "\n",
    "        train_x_cloudless = pd.read_csv(DATA_DIR_MODEL_TRAINING / f\"train_features_cloudless_meta_cv{hparams['cross_validation_split']}.csv\", index=False)\n",
    "        train_y_cloudless = pd.read_csv(DATA_DIR_MODEL_TRAINING / f\"train_labels_cloudless_meta_cv{hparams['cross_validation_split']}.csv\", index=False)\n",
    "\n",
    "        train_y = train_y.append(train_y_cloudless, ignore_index=True)\n",
    "        train_x = train_x.append(train_x_cloudless, ignore_index=True)\n",
    "\n",
    "        df_cloudbank = pd.read_csv(DATA_DIR_MODEL_TRAINING / f\"cloudbank_meta_cv{hparams['cross_validation_split']}.csv\")\n",
    "\n",
    "    if hparams['test_run']:\n",
    "        nuse = hparams['test_run_nchips']\n",
    "\n",
    "        train_x = train_x.iloc[:nuse]\n",
    "        train_y = train_y.iloc[:nuse]\n",
    "\n",
    "        val_x = val_x.iloc[:nuse]\n",
    "        val_x = val_x.iloc[:nuse]\n",
    "\n",
    "        df_cloudbank = df_cloudbank.iloc[:nuse] if df_cloudbank is not None else None\n",
    "        \n",
    "\n",
    "    # Set up models and callbacks\n",
    "    cloud_model = CloudModel(\n",
    "        bands=hparams['bands_use'],\n",
    "        x_train=train_x,\n",
    "        y_train=train_y,\n",
    "        x_val=val_x,\n",
    "        y_val=val_y,\n",
    "        cloudbank=df_cloudbank,\n",
    "        train_transforms=train_transforms,\n",
    "        val_transforms=val_transforms,\n",
    "        hparams=hparams,\n",
    "    )\n",
    "\n",
    "    tb_logger = pl_loggers.TensorBoardLogger(\n",
    "        save_dir=hparams['LOG_DIR'],\n",
    "        name='log',\n",
    "    )\n",
    "\n",
    "    checkpoint_callback = pl.callbacks.ModelCheckpoint(\n",
    "        dirpath=hparams['MODEL_DIR'],\n",
    "        filename='{epoch}-{val_iou_epoch:.2f}',\n",
    "        monitor=\"val_iou_epoch\",\n",
    "        mode=\"max\",\n",
    "        verbose=True,\n",
    "        save_last=True\n",
    "    )\n",
    "\n",
    "    early_stopping_callback = pl.callbacks.early_stopping.EarlyStopping(\n",
    "        monitor=\"val_iou_epoch\",\n",
    "        patience=(cloud_model.patience * 3),\n",
    "        mode=\"max\",\n",
    "        verbose=True,\n",
    "    )\n",
    "\n",
    "    lr_monitor = pl.callbacks.LearningRateMonitor(\n",
    "        logging_interval='epoch'\n",
    "    )\n",
    "\n",
    "    # Train model\n",
    "    # \"ddp_spawn\" needed for interactive jupyter, but best to use \"ddp\" if not\n",
    "    trainer = pl.Trainer(\n",
    "        gpus=-1,\n",
    "        # deterministic=True,\n",
    "        fast_dev_run=False,\n",
    "        # profiler=\"simple\",\n",
    "        # max_epochs=2,\n",
    "        # overfit_batches=1,\n",
    "        # auto_scale_batch_size=True,\n",
    "        check_val_every_n_epoch=1,\n",
    "        num_sanity_val_steps=2,\n",
    "        precision=hparams['precision'],\n",
    "        strategy=hparams['strategy'],\n",
    "        # plugins=DDPSpawnPlugin(find_unused_parameters=False),\n",
    "        callbacks=[checkpoint_callback, early_stopping_callback, lr_monitor],\n",
    "        logger=tb_logger,\n",
    "    )\n",
    "\n",
    "    # Fit the model\n",
    "    trainer.fit(model=cloud_model)\n",
    "    \n",
    "if __name__=='__main__':\n",
    "    \n",
    "    parser = argparse.ArgumentParser(description='runtime parameters')\n",
    "    \n",
    "    # Data and IO\n",
    "    parser.add_argument(\"--bands\", nargs='+' , default=[\"B02\", \"B03\", \"B04\", \"B08\"],\n",
    "                        help=\"bands desired\")\n",
    "    \n",
    "    parser.add_argument(\"--bands_new\", nargs='+', default=None,\n",
    "                        help=\"additional bands to use beyond original four\")\n",
    "    \n",
    "    parser.add_argument(\"-cv\", \"--cross_validation_split\", type=int, default=0,\n",
    "                        help=\"cross validation split to use for training\") \n",
    "\n",
    "    parser.add_argument(\"--OUTPUT_DIR\", type=str, default='../trained_models/',\n",
    "                        help=\"Directory to save logs and trained models model\")\n",
    "                                      \n",
    "    parser.add_argument(\"--LOG_DIR\", type=str, default='logs/',\n",
    "                        help=\"Sub-directory of OUTPUT_DIR to save logs\")\n",
    "    \n",
    "    parser.add_argument(\"--MODEL_DIR\", type=str, default='model/',\n",
    "                        help=\"Sub-directory of OUTPUT_DIR to save logs\")\n",
    "\n",
    "    parser.add_argument(\"--seed\", type=int , default=13579,\n",
    "                        help=\"random seed for train test split\")\n",
    "   \n",
    "    parser.add_argument(\"-v\", \"--verbose\", action=\"store_true\",\n",
    "                        help=\"increase output verbosity\")\n",
    "   \n",
    "\n",
    "\n",
    "    # Training (gpus, optimization, etc...)\n",
    "    parser.add_argument(\"--gpu\", action=\"store_true\",\n",
    "                        help=\"Use GPU\")\n",
    "    \n",
    "    parser.add_argument(\"--strategy\", type=str, default='ddp',\n",
    "                        help=\"Distributed training strategy\")\n",
    "        \n",
    "    parser.add_argument(\"--test_run\", action=\"store_true\",\n",
    "                        help=\"Subsample training and validation data\")\n",
    "    \n",
    "    parser.add_argument(\"--test_run_nchips\", type=int, default=512,\n",
    "                        help=\"Subsample training and validation data to this size\")\n",
    "\n",
    "    parser.add_argument(\"--num_workers\", type=int, default=3,\n",
    "                        help=\"number of data loader workers\")\n",
    "    \n",
    "    parser.add_argument(\"--persistent_workers\", action=\"store_false\",\n",
    "                        help=\"Persistent data loader workers\")\n",
    "    \n",
    "    parser.add_argument(\"--batch_size\", type=int, default=8,\n",
    "                        help=\"Batch size for model training\")\n",
    "    \n",
    "    parser.add_argument(\"--loss_function\", type=str, default='dice',\n",
    "                        help=\"loss_function to use\", choices=['bce', 'Dice'])\n",
    "      \n",
    "    parser.add_argument(\"--learning_rate\", type=float, default=1e-3,\n",
    "                        help=\"Learning rate for model optimization\")\n",
    "  \n",
    "    parser.add_argument(\"--optimizer\", type=str, default='ADAM',\n",
    "                        help=\"Optimizer to use\", choices=['ADAM', 'SGD'])\n",
    "    \n",
    "    parser.add_argument(\"--scheduler\", type=str, default='plateau',\n",
    "                        help=\"Learning rate scheduler to use\", choices=['plateau', 'EXPONENTIAL', 'cosine'])\n",
    "    \n",
    "    parser.add_argument(\"--plot_validation_images\", action=\"store_true\",\n",
    "                        help=\"Plot final batch to tensorboard\")\n",
    "              \n",
    "        \n",
    "    # Models and Augmentations\n",
    "    parser.add_argument(\"--segmentation_model\", type=str, default='unet',\n",
    "                        help=\"Encocoder architecture to use\", choices=['unet', 'DeepLabV3Plus'])\n",
    "  \n",
    "    parser.add_argument(\"--encoder_name\", type=str, default='efficientnet-b0',\n",
    "                        help=\"Encocoder architecture to use\", choices=['efficientnet-b0', 'resnet18', 'resnet34', 'vgg19_bn'])\n",
    "  \n",
    "    parser.add_argument(\"--augmentations\", type=str, default='vfhfrrnr',\n",
    "                        help=\"training augmentations to use\")\n",
    "    \n",
    "    parser.add_argument(\"--cloud_augment\", action=\"store_true\",\n",
    "                        help=\"Use cloud augmentation\")\n",
    "\n",
    "    args = parser.parse_args()\n",
    "    \n",
    "    main(args)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2b5f1c8-e3ee-40a5-9d7d-5530fe9cba67",
   "metadata": {},
   "source": [
    "# Model predict script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1747b6a7-b25f-4e62-ab21-d936c56eb4b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting ../scripts/predict_unet.py\n"
     ]
    }
   ],
   "source": [
    "%%file ../scripts/predict_unet.py\n",
    "\n",
    "import shutil\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pandas_path as path\n",
    "from PIL import Image\n",
    "import torch\n",
    "import pytorch_lightning as pl\n",
    "import glob\n",
    "from pathlib import Path\n",
    "\n",
    "from typing import List\n",
    "# import typer\n",
    "import logging\n",
    "\n",
    "import os\n",
    "import argparse\n",
    "\n",
    "from cloud_seg.models.unet.cloud_model import CloudModel\n",
    "from cloud_seg.models.unet.cloud_model import CloudDataset\n",
    "\n",
    "\n",
    "parser = argparse.ArgumentParser(description='runtime parameters')\n",
    "parser.add_argument(\"--bands\", nargs='+' , default=[\"B02\", \"B03\", \"B04\", \"B08\"],\n",
    "                    help=\"bands desired\")\n",
    "parser.add_argument(\"--bands_new\", nargs='+', default=None,\n",
    "                    help=\"additional bands to use beyond original four\")\n",
    "\n",
    "parser.add_argument(\"-cv\", \"--cross_validation_split\", type=int, default=0,\n",
    "                    help=\"cross validation split to use for training\") \n",
    "\n",
    "parser.add_argument(\"--batch_size\", type=int, default=8,\n",
    "                    help=\"Batch size for model inference\")\n",
    "\n",
    "parser.add_argument(\"--INPUT_DIR\", type=str, default='../trained_models/unet/4band_originaldata_efficientnet-b0_dice__Normalize_VerticalFlip_HorizontalFlip_RandomRotate90/',\n",
    "                    help=\"Directory to save logs and trained models model\")\n",
    "\n",
    "parser.add_argument(\"--LOG_DIR\", type=str, default='logs/',\n",
    "                    help=\"Sub-directory of OUTPUT_DIR to save logs\")\n",
    "\n",
    "parser.add_argument(\"--MODEL_DIR\", type=str, default='model/',\n",
    "                    help=\"Sub-directory of OUTPUT_DIR to save logs\")\n",
    "\n",
    "parser.add_argument(\"--OUTPUT_DIR\", type=str, default='predictions/',\n",
    "                    help=\"Directory to save logs and trained models model\")\n",
    "\n",
    "parser.add_argument(\"--gpu\", action=\"store_true\",\n",
    "                    help=\"Use GPU\")  \n",
    "                    \n",
    "parser.add_argument(\"-v\", \"--verbose\", action=\"store_true\",\n",
    "                    help=\"increase output verbosity\")\n",
    "                    \n",
    "parser.add_argument(\"--local_run\", action=\"store_true\",\n",
    "                    help=\"Whether running locally or on planetary computer\")\n",
    "                    \n",
    "parser.add_argument(\"--model_name\", type=str, default='cloud_model.pt',\n",
    "                    help=\"directory to save trained model\")\n",
    "\n",
    "parser.add_argument(\"--segmentation_model\", type=str, default='unet',\n",
    "                    help=\"Encocoder architecture to use\", choices=['unet', 'DeepLabV3Plus'])\n",
    "  \n",
    "parser.add_argument(\"--encoder_name\", type=str, default='efficientnet-b0',\n",
    "                    help=\"Architecture to use\", choices=['efficientnet-b0', 'resnet34'])\n",
    "\n",
    "parser.add_argument(\"--load_checkpoint\", action=\"store_true\",\n",
    "                    help=\"Whether loading weights from checkpoint (.ckpt) or just from saved weights state_dict (.pt)\")\n",
    "\n",
    "hparams = vars(parser.parse_args())\n",
    "hparams['weights'] = None\n",
    "hparams['bands_use'] = sorted(hparams['bands'] + hparams['bands_new']) if hparams['bands_new'] is not None else hparams['bands']\n",
    "         \n",
    "# hparams['INPUT_DIR'] = os.path.join(hparams['INPUT_DIR'], hparams['segmentation_model'], hparams['model_training_name'])\n",
    "# hparams['MODEL_DIR'] = os.path.join(hparams['INPUT_DIR'], hparams['model_training_name'], hparams['MODEL_DIR'])\n",
    "# hparams['LOG_DIR'] = os.path.join(hparams['INPUT_DIR'], hparams['model_training_name'], hparams['OUTPUT_DIR'], hparams['LOG_DIR'])\n",
    "# hparams['OUTPUT_DIR'] = os.path.join(hparams['INPUT_DIR'], hparams['model_training_name'], hparams['OUTPUT_DIR'])\n",
    "\n",
    "# Path(hparams['LOG_DIR']).mkdir(parents=True, exist_ok=True)\n",
    "# Path(hparams['OUTPUT_DIR']).mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "if hparams['local_run']:      \n",
    "    \n",
    "    ROOT_DIR = Path.cwd().parent.resolve()\n",
    "    ASSETS_DIR = Path(hparams['INPUT_DIR'])\n",
    "    MODEL_PATH = ASSETS_DIR / hparams['MODEL_DIR'] / \"last.ckpt\"\n",
    "                    \n",
    "    PREDICTIONS_DIR = ASSETS_DIR / hparams['OUTPUT_DIR']\n",
    "     \n",
    "    DATA_DIR = ROOT_DIR / \"data/\"\n",
    "    DATA_DIR_MODEL_TRAINING = DATA_DIR / \"model_training/\"\n",
    "    DATA_DIR_CLOUDLESS = DATA_DIR / 'cloudless/tif/'\n",
    "    DATA_DIR_CLOUDS = DATA_DIR / 'clouds/'\n",
    "\n",
    "    INPUT_IMAGES_DIR = DATA_DIR / \"train_features\"\n",
    "    INPUT_IMAGES_DIR_NEW = DATA_DIR / \"train_features_new\"\n",
    "\n",
    "    TRAIN_LABELS = DATA_DIR / \"train_labels\"\n",
    "\n",
    "    band_mean_std = np.load(DATA_DIR / 'measured_band_stats.npy', allow_pickle=True).item()\n",
    "       \n",
    "    logger = logging.getLogger(\"test_logger\")\n",
    "    fh = logging.FileHandler('test_logger.log')\n",
    "    ch = logging.StreamHandler()\n",
    "    \n",
    "    logger.addHandler(fh)\n",
    "    logger.addHandler(ch)\n",
    "\n",
    "    Path(PREDICTIONS_DIR).mkdir(parents=True, exist_ok=True)\n",
    "  \n",
    "else:\n",
    "    ROOT_DIR = Path(\"/codeexecution\")\n",
    "    PREDICTIONS_DIR = ROOT_DIR / \"predictions\"\n",
    "    ASSETS_DIR = ROOT_DIR / \"assets\"\n",
    "                    \n",
    "    DATA_DIR = ROOT_DIR / \"data\"\n",
    "    INPUT_IMAGES_DIR = DATA_DIR / \"test_features\"\n",
    "                    \n",
    "    # Set the pytorch cache directory and include cached models in your submission.zip\n",
    "    os.environ[\"TORCH_HOME\"] = str(ASSETS_DIRECTORY / \"assets/torch\")\n",
    "\n",
    "    MODEL_PATH = ASSETS_DIR / hparams['model_name']            \n",
    "\n",
    "logger = logging.getLogger()\n",
    "\n",
    "def get_metadata(features_dir: os.PathLike, bands: List[str]):\n",
    "    \"\"\"\n",
    "    Given a folder of feature data, return a dataframe where the index is the chip id\n",
    "    and there is a column for the path to each band's TIF image.\n",
    "\n",
    "    Args:\n",
    "        features_dir (os.PathLike): path to the directory of feature data, which should have\n",
    "            a folder for each chip\n",
    "        bands (list[str]): list of bands provided for each chip\n",
    "    \"\"\"\n",
    "    chip_metadata = pd.DataFrame(index=[f\"{band}_path\" for band in bands])\n",
    "    chip_ids = (\n",
    "        pth.name for pth in features_dir.iterdir() if not pth.name.startswith(\".\")\n",
    "    )\n",
    "\n",
    "    for chip_id in sorted(chip_ids):\n",
    "        chip_bands = [features_dir / chip_id / f\"{band}.tif\" for band in bands]\n",
    "        chip_metadata[chip_id] = chip_bands\n",
    "\n",
    "    return chip_metadata.transpose().reset_index().rename(columns={\"index\": \"chip_id\"})\n",
    "\n",
    "\n",
    "def make_predictions(\n",
    "    model: CloudModel,\n",
    "    x_paths: pd.DataFrame,\n",
    "    bands: List[str],\n",
    "    predictions_dir: os.PathLike,\n",
    "):\n",
    "    \"\"\"Predicts cloud cover and saves results to the predictions directory.\n",
    "\n",
    "    Args:\n",
    "        model (CloudModel): an instantiated CloudModel based on pl.LightningModule\n",
    "        x_paths (pd.DataFrame): a dataframe with a row for each chip. There must be a column for chip_id,\n",
    "                and a column with the path to the TIF for each of bands provided\n",
    "        bands (list[str]): list of bands provided for each chip\n",
    "        predictions_dir (os.PathLike): Destination directory to save the predicted TIF masks\n",
    "    \"\"\"\n",
    "    predict_dataset = CloudDataset(\n",
    "        x_paths=x_paths,\n",
    "        bands=bands,\n",
    "    )\n",
    "    predict_dataloader = torch.utils.data.DataLoader(\n",
    "        predict_dataset,\n",
    "        batch_size=model.batch_size,\n",
    "        num_workers=model.num_workers,\n",
    "        shuffle=False,\n",
    "        pin_memory=True,\n",
    "    )\n",
    "    \n",
    "    for batch_index, batch in enumerate(predict_dataloader):\n",
    "        print(\"Running on batch: \", batch_index)\n",
    "        logger.debug(f\"Predicting batch {batch_index} of {len(predict_dataloader)}\")\n",
    "       \n",
    "        x = batch[\"chip\"]\n",
    "        if model.gpu:\n",
    "            x = x.cuda(non_blocking=True)\n",
    "        \n",
    "        preds = model.forward(x)\n",
    "        if not hparams['local_run']:\n",
    "            preds = (preds > 0.5)\n",
    "            \n",
    "        preds = preds.detach()\n",
    "        \n",
    "        if model.gpu:\n",
    "            preds = preds.to(\"cpu\").numpy()\n",
    "        if not hparams['local_run']:\n",
    "            preds = preds.astype(\"uint8\")\n",
    "\n",
    "        for chip_id, pred in zip(batch[\"chip_id\"], preds):\n",
    "            chip_pred_path = predictions_dir / f\"{chip_id}.tif\"\n",
    "            chip_pred_im = Image.fromarray(pred)\n",
    "            chip_pred_im.save(chip_pred_path)\n",
    "\n",
    "\n",
    "def main(\n",
    "    bands: List[str] = [\"B02\", \"B03\", \"B04\", \"B08\"],\n",
    "    fast_dev_run: bool = False,\n",
    "):\n",
    "    \"\"\"\n",
    "    Generate predictions for the chips in features_dir using the model saved at\n",
    "    model_path.\n",
    "\n",
    "    Predictions are saved in predictions_dir. The default paths to all three files are based on\n",
    "    the structure of the code execution runtime.\n",
    "\n",
    "    Args:\n",
    "        model_weights_path (os.PathLike): Path to the weights of a trained CloudModel.\n",
    "        features_dir (os.PathLike, optional): Path to the features for the data. Defaults\n",
    "            to 'data/test_features' in the same directory as main.py\n",
    "        predictions_dir (os.PathLike, optional): Destination directory to save the predicted TIF masks\n",
    "            Defaults to 'predictions' in the same directory as main.py\n",
    "        bands (List[str], optional): List of bands provided for each chip\n",
    "    \"\"\"\n",
    "    if not INPUT_IMAGES_DIR.exists():\n",
    "        raise ValueError(\n",
    "            f\"The directory for feature images must exist and {INPUT_IMAGES_DIR} does not exist\"\n",
    "        )\n",
    "    PREDICTIONS_DIR.mkdir(exist_ok=True, parents=True)\n",
    "\n",
    "    print('RUNNING')\n",
    "    logger.info(\"Loading model\")\n",
    "    print('RUNNING')\n",
    "    \n",
    "    # Load with gpu=False, then put on GPU\n",
    "    hparams['gpu'] = False\n",
    "    model = CloudModel(\n",
    "        bands=hparams['bands_use'],\n",
    "        hparams=hparams\n",
    "    )\n",
    "   \n",
    "    print('Constructed base model')\n",
    "    # load model from disk\n",
    "    if not hparams['load_checkpoint']:\n",
    "        # directly load weights\n",
    "        model.load_state_dict(torch.load(MODEL_PATH))\n",
    "        \n",
    "    if hparams['load_checkpoint']:\n",
    "        # load weights from checkpoint\n",
    "        checkpoint = torch.load(MODEL_PATH)\n",
    "        model.load_state_dict(checkpoint['state_dict'])\n",
    "    print('Loaded model weights')\n",
    "    \n",
    "    hparams['gpu'] = True\n",
    "    if hparams['gpu']:\n",
    "        model = model.cuda()\n",
    "        model.gpu = True\n",
    "\n",
    "             \n",
    "    # Load metadata\n",
    "    logger.info(\"Loading metadata\")\n",
    "    metadata = get_metadata(INPUT_IMAGES_DIR, bands=bands)\n",
    "    if fast_dev_run:\n",
    "        metadata = metadata.head()\n",
    "    logger.info(f\"Found {len(metadata)} chips\")\n",
    "    \n",
    "    \n",
    "    print('Loaded metadata')\n",
    "    # Make predictions and save to disk\n",
    "    logger.info(\"Generating predictions in batches\")\n",
    "    make_predictions(model, metadata, bands, PREDICTIONS_DIR)\n",
    "\n",
    "    logger.info(f\"\"\"Saved {len(list(PREDICTIONS_DIR.glob(\"*.tif\")))} predictions\"\"\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # if hparams['local_run']:              \n",
    "    #     main()\n",
    "    # else:\n",
    "        #typer.run(main)\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "51b867f4-7c47-4574-ae10-b09864c90319",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch\n",
      "global_step\n",
      "pytorch-lightning_version\n",
      "state_dict\n",
      "callbacks\n",
      "optimizer_states\n",
      "lr_schedulers\n",
      "hparams_name\n",
      "hyper_parameters\n",
      "kwargs\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "MODEL_PATH = '../../trained_models/unet/test/epoch=21-val_iou_epoch=0.84.ckpt'\n",
    "checkpoint = torch.load(MODEL_PATH, map_location=torch.device('cpu'))\n",
    "for k, v in checkpoint.items():\n",
    "    print(k)\n",
    "# model.load_state_dict(checkpoint['model'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "27f52214-c423-4af7-87ba-a061e59158a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting ../cloud_seg/models/unet/cloud_dataset.py\n"
     ]
    }
   ],
   "source": [
    "%%file {unet_model_dir}/cloud_dataset.py\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import rasterio\n",
    "import torch\n",
    "from typing import Optional, List\n",
    "import torchvision\n",
    "\n",
    "class CloudDataset(torch.utils.data.Dataset):\n",
    "    \"\"\"Reads in images, transforms pixel values, and serves a\n",
    "    dictionary containing chip ids, image tensors, and\n",
    "    label masks (where available).\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        x_paths: pd.DataFrame,\n",
    "        bands: List[str],\n",
    "        y_paths: Optional[pd.DataFrame] = None,\n",
    "        cloudbank: Optional[pd.DataFrame] = None,\n",
    "        transforms: Optional[list] = None,\n",
    "    ):\n",
    "        \"\"\"\n",
    "        Instantiate the CloudDataset class.\n",
    "\n",
    "        Args:\n",
    "            x_paths (pd.DataFrame): a dataframe with a row for each chip. There must be a column for chip_id,\n",
    "                and a column with the path to the TIF for each of bands\n",
    "            bands (list[str]): list of the bands included in the data\n",
    "            y_paths (pd.DataFrame, optional): a dataframe with a row for each chip and columns for chip_id\n",
    "                and the path to the label TIF with ground truth cloud cover\n",
    "            cloudbank (pd.DataFrame, optional): a dataframe with a row for each cloud chip, columns for chip_id\n",
    "                and the path to the cloud band TIFs and label TIF with ground truth cloud cover.\n",
    "            transforms (list, optional): list of transforms to apply to the feature data (eg augmentations)\n",
    "        \"\"\"\n",
    "        self.data  = x_paths\n",
    "        self.label = y_paths\n",
    "        self.cloudbank = cloudbank\n",
    "        if cloudbank is not None:\n",
    "            self.len_cloudbank = len(cloudbank)\n",
    "        \n",
    "        self.transforms = transforms\n",
    "        self.bands = bands\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx: int):\n",
    "        # Loads an n-channel image from a chip-level dataframe\n",
    "        img = self.data.loc[idx]\n",
    "        band_arrs = []\n",
    "        for band in self.bands:\n",
    "            with rasterio.open(img[f\"{band}_path\"]) as b:\n",
    "                band_arr = b.read(1).astype(\"float32\")\n",
    "            band_arrs.append(band_arr)\n",
    "            \n",
    "        x_arr = np.stack(band_arrs, axis=-1) # images in (B, H, W, C)\n",
    "\n",
    "        # Load label if available\n",
    "        if self.label is not None:\n",
    "            label_path = self.label.loc[idx].label_path\n",
    "            if label_path != 'None':\n",
    "                with rasterio.open(label_path) as lp:\n",
    "                    y_arr = lp.read(1).astype(\"float32\")\n",
    "            else:\n",
    "                # This is a cloudless image, so sample a random cloud chip from cloudbank\n",
    "                # load in new cloud label, and add cloud band data to x_arr bands\n",
    "                idx_cloud = np.random.randint(0, self.len_cloudbank)\n",
    "                cloud_paths = self.cloudbank.loc[idx_cloud]\n",
    "                \n",
    "                # load label\n",
    "                with rasterio.open(cloud_paths.label_path) as lp:\n",
    "                    y_arr = lp.read(1).astype(\"float32\")  \n",
    "                    \n",
    "                # load cloud bands\n",
    "                band_arrs = []\n",
    "                for band in self.bands:\n",
    "                    with rasterio.open(cloud_paths[f\"{band}_path\"]) as b:\n",
    "                        band_arr = b.read(1).astype(\"float32\")\n",
    "                    band_arrs.append(band_arr)\n",
    "                    \n",
    "                # add clouds to cloudless image\n",
    "                x_arr += np.stack(band_arrs, axis=-1)\n",
    "\n",
    "        # Prepare dictionary for item\n",
    "        item = {}\n",
    "        item[\"chip_id\"] = img.chip_id\n",
    "        \n",
    "        # Apply data augmentations, if provided\n",
    "        if self.label is not None:\n",
    "            # Apply same data augmentations to the label\n",
    "            if self.transforms:\n",
    "                transformed = self.transforms(image=x_arr, mask=y_arr)\n",
    "                x_arr = transformed[\"image\"]\n",
    "                y_arr = transformed[\"mask\"]\n",
    "                \n",
    "            item[\"label\"] = y_arr\n",
    "        if self.label is None:\n",
    "            if self.transforms:\n",
    "                x_arr = self.transforms(image=x_arr)[\"image\"]\n",
    "                \n",
    "        x_arr = np.transpose(x_arr, [2, 0, 1]) # put images in (B, C, H, W)\n",
    "\n",
    "        item[\"chip\"] = x_arr\n",
    "        \n",
    "        return item"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "919ac2db-5a78-46be-a4a9-3106e694adeb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting ../cloud_seg/models/unet/losses.py\n"
     ]
    }
   ],
   "source": [
    "%%file {unet_model_dir}/losses.py\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "from typing import Sequence, Optional, Union\n",
    "\n",
    "def intersection_and_union(pred, true):\n",
    "    \"\"\"\n",
    "    Calculates intersection and union for a batch of images.\n",
    "\n",
    "    Args:\n",
    "        pred (torch.Tensor): a tensor of predictions\n",
    "        true (torc.Tensor): a tensor of labels\n",
    "\n",
    "    Returns:\n",
    "        intersection (int): total intersection of pixels\n",
    "        union (int): total union of pixels\n",
    "    \"\"\"\n",
    "    # valid_pixel_mask = true.ne(255)  # valid pixel mask\n",
    "    # true = true.masked_select(valid_pixel_mask).to(\"cpu\")\n",
    "    # pred = pred.masked_select(valid_pixel_mask).to(\"cpu\")\n",
    "\n",
    "    # Intersection and union totals\n",
    "    pred_flattened = pred.view(-1)\n",
    "    true_flattened = true.view(-1)\n",
    "\n",
    "    intersection = torch.logical_and(true_flattened, pred_flattened)\n",
    "    union = torch.logical_or(true_flattened, pred_flattened)\n",
    "    \n",
    "    return torch.sum(intersection).float(), torch.sum(union).float()#, torch.sum(intersection) / torch.sum(union)\n",
    "\n",
    "def dice_loss(pred, true, dice_smooth=1.):\n",
    "    \n",
    "    pred_flattened = pred.view(-1)\n",
    "    true_flattened = true.view(-1)\n",
    "\n",
    "    intersection = (pred_flattened * true_flattened).sum()\n",
    "    \n",
    "    return 1 - ((2. * intersection + dice_smooth) /\n",
    "              (pred_flattened.sum() + true_flattened.sum() + dice_smooth))\n",
    "\n",
    "class DiceLoss(torch.nn.Module):\n",
    "    def __init__(self, weight=None, size_average=True):\n",
    "        super(DiceLoss, self).__init__()\n",
    "\n",
    "    def forward(self, inputs, targets, smooth=1):\n",
    "                \n",
    "        #flatten label and prediction tensors\n",
    "        inputs = inputs.view(-1)\n",
    "        targets = targets.view(-1)\n",
    "        \n",
    "        intersection = (inputs * targets).sum()                            \n",
    "        dice = (2.*intersection + smooth)/(inputs.sum() + targets.sum() + smooth)  \n",
    "        \n",
    "        return 1 - dice\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7cfeb53a-c77b-495d-b996-9be1b42bd1e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting ../cloud_seg/models/unet/metrics.py\n"
     ]
    }
   ],
   "source": [
    "%%file {unet_model_dir}/metrics.py\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import torchmetrics\n",
    "\n",
    "class Intersection(torchmetrics.Metric):\n",
    "    def __init__(self, dist_sync_on_step=False):\n",
    "        super().__init__(dist_sync_on_step=dist_sync_on_step)\n",
    "\n",
    "        self.add_state(\"intersection\", default=torch.tensor(0), dist_reduce_fx=\"sum\")\n",
    "        self.add_state(\"total\", default=torch.tensor(0), dist_reduce_fx=\"sum\")\n",
    "\n",
    "    def update(self, preds: torch.Tensor, target: torch.Tensor):\n",
    "        preds, target = self._input_format(preds, target)\n",
    "        assert preds.shape == target.shape\n",
    "\n",
    "        self.intersection += torch.logical_and(preds.view(-1), target.view(-1))\n",
    "        # self.correct += torch.sum(preds == target)\n",
    "        # self.total += target.numel()\n",
    "\n",
    "    def compute(self):\n",
    "        return self.intersection.float()\n",
    "        # return self.correct.float() / self.total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "25dae48a-620e-4621-9649-5b8aa40b0443",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting ../cloud_seg/models/unet/callbacks.py\n"
     ]
    }
   ],
   "source": [
    "%%file {unet_model_dir}/callbacks.py\n",
    "\n",
    "# Adapted from https://github.com/PyTorchLightning/Lightning-Bolts/blob/master/pl_bolts/callbacks/vision/confused_logit.py#L20-L167\n",
    "from typing import Sequence\n",
    "\n",
    "import torch\n",
    "from pytorch_lightning import Callback, LightningModule, Trainer\n",
    "from torch import Tensor, nn\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "from matplotlib.axes import Axes\n",
    "from matplotlib.figure import Figure\n",
    "\n",
    "# from pytorch_lightning.utilities import rank_zero_only\n",
    "# @rank_zero_only\n",
    "class DisplayChipsCallback(Callback):  # pragma: no cover\n",
    "    \"\"\"Takes the input chip, true label, and label prediction\n",
    "        trainer = Trainer(callbacks=[DisplayChips()])\n",
    "    .. note:: Whenever called, this model will look for ``self.last_batch`` and ``self.last_logits``\n",
    "              in the LightningModule.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        num_images_plot: int=4,\n",
    "    ):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            top_k: How many  images we should plot\n",
    "   \n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        self.num_images_plot = num_images_plot\n",
    "\n",
    "    def on_validation_epoch_end(\n",
    "        self,\n",
    "        trainer: Trainer,\n",
    "        pl_module: LightningModule,\n",
    "        # outputs: Sequence,\n",
    "        # batch: Sequence,\n",
    "        # batch_idx: int,\n",
    "        # dataloader_idx: int,\n",
    "    ) -> None:\n",
    "        # show images only every 20 batches\n",
    "        # if batch_idx != 0:\n",
    "        #     return\n",
    "\n",
    "        # pick the last batch and logits\n",
    "        # x, y = batch[\"chip\"], batch[\"label\"]\n",
    "        try:\n",
    "            x = pl_module.last_x.to(\"cpu\")\n",
    "            y = pl_module.last_y.to(\"cpu\")\n",
    "            pred = pl_module.last_pred.to(\"cpu\")\n",
    "            \n",
    "        except AttributeError as err:\n",
    "            m = \"\"\"please track the last_pred in the validation_step like so:\n",
    "                def validation_step(...):\n",
    "                    self.last_pred = your_pred\n",
    "            \"\"\"\n",
    "            raise AttributeError(m) from err\n",
    "\n",
    "        print(pred)\n",
    "        self._plot(x, y, pred, trainer, pl_module)\n",
    "\n",
    "    def _plot(\n",
    "        self,\n",
    "        x: Tensor,\n",
    "        y: Tensor,\n",
    "        pred: Tensor,\n",
    "        trainer: Trainer,\n",
    "        model: LightningModule,\n",
    "    ) -> None:\n",
    "\n",
    "        batch_size, c, w, h = x.size()\n",
    "\n",
    "        # final batch may not be full size\n",
    "        nimg_plt = self.min(batch_size, self.num_images_plot)\n",
    "        \n",
    "        fig, axarr = plt.subplots(nrows=nimg_plt, ncols=3, figsize=(15, 5*))\n",
    "       \n",
    "        for img_i in range(nimg_plt):\n",
    "            xi = x[img_i].to(\"cpu\")\n",
    "            yi = y[img_i].to(\"cpu\")\n",
    "            predi = pred[img_i].to(\"cpu\")\n",
    "            \n",
    "            self.__draw_data_sample(fig, axarr, img_i, 0, xi[0], \"Chip\")\n",
    "            self.__draw_label_sample(fig, axarr, img_i, 1, yi, \"True label\")\n",
    "            self.__draw_label_sample(fig, axarr, img_i, 2, predi, \"Prediction\")\n",
    "            \n",
    "        # model.logger.experiment.add_figure(\"validation_predictions\", fig, global_step=trainer.global_step)\n",
    "        # trainer.logger.experiment[0].add_image(\"validation_predictions\", fig, global_step=trainer.global_step)\n",
    "        # model.log(\"validation_predictions\", fig, global_step=trainer.global_step)\n",
    "\n",
    "    @staticmethod\n",
    "    def __draw_data_sample(fig: Figure, axarr: Axes, row_idx: int, col_idx: int, img: Tensor, title: str) -> None:\n",
    "        im = axarr[row_idx, col_idx].imshow(img)\n",
    "        axarr[row_idx, col_idx].set_title(title, fontsize=20)\n",
    "        \n",
    "    @staticmethod\n",
    "    def __draw_label_sample(fig: Figure, axarr: Axes, row_idx: int, col_idx: int, img: Tensor, title: str) -> None:\n",
    "        im = axarr[row_idx, col_idx].imshow(img, vmin=0., vmax=1.)\n",
    "        axarr[row_idx, col_idx].set_title(title, fontsize=20)\n",
    "        \n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "80fab01d-4d82-436a-b219-41913e5357a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting ../cloud_seg/models/unet/plotting_tools.py\n"
     ]
    }
   ],
   "source": [
    "%%file {unet_model_dir}/plotting_tools.py\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch import Tensor\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "import xarray\n",
    "import xrspatial.multispectral as ms\n",
    "\n",
    "# from pytorch_lightning.utilities import rank_zero_only\n",
    "# @rank_zero_only\n",
    "\n",
    "def to_xarray(im_arr):\n",
    "    \"\"\"Put images in xarray.DataArray format\"\"\"\n",
    "\n",
    "    return xarray.DataArray(im_arr, dims=[\"y\", \"x\"])\n",
    "\n",
    "def true_color_img(img, normalized=True):\n",
    "    \"\"\"Given the path to the directory of Sentinel-2 chip feature images,\n",
    "    plots the true color image\"\"\"\n",
    "    \n",
    "    band_mean_std = {'B02': {'mean': 2848.064112016446,\n",
    "    'std': 3156.9268464765087,\n",
    "    'min': 0,\n",
    "    'max': 27600},\n",
    "    'B03': {'mean': 2839.0871485290295,\n",
    "    'std': 2899.280144509762,\n",
    "    'min': 0,\n",
    "    'max': 26096},\n",
    "    'B04': {'mean': 2741.2891076425326,\n",
    "    'std': 2789.961608891907,\n",
    "    'min': 0,\n",
    "    'max': 23104},\n",
    "    'B08': {'mean': 3657.9092112857143,\n",
    "    'std': 2424.18942846055,\n",
    "    'min': 0,\n",
    "    'max': 19568}}\n",
    "\n",
    "    if normalized:\n",
    "        img[2] = img[2]*band_mean_std['B04']['std'] + band_mean_std['B04']['mean']\n",
    "        img[1] = img[1]*band_mean_std['B03']['std'] + band_mean_std['B03']['mean']\n",
    "        img[0] = img[0]*band_mean_std['B02']['std'] + band_mean_std['B02']['mean']\n",
    "        \n",
    "    red = to_xarray(img[2])\n",
    "    green = to_xarray(img[1])\n",
    "    blue = to_xarray(img[0])\n",
    "    \n",
    "    return ms.true_color(r=red, g=green, b=blue)\n",
    "\n",
    "def plot_prediction_grid(x: Tensor, y: Tensor, pred: Tensor, chip_id, num_images_plot: int = 4, fontsize=18):\n",
    "\n",
    "        batch_size, c, w, h = x.size()\n",
    "        \n",
    "        nimg_plt = min(batch_size, num_images_plot)\n",
    "\n",
    "        fig, axarr = plt.subplots(nrows=nimg_plt, ncols=3, figsize=(15, 5*nimg_plt))\n",
    "       \n",
    "        for img_i in range(nimg_plt):\n",
    "            \n",
    "            chip_idi = chip_id[img_i]\n",
    "            xi = true_color_img(x[img_i].to(\"cpu\").numpy().astype(np.float32), normalized=True)\n",
    "            yi = y[img_i].to(\"cpu\")\n",
    "            predi = pred[img_i].to(\"cpu\")\n",
    "            \n",
    "            axarr[img_i, 0].imshow(xi)\n",
    "            axarr[img_i, 0].set_title(f\"{chip_idi}\", fontsize=fontsize)\n",
    "            \n",
    "            axarr[img_i, 1].imshow(yi, vmin=0., vmax=1.)\n",
    "            axarr[img_i, 1].set_title(\"True label\", fontsize=fontsize)\n",
    "            \n",
    "            axarr[img_i, 2].imshow(predi, vmin=0., vmax=1.)\n",
    "            axarr[img_i, 2].set_title(\"Prediction\", fontsize=fontsize)\n",
    "            \n",
    "        plt.close(fig)\n",
    "        \n",
    "        return fig\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "ded66935-219f-435c-af56-0be0315dd518",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting ../cloud_seg/models/unet/cloud_model.py\n"
     ]
    }
   ],
   "source": [
    "%%file {unet_model_dir}/cloud_model.py\n",
    "\n",
    "from typing import Optional, List\n",
    "\n",
    "import pandas as pd\n",
    "import pytorch_lightning as pl\n",
    "import segmentation_models_pytorch as smp\n",
    "import torch\n",
    "import torchmetrics\n",
    "# from pytorch_lightning.utilities import rank_zero_only\n",
    "# from pytorch_lightning.loggers.base import rank_zero_experiment\n",
    "\n",
    "from .cloud_dataset import CloudDataset\n",
    "from .losses import intersection_and_union\n",
    "from .losses import dice_loss\n",
    "from .plotting_tools import plot_prediction_grid\n",
    "\n",
    "\n",
    "class CloudModel(pl.LightningModule):\n",
    "    def __init__(\n",
    "        self,\n",
    "        bands: List[str],\n",
    "        x_train: Optional[pd.DataFrame] = None,\n",
    "        y_train: Optional[pd.DataFrame] = None,\n",
    "        x_val: Optional[pd.DataFrame] = None,\n",
    "        y_val: Optional[pd.DataFrame] = None,\n",
    "        cloudbank: Optional[pd.DataFrame] = None,\n",
    "        train_transforms = None,\n",
    "        val_transforms = None,\n",
    "        hparams: dict = {},\n",
    "    ):\n",
    "        \"\"\"\n",
    "        Instantiate the CloudModel class based on the pl.LightningModule\n",
    "        (https://pytorch-lightning.readthedocs.io/en/latest/common/lightning_module.html).\n",
    "\n",
    "        Args:\n",
    "            bands (list[str]): Names of the bands provided for each chip\n",
    "            x_train (pd.DataFrame, optional): a dataframe of the training features with a row for each chip.\n",
    "                There must be a column for chip_id, and a column with the path to the TIF for each of bands.\n",
    "                Required for model training\n",
    "            y_train (pd.DataFrame, optional): a dataframe of the training labels with a for each chip\n",
    "                and columns for chip_id and the path to the label TIF with ground truth cloud cover.\n",
    "                Required for model training\n",
    "            x_val (pd.DataFrame, optional): a dataframe of the validation features with a row for each chip.\n",
    "                There must be a column for chip_id, and a column with the path to the TIF for each of bands.\n",
    "                Required for model training\n",
    "            y_val (pd.DataFrame, optional): a dataframe of the validation labels with a for each chip\n",
    "                and columns for chip_id and the path to the label TIF with ground truth cloud cover.\n",
    "                Required for model training\n",
    "            cloudbank (pd.DataFrame, optional): a dataframe of paths to additional clouds to sample from. \n",
    "                Optional for model training, but required if using chips where label_path=='None'\n",
    "            hparams (dict, optional): Dictionary of additional modeling parameters.\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        self.hparams.update(hparams)\n",
    "        self.save_hyperparameters()\n",
    "\n",
    "        # required\n",
    "        self.bands = bands\n",
    "        self.num_channels = len(bands)\n",
    "        \n",
    "        # optional modeling params\n",
    "        self.segmentation_model = self.hparams.get(\"segmentation_model\", \"unet\")\n",
    "        self.encoder_name = self.hparams.get(\"encoder_name\", \"efficientnet-b0\")\n",
    "        self.weights = self.hparams.get(\"weights\", None)\n",
    "        \n",
    "        self.loss_function = self.hparams.get(\"loss_function\", \"dice\")        \n",
    "        self.optimizer = self.hparams.get(\"optimizer\", \"ADAM\")\n",
    "        self.scheduler = self.hparams.get(\"scheduler\", \"PLATEAU\")\n",
    "        \n",
    "        self.learning_rate = self.hparams.get(\"learning_rate\", 1e-3)\n",
    "        self.momentum = self.hparams.get(\"momentum\", 0.9)\n",
    "        self.T_0 = self.hparams.get(\"T_0\", 10)\n",
    "        self.eta_min = self.hparams.get(\"eta_min\", 1e-5)\n",
    "      \n",
    "        self.reduce_learning_rate_factor = self.hparams.get(\"reduce_learning_rate_factor\", 0.1)\n",
    "\n",
    "        self.patience = self.hparams.get(\"patience\", 5)\n",
    "        self.learning_rate_patience = self.hparams.get(\"learning_rate_patience\", 5)\n",
    "        self.batch_size = self.hparams.get(\"batch_size\", 8)\n",
    "\n",
    "        self.num_workers = self.hparams.get(\"num_workers\", 2)\n",
    "        self.pin_memory = self.hparams.get(\"pin_memory\", True)\n",
    "        self.persistent_workers = self.hparams.get(\"persistent_workers\", False)\n",
    "        \n",
    "        self.gpu = self.hparams.get(\"gpu\", False)\n",
    "        \n",
    "        self.log_on_step = self.hparams.get(\"log_on_step\", False)\n",
    "        self.progress_bar = self.hparams.get(\"progress_bar\", False)\n",
    "        \n",
    "        self.plot_validation_images = self.hparams.get(\"plot_validation_images\", True)\n",
    "        self.num_images_plot = self.hparams.get(\"num_images_plot\", self.batch_size)\n",
    "\n",
    "        self.train_transform = train_transforms\n",
    "        self.val_transform = val_transforms\n",
    "\n",
    "        # Instantiate datasets, model, and trainer params if provided\n",
    "        self.train_dataset = CloudDataset(\n",
    "            x_paths=x_train,\n",
    "            bands=self.bands,\n",
    "            y_paths=y_train,\n",
    "            cloudbank=cloudbank,\n",
    "            transforms=self.train_transform,\n",
    "        )\n",
    "        self.val_dataset = CloudDataset(\n",
    "            x_paths=x_val,\n",
    "            bands=self.bands,\n",
    "            y_paths=y_val,\n",
    "            transforms=self.val_transform,\n",
    "        )\n",
    "        \n",
    "        # define some performance metrics using torchmetrics\n",
    "        # self.train_accuracy = torchmetrics.Accuracy()\n",
    "        # self.val_intersection = mymetrics.Intersection()\n",
    "        self.val_IoU = torchmetrics.IoU(num_classes=2)\n",
    "        self.train_IoU = torchmetrics.IoU(num_classes=2)\n",
    "\n",
    "        self.model = self._prepare_model()\n",
    "\n",
    "    ## Required LightningModule methods ##\n",
    "    def forward(self, image: torch.Tensor):\n",
    "        # Forward pass\n",
    "        # output of model is (B, 1, H, W), so remove axis=1\n",
    "        if self.loss_function == \"BCE\":\n",
    "            # return raw logits in order to use BCEWithLogitsLoss\n",
    "            # which is more stable than BCE:\n",
    "            # https://pytorch.org/docs/stable/generated/torch.nn.BCEWithLogitsLoss.html#torch.nn.BCEWithLogitsLoss\n",
    "            return self.model(image).view(-1, 512, 512)\n",
    "        \n",
    "        else:\n",
    "            return torch.sigmoid(self.model(image).view(-1, 512, 512))\n",
    "            \n",
    "\n",
    "    def calculate_loss(self, chip, label, preds):\n",
    "        if self.loss_function.upper()==\"BCE\":\n",
    "            loss = torch.nn.BCEWithLogitsLoss(reduction=\"none\")(preds, label.float()).mean()\n",
    "            \n",
    "        if self.loss_function.upper()==\"DICE\":\n",
    "            loss = dice_loss(preds, label)\n",
    "\n",
    "            # loss = DiceLoss()(preds, label)\n",
    "            # loss = smp.losses.JaccardLoss()(preds, label)\n",
    "        #if self.loss_function.upper()==\"IOU\":\n",
    "        #     loss = torchmetrics.IoU(num_classes=2)(preds, label)\n",
    "\n",
    "        return loss\n",
    "\n",
    "    def training_step(self, batch: dict, batch_idx: int):\n",
    "        \"\"\"\n",
    "        Training step.\n",
    "\n",
    "        Args:\n",
    "            batch (dict): dictionary of items from CloudDataset of the form\n",
    "                {'chip_id': list[str], 'chip': list[torch.Tensor], 'label': list[torch.Tensor]}\n",
    "            batch_idx (int): batch number\n",
    "        \"\"\"\n",
    "        if self.train_dataset.data is None:\n",
    "            raise ValueError(\n",
    "                \"x_train and y_train must be specified when CloudModel is instantiated to run training\"\n",
    "            )\n",
    "\n",
    "        # Switch on training mode\n",
    "        self.model.train()\n",
    "        torch.set_grad_enabled(True)\n",
    "\n",
    "        # Load images and labels\n",
    "        x = batch[\"chip\"]\n",
    "        y = batch[\"label\"].long()\n",
    "        if self.gpu:\n",
    "            x, y = x.cuda(non_blocking=True), y.cuda(non_blocking=True)\n",
    "\n",
    "        # Forward pass\n",
    "        preds = self.forward(x)\n",
    "\n",
    "        loss = self.calculate_loss(x, y, preds)\n",
    "\n",
    "        if self.loss_function == \"BCE\":\n",
    "            preds = torch.sigmoid(preds)\n",
    "            \n",
    "        \n",
    "        preds = (preds > 0.5) * 1  # convert to int\n",
    "\n",
    "        # batch_intersection, batch_union = intersection_and_union(preds, y)\n",
    "    \n",
    "        self.train_IoU(preds, y)\n",
    "\n",
    "        self.log(\n",
    "            \"train_performance\", \n",
    "            {\"iou\": self.train_IoU},\n",
    "            on_step=self.log_on_step,\n",
    "            on_epoch=True,\n",
    "            prog_bar=self.progress_bar,\n",
    "        )\n",
    "        self.log(\n",
    "            \"train_loss\",\n",
    "            loss,\n",
    "            on_step=self.log_on_step,\n",
    "            on_epoch=True,\n",
    "            prog_bar=self.progress_bar,\n",
    "        )\n",
    "\n",
    "        return loss\n",
    "\n",
    "    def validation_step(self, batch: dict, batch_idx: int):\n",
    "        \"\"\"\n",
    "        Validation step.\n",
    "\n",
    "        Args:\n",
    "            batch (dict): dictionary of items from CloudDataset of the form\n",
    "                {'chip_id': list[str], 'chip': list[torch.Tensor], 'label': list[torch.Tensor]}\n",
    "            batch_idx (int): batch number\n",
    "        \"\"\"\n",
    "        if self.val_dataset.data is None:\n",
    "            raise ValueError(\n",
    "                \"x_val and y_val must be specified when CloudModel is instantiated to run validation\"\n",
    "            )\n",
    "\n",
    "        # Switch on validation mode\n",
    "        self.model.eval()\n",
    "        torch.set_grad_enabled(False)\n",
    "\n",
    "        # Load images and labels\n",
    "        x = batch[\"chip\"]\n",
    "        y = batch[\"label\"].long()\n",
    "        chip_id = batch[\"chip_id\"]\n",
    "        if self.gpu:\n",
    "            x, y = x.cuda(non_blocking=True), y.cuda(non_blocking=True)\n",
    "\n",
    "        preds = self.forward(x)\n",
    "\n",
    "        loss = self.calculate_loss(x, y, preds)\n",
    "\n",
    "        if self.loss_function == \"BCE\":\n",
    "            preds = torch.sigmoid(preds)\n",
    "            \n",
    "        preds = (preds > 0.5) * 1  # convert to int\n",
    "\n",
    "        if self.plot_validation_images:\n",
    "            # keep to pass to validation_epoch_end and plot\n",
    "            self.last_x = x\n",
    "            self.last_y = y\n",
    "            self.last_pred = preds\n",
    "            self.last_chip_id = chip_id\n",
    "\n",
    "        # Log batch IOU\n",
    "        batch_intersection, batch_union = intersection_and_union(preds, y)\n",
    "        self.val_IoU(preds, y)\n",
    "\n",
    "        self.log(\"val_performance\", \n",
    "                 {\"iou\": self.val_IoU},\n",
    "                 on_step=self.log_on_step, on_epoch=True, prog_bar=self.progress_bar)\n",
    "                 \n",
    "        self.log(\"val_loss\", loss, on_step=self.log_on_step, on_epoch=True, prog_bar=self.progress_bar)\n",
    "        \n",
    "        # keep seperate to use for early stopping\n",
    "        self.log(\"val_iou\", self.val_IoU, on_step=True, on_epoch=True, prog_bar=self.progress_bar)\n",
    "\n",
    "        return {\"loss\": loss}#, \"x\": x, \"y\": y, \"pred\": preds}\n",
    "\n",
    "#     def validation_step_end(self, batch_parts):\n",
    "#         gpu_use = 0\n",
    "#         # print(batch_parts['x'][gpu_use].size())\n",
    "#         return {\"x\": batch_parts[\"x\"][gpu_use], \"y\": batch_parts[\"y\"][gpu_use], \"pred\": batch_parts[\"pred\"][gpu_use]}\n",
    "\n",
    "    # @rank_zero_only\n",
    "    # @rank_zero_experiment\n",
    "    \n",
    "    def validation_epoch_end(self, outputs):\n",
    "        # idevice = self.last_x.get_device()\n",
    "        # if idevice == 0:\n",
    "        # if self.global_rank==0:\n",
    "        if self.plot_validation_images:\n",
    "            # self.logger[0].experiment.add_figure(\"chip_label_prediction\", \n",
    "            self.logger.experiment.add_figure(\"chip_label_prediction\", \n",
    "                                                 plot_prediction_grid(self.last_x,\n",
    "                                                                      self.last_y,\n",
    "                                                                      self.last_pred,\n",
    "                                                                      self.last_chip_id,\n",
    "                                                                      num_images_plot=self.num_images_plot),\n",
    "                                                 self.current_epoch)\n",
    "\n",
    "        # if batch_idx == 0:\n",
    "            # print(out)\n",
    "            # for out in validation_step_outputs[:1]:\n",
    "            #     # output from each gpu\n",
    "            #     print(out)\n",
    "            \n",
    "    def train_dataloader(self):\n",
    "        # DataLoader class for training\n",
    "        return torch.utils.data.DataLoader(\n",
    "            self.train_dataset,\n",
    "            batch_size=self.batch_size|self.hparams.batch_size,\n",
    "            num_workers=self.num_workers,\n",
    "            shuffle=True,\n",
    "            pin_memory=self.pin_memory,\n",
    "            persistent_workers=self.persistent_workers,\n",
    "        )\n",
    "\n",
    "    def val_dataloader(self):\n",
    "        # DataLoader class for validation\n",
    "        return torch.utils.data.DataLoader(\n",
    "            self.val_dataset,\n",
    "            batch_size=self.batch_size,\n",
    "            num_workers=self.num_workers,\n",
    "            shuffle=False,\n",
    "            drop_last=self.plot_validation_images, # if plotting last batch images ensure full last batch\n",
    "            pin_memory=self.pin_memory,\n",
    "            persistent_workers=self.persistent_workers,\n",
    "        )\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        \n",
    "        if self.optimizer.upper()==\"ADAM\":\n",
    "            optimizer = torch.optim.Adam(\n",
    "                self.model.parameters(),\n",
    "                lr=self.learning_rate,\n",
    "            )\n",
    "            \n",
    "        if self.optimizer.upper()==\"ADAMW\":\n",
    "            optimizer = torch.optim.AdamW(\n",
    "                self.model.parameters(),\n",
    "                lr=self.learning_rate,\n",
    "            )\n",
    "            # sch = torch.optim.lr_scheduler.CosineAnnealingLR(opt, T_max=10)\n",
    "\n",
    "        if self.optimizer.upper()==\"SGD\":\n",
    "            optimizer = torch.optim.SGD(\n",
    "                self.model.parameters(),\n",
    "                lr=self.learning_rate,\n",
    "                momentum=self.momentum,\n",
    "            )\n",
    "        \n",
    "        if self.scheduler.upper()==\"EXPONENTIAL\":\n",
    "            scheduler = torch.optim.lr_scheduler.ExponentialLR(\n",
    "                optimizer,\n",
    "                gamma=0.95,\n",
    "            )\n",
    "            \n",
    "        if self.scheduler.upper()==\"COSINE\":\n",
    "            scheduler = torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(\n",
    "                optimizer,\n",
    "                T_0=self.T_0,\n",
    "                eta_min=self.eta_min,\n",
    "            ) \n",
    "  \n",
    "        if self.scheduler.upper()==\"PLATEAU\":\n",
    "            scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(\n",
    "                optimizer,\n",
    "                'max',\n",
    "                factor=self.reduce_learning_rate_factor,\n",
    "                patience=self.learning_rate_patience,\n",
    "            )\n",
    "            \n",
    "            return {\"optimizer\": optimizer, \n",
    "                    \"lr_scheduler\": {\n",
    "                        \"scheduler\": scheduler,\n",
    "                        \"monitor\": \"val_iou\",\n",
    "                    },\n",
    "            }\n",
    "                                       \n",
    "        return [optimizer], [scheduler]\n",
    "                \n",
    "    ## Convenience Methods ##\n",
    "    def _prepare_model(self):\n",
    "        \n",
    "        if self.segmentation_model.upper()==\"UNET\":\n",
    "            # Instantiate U-Net model\n",
    "            unet_model = smp.Unet(\n",
    "                encoder_name=self.encoder_name,\n",
    "                encoder_weights=self.weights,\n",
    "                in_channels=self.num_channels,\n",
    "                classes=1,\n",
    "            )\n",
    "            if self.gpu:\n",
    "                unet_model.cuda()\n",
    "                \n",
    "        if self.segmentation_model.upper()==\"DEEPLABV3PLUS\":\n",
    "            # Instantiate DeepLabV3Plus model (https://arxiv.org/abs/1802.02611v3)\n",
    "            unet_model = smp.DeepLabV3Plus(\n",
    "                encoder_name=self.encoder_name,\n",
    "                encoder_weights=self.weights,\n",
    "                in_channels=self.num_channels,\n",
    "                classes=1,\n",
    "            )\n",
    "            if self.gpu:\n",
    "                unet_model.cuda()\n",
    "\n",
    "        return unet_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab78b2f3-8eb6-4c81-9e1f-80402e0f98ca",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbaf9947-5324-479f-abd4-cfc29c556a4e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d8da26b9-408f-4227-9d29-cc52e0604e21",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'cloud_model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_20946/1422955332.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mmodel_weight_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msubmission_assets_dir\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;34m\"cloud_model.pt\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcloud_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_weight_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'cloud_model' is not defined"
     ]
    }
   ],
   "source": [
    "# save the model\n",
    "submission_assets_dir = submission_dir / \"assets\"\n",
    "submission_assets_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "model_weight_path = submission_assets_dir / \"cloud_model.pt\"\n",
    "torch.save(cloud_model.state_dict(), model_weight_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "5995f904-7e4b-45f8-abd0-22960e22791a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "benchmark_src\n",
      "├── __pycache__\n",
      "│   └── main.cpython-38.pyc\n",
      "└── main.py\n",
      "\n",
      "1 directory, 2 files\n"
     ]
    }
   ],
   "source": [
    "!tree benchmark_src\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f74855c-3bb6-4ad4-8780-629800b79ebf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Zip submission\n",
    "!cd unet_src && zip -r ../submission.zip *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "1c0d7d79-817b-4261-86bf-dbdee7bd764c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "84M\tsubmission.zip\n"
     ]
    }
   ],
   "source": [
    "!du -h submission.zip\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea250baf-494f-4c8e-9698-91f1c27f6bfe",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "CloudCover",
   "language": "python",
   "name": "cloud_cover"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
