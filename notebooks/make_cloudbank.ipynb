{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "24195ab3-3987-4275-8688-f08fc6fc378c",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "from pathlib import Path\n",
    "\n",
    "import os\n",
    "os.environ['OPENBLAS_NUM_THREADS'] = '1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2d028de9-a9fe-4794-8a83-33b5a44a5a54",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting ../scripts/make_cloudbank.py\n"
     ]
    }
   ],
   "source": [
    "%%file ../scripts/make_cloudbank.py\n",
    "\"\"\"\n",
    "Script to:\n",
    "\n",
    "1.) extract clouds from pairs of cloudy/cloudless images.\n",
    "    use flag --extract_clouds\n",
    "    \n",
    "2.) Make folder full of cloudless .tif chips from .npz arrays.\n",
    "    use flag --save_cloudless_as_tif\n",
    "    \n",
    "3.) Make cloudbank dataframe to feed to pytorch dataloader for model training.\n",
    "\"\"\"\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pandas_path as path\n",
    "from pathlib import Path\n",
    "from PIL import Image\n",
    "import glob\n",
    "import argparse\n",
    "import os\n",
    "\n",
    "from cloud_seg.utils import utils\n",
    "from cloud_seg.io import io\n",
    "\n",
    "DATA_DIR = Path.cwd().parent.resolve() / \"data/\"\n",
    "DATA_DIR_CLOUDS = DATA_DIR / 'clouds/'\n",
    "DATA_DIR_CLOUDLESS = DATA_DIR / 'cloudless/'\n",
    "DATA_DIR_CLOUDLESS_MOST_SIMILAR = DATA_DIR / 'cloudless_most_similar/'\n",
    "DATA_DIR_CLOUDLESS_TIF = DATA_DIR / 'cloudless_tif/'\n",
    "DATA_DIR_OUT = DATA_DIR / \"model_training/\"\n",
    "\n",
    "TRAIN_FEATURES = DATA_DIR / \"train_features/\"\n",
    "TRAIN_FEATURES_NEW = DATA_DIR / \"train_features_new/\"\n",
    "\n",
    "TRAIN_LABELS = DATA_DIR / \"train_labels/\"\n",
    "\n",
    "assert TRAIN_FEATURES.exists(), TRAIN_LABELS.exists()\n",
    "\n",
    "Path(DATA_DIR_OUT).mkdir(parents=True, exist_ok=True)\n",
    "Path(DATA_DIR_CLOUDS).mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "def construct_cloudbank_dataframe(df_val, params: dict):\n",
    "    \"\"\"Construct cloudbank using all chips that do not overlap with validation set\"\"\"\n",
    "    cloud_chips = sorted(glob.glob(str(DATA_DIR_CLOUDS) + '/*'))\n",
    "    \n",
    "    print(f\"\\nTotal number of cloud chips is {len(cloud_chips)}\")\n",
    "    \n",
    "    # remove cloud chips that are from validation sample\n",
    "    in_val = [os.path.basename(i) in df_val['chip_id'].to_numpy() for i in cloud_chips]\n",
    "    cloud_chips = [chip for ichip, chip in enumerate(cloud_chips) if not in_val[ichip]] \n",
    "\n",
    "    cloudbank = []\n",
    "    for chip in cloud_chips:\n",
    "        # for each location choose an image \n",
    "        chip_id = os.path.basename(chip)\n",
    "        # print(chip, chip_id)\n",
    "\n",
    "        feature_cols = [chip + f\"/{band}.tif\" for band in params['bands_use']]\n",
    "        label_col = [chip + f\"/label.tif\"]\n",
    "        # print(feature_cols, label_col)\n",
    "        cloudbank.append([chip_id]+feature_cols+label_col)\n",
    "\n",
    "    df_meta = pd.DataFrame(cloudbank, columns=list(df_val.columns)+['label_path'])\n",
    "    print(f\"Size of cloudbank not overlapping validation chips is {len(df_meta)} chips\")\n",
    "    df_meta.head()\n",
    "    \n",
    "    return df_meta\n",
    "\n",
    "def load_validation_dataframe(isplit: int, params: dict):\n",
    "    \n",
    "    file_name_in = f\"validate_features_meta_cv{isplit}.csv\"\n",
    "    # file_name_in = f\"validate_features_meta_seed{params['seed']}_cv{isplit}.csv\"\n",
    "\n",
    "    df_val = pd.read_csv(DATA_DIR_OUT / file_name_in)\n",
    "          \n",
    "    return(df_val)\n",
    "\n",
    "def save_dataframe_to_disk(df_meta, isplit, params: dict):\n",
    "    \n",
    "    print(f\"\\nSaving cloudbank from split {isplit} to disk at:\\n{str(DATA_DIR_OUT)}\")\n",
    "\n",
    "    file_name_out = f\"cloudbank_meta_cv{isplit}.csv\"\n",
    "    # file_name_out = f\"cloudbank_meta_seed{params['seed']}_cv{isplit}.csv\"\n",
    "\n",
    "    df_meta.to_csv(DATA_DIR_OUT / file_name_out, index=False)\n",
    "\n",
    "def load_npz_arrays_for_chip(params, chip_id):\n",
    "    \n",
    "    cloudless_chip_dir = DATA_DIR_CLOUDLESS / chip_id\n",
    "    images_cloudless_all = {}\n",
    "\n",
    "    for band in params['bands_use']:\n",
    "        f_ = cloudless_chip_dir / f\"{band}.npz\" \n",
    "        \n",
    "        d_ = np.load(f_, allow_pickle=True)\n",
    "\n",
    "        # resize images to outsize\n",
    "        images_in = np.array(d_[\"images\"]).astype(np.float32)\n",
    "\n",
    "        single_image = False\n",
    "        if images_in.ndim < 3:\n",
    "            # only a single image was saved to .npz file\n",
    "            single_image = True\n",
    "            images_in = images_in[None, ...]\n",
    "\n",
    "            \n",
    "        images_out = np.zeros( (images_in.shape[0], params['outsize'][0], params['outsize'][1]), dtype=np.float32)\n",
    "        for i in range(images_in.shape[0]):\n",
    "            images_out[i] = utils.resize_image(images_in[i], params['outsize'], interpolation_order=params['interpolation_order']) \n",
    "\n",
    "        images_cloudless_all[band] = images_out\n",
    "        if single_image:\n",
    "            images_cloudless_all[band+\"_time\"] = [d_[\"times\"]]\n",
    "            images_cloudless_all[band+\"_dtime\"] = [d_[\"dtimes\"]]\n",
    "            images_cloudless_all[band+\"_properties\"] = [d_[\"properties\"]]\n",
    "\n",
    "        else:\n",
    "            images_cloudless_all[band+\"_time\"] = d_[\"times\"]\n",
    "            images_cloudless_all[band+\"_dtime\"] = d_[\"dtimes\"]\n",
    "            images_cloudless_all[band+\"_properties\"] = d_[\"properties\"]\n",
    "\n",
    "        images_cloudless_all[band+\"_nimg\"] = images_out.shape[0]\n",
    "        \n",
    "    nimages = images_cloudless_all[\"B02_nimg\"]\n",
    "    images_matching = np.full(nimages, True, dtype=bool)\n",
    "    for iimg in range(nimages):\n",
    "        for iband, band in enumerate(params['bands_use']):\n",
    "            if iband == 0:\n",
    "                chip_properties = images_cloudless_all[band+\"_properties\"][iimg]\n",
    "            else:\n",
    "                images_matching[iimg] = images_matching[iimg] and (images_cloudless_all[band+\"_properties\"][iimg]==chip_properties)\n",
    "                \n",
    "    if params['verbose']: print(\"All images matching? \", images_matching)\n",
    "     \n",
    "    images_cloudless_all_matching = {}\n",
    "    for iband, band in enumerate(params['bands_use']):\n",
    "        images_cloudless_all_matching[band] =  images_cloudless_all[band][images_matching]\n",
    "    \n",
    "    if params['verbose']: print(images_cloudless_all_matching[\"B02\"].shape)\n",
    "        \n",
    "    return images_cloudless_all_matching       \n",
    "\n",
    "def save_npz_chip_arrays_to_tif(params: dict):\n",
    "    \n",
    "    cloudless_dirs = sorted(glob.glob(str(DATA_DIR_CLOUDLESS) + '/*'))\n",
    "\n",
    "    for ic, cloudless_dir in enumerate(cloudless_dirs):\n",
    "\n",
    "        if ic % 100 == 0:\n",
    "            print('Running on ', ic)\n",
    "        chip_id = os.path.basename(cloudless_dir)\n",
    "\n",
    "        # check if output files already exist for this chip. Skip if so\n",
    "        exists = True \n",
    "        if params['remake_all']: \n",
    "            exists = False\n",
    "        \n",
    "        for band in params['bands_use']:\n",
    "            if not Path(DATA_DIR_CLOUDLESS_TIF / f'{chip_id}/0/{band}.tif').is_file():\n",
    "                exists = False\n",
    "        \n",
    "        if exists:\n",
    "            continue\n",
    "        images_cloudless_all = load_npz_arrays_for_chip(params, chip_id)\n",
    "    \n",
    "        for iimg in range(images_cloudless_all[\"B02\"].shape[0]):\n",
    "            band_diri = Path(DATA_DIR_CLOUDLESS_TIF / f\"{chip_id}/{iimg}/\")\n",
    "            Path(band_diri).mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "            for band in params['bands_use']:\n",
    "\n",
    "                band_loc = band_diri / f\"{band}.tif\"\n",
    "                # if not os.path.isfile(band_loc):\n",
    "                band_image = Image.fromarray(images_cloudless_all[band][iimg])        \n",
    "                band_image.save(band_loc)   \n",
    "\n",
    "def find_and_return_most_similar_image(params, image, label, images_cloudless, brightness_correct_image_cloudless=False):\n",
    "    \"\"\"Given a cloudy chip and a number of cloudless versions of the same area, choose or create \n",
    "    the most similar one to the cloudy chip.\n",
    "    \n",
    "    The simple approximation is to just calculate which set of images best matches in regions where labels==0. \n",
    "    This does not accound for shadows.\n",
    "    \"\"\"\n",
    "    \n",
    "     # determine which new cloudless image is most similar to the old\n",
    "     # by calculating agreement in non-cloudy regions\n",
    "    diffs = np.zeros( (len(params['bands_use']), images_cloudless['B02'].shape[0]) )\n",
    "    for i, band in enumerate(params['bands_use']):\n",
    "\n",
    "        diff = (image[band]-images_cloudless[band]) * label\n",
    "        diffs[i] = np.sum(diff, axis=(1,2))\n",
    "\n",
    "        if diffs[i].max() > 0.:\n",
    "            # if totally cloud covered label==0 everywhere, and max will be 0.\n",
    "            diffs[i] /= diffs[i].max()\n",
    "\n",
    "    total_diffs = np.mean(diffs, axis=0)\n",
    "\n",
    "    ind_min_band_diff = np.argmin(total_diffs)  \n",
    "    \n",
    "    image_cloudless = {}\n",
    "    for band in params['bands_use']:\n",
    "        image_cloudless[band] = images_cloudless[band][ind_min_band_diff]\n",
    "    \n",
    "        if brightness_correct_image_cloudless:\n",
    "            # try to match the average intensity in non cloudy regions\n",
    "            dm = label == 1\n",
    "\n",
    "            if np.sum(dm) > 0:\n",
    "                mean_diff = np.median(image[band][dm] - image_cloudless[band][dm])\n",
    "            else:\n",
    "                mean_diff = 1.\n",
    "\n",
    "            # print('mean_diff', mean_diff)\n",
    "            images_cloudless[band] += mean_diff\n",
    "\n",
    "    return image_cloudless\n",
    "\n",
    "def extract_clouds(params, image, label, images_cloudless, cloud_extract_model='additive'):\n",
    "    \"\"\"Given cloudy image/label pair, and 'cloudless' images of the same area pulled from the planetary computer,\n",
    "    extract brightness changes due to clouds.\n",
    "    \n",
    "    The simplest model is to assume clouds simply add brightness to each pixel that they cover. \n",
    "    If true, assuming that the land does not change between when the cloudy and cloudless images were taken,\n",
    "    clouds = (images - images_cloudless)*labels.\n",
    "    \n",
    "    Unfortunately, both of these assumptions are incorrect\n",
    "    \n",
    "    1.) The cloudy and cloudless images are of the same location, but are often seperated by months or years.\n",
    "        Over this timeframe plants change color, water levels change, and human infractstructure near cities changes.\n",
    "        Additionally, the images might not be taken from the same angle, causing mis-alignments between each image set.\n",
    "        \n",
    "    2.) Clouds are sometimes transparent, sometimes not. An additive model does not correcely account for this\n",
    "    \n",
    "    3.) Cloud shadows... We know what angle the sun makes for each chip (in chip properties) can we come up with a way to project these?\n",
    "    \n",
    "    \"\"\"\n",
    "    cloud_extract_models = ['additive'] # Add transparency later\n",
    "    \n",
    "    if cloud_extract_model not in cloud_extract_models:\n",
    "        print(f\"WARNING: cloud model {cloud_extract_model} is not a possible value to use. Using {cloud_extract_models[0]} instead \\\n",
    "            Possible choices are:\", cloud_extract_models)\n",
    "        \n",
    "    image_cloudless = find_and_return_most_similar_image(params, image, label, images_cloudless)   \n",
    "    \n",
    "    # and save to disk as .tif\n",
    "    clouds = {}\n",
    "    for band in params['bands_use']:\n",
    "\n",
    "        if cloud_extract_model=='additive':\n",
    "            clouds[band] = (image[band] - image_cloudless[band]) \n",
    "\n",
    "    return image_cloudless, clouds\n",
    "\n",
    "def make_clouds(params, cloudless_dir):\n",
    "    \n",
    "    chip_id = os.path.basename(cloudless_dir)\n",
    "    print(chip_id)\n",
    "\n",
    "    # check if output files already exist for this chip. Skip if so\n",
    "    # if Path(DATA_DIR_CLOUDS / f'{chip_id}/').is_dir() and not params['remake_all']:\n",
    "    #     if params['verbose']: print(f\"{DATA_DIR_CLOUDLESS_TIF / f'{chip_id}/'} already exists\")\n",
    "    #     continue\n",
    "\n",
    "    image = io.load_image(chip_id, TRAIN_FEATURES, TRAIN_FEATURES_NEW, bands=params['bands_use'])\n",
    "    label = io.load_label(chip_id, TRAIN_LABELS)\n",
    "\n",
    "    files = sorted(glob.glob(str(DATA_DIR_CLOUDLESS / chip_id / '*')))\n",
    "\n",
    "    images_cloudless_all = load_npz_arrays_for_chip(params, chip_id)\n",
    "\n",
    "    image_cloudless, clouds = extract_clouds(params, image, label, images_cloudless_all, cloud_extract_model='additive')  \n",
    "\n",
    "    band_diri = Path(DATA_DIR_CLOUDS / f\"{chip_id}\")\n",
    "    Path(band_diri).mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    for band in params['bands_use']:\n",
    "\n",
    "        # save clouds\n",
    "        band_diri = Path(DATA_DIR_CLOUDS / f\"{chip_id}\")\n",
    "        Path(band_diri).mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "        band_loc = band_diri / f\"{band}.tif\"\n",
    "        band_image = Image.fromarray(clouds[band])        \n",
    "        band_image.save(band_loc)                                  \n",
    "\n",
    "        # save most similar cloudless image\n",
    "        band_diri = Path(DATA_DIR_CLOUDLESS_MOST_SIMILAR / f\"{chip_id}\")\n",
    "        Path(band_diri).mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "        band_loc = band_diri / f\"{band}.tif\"\n",
    "        band_image = Image.fromarray(image_cloudless[band])        \n",
    "        band_image.save(band_loc)                                  \n",
    "\n",
    "    # save label\n",
    "    band_diri = Path(DATA_DIR_CLOUDS / f\"{chip_id}\")\n",
    "\n",
    "    band_loc = band_diri / f\"label.tif\"\n",
    "    band_labels = Image.fromarray(label)        \n",
    "    band_labels.save(band_loc)                                  \n",
    "\n",
    "def run_make_clouds(params: dict):\n",
    "    \n",
    "    cloudless_dirs = sorted(glob.glob(str(DATA_DIR_CLOUDLESS) + '/*'))\n",
    "\n",
    "    for ic, cloudless_dir in enumerate(cloudless_dirs):\n",
    "\n",
    "        if ic % 10 == 0:\n",
    "            print('Running on ', ic)\n",
    " \n",
    "        chip_id = os.path.basename(cloudless_dir)\n",
    "\n",
    "        # check if output files already exist for this chip. Skip if so\n",
    "        exists = True \n",
    "        if params['remake_all']: \n",
    "            exists = False\n",
    "        \n",
    "        for band in params['bands_use']:\n",
    "            if not Path(DATA_DIR_CLOUDS / f'{chip_id}/{band}.tif').is_file():\n",
    "                exists = False\n",
    "        \n",
    "        if exists:\n",
    "            continue\n",
    "           \n",
    "        make_clouds(params, cloudless_dir)\n",
    "        \n",
    "def main():\n",
    "    \n",
    "    parser = argparse.ArgumentParser(description='runtime parameters')\n",
    "    parser.add_argument(\"--bands\", nargs='+' , default=[\"B02\", \"B03\", \"B04\", \"B08\"],\n",
    "                        help=\"bands desired\")\n",
    "    parser.add_argument(\"--bands_new\", nargs='+', default=None,\n",
    "                        help=\"additional bands to use beyond original four\")\n",
    "    parser.add_argument(\"-ncv\", \"--num_cross_validation_splits\", type=int, default=4,\n",
    "                        help=\"fraction of data to put in validation set\") \n",
    "    parser.add_argument(\"--save_cloudless_as_tif\", action=\"store_true\",\n",
    "                        help=\"For each cloudless chip save array of band data (Nimg, H, W) as invididual .tif files\") \n",
    "        \n",
    "    parser.add_argument(\"--extract_clouds\", action=\"store_true\",\n",
    "                        help=\"Extract clouds from pairs of cloudy and cloudless chips\") \n",
    "    \n",
    "    parser.add_argument(\"--remake_all\", action=\"store_true\",\n",
    "                        help=\"Remake all images, and overwrite current ones on disk\") \n",
    "    \n",
    "    parser.add_argument(\"--interpolation_order\", type=int, default=0,\n",
    "                        help=\"interpolation order for resizing images\") \n",
    "             \n",
    "    parser.add_argument(\"--seed\", type=int , default=13579,\n",
    "                        help=\"random seed for train test split\")\n",
    "    parser.add_argument(\"--dont_save_to_disk\", action=\"store_true\",\n",
    "                        help=\"save training and validation sets to disk\")     \n",
    "    parser.add_argument(\"-v\", \"--verbose\", action=\"store_true\",\n",
    "                        help=\"increase output verbosity\")\n",
    "   \n",
    "    params = vars(parser.parse_args())\n",
    "    params['bands_use'] = sorted(params['bands'] + params['bands_new']) if params['bands_new'] is not None else params['bands']\n",
    "    \n",
    "    params['outsize'] = [512, 512]\n",
    "\n",
    "    if params['verbose']: print(\"Parameters are: \", params)\n",
    "    \n",
    "    if params['save_cloudless_as_tif']:\n",
    "        save_npz_chip_arrays_to_tif(params)\n",
    "\n",
    "    if params['extract_clouds']:\n",
    "        # Extract all clouds from pairs of cloudy and cloudless chips\n",
    "        run_make_clouds(params)\n",
    "    \n",
    "    for isplit in range(params['num_cross_validation_splits']):\n",
    "        df_val = load_validation_dataframe(isplit, params)\n",
    "        \n",
    "        df_meta = construct_cloudbank_dataframe(df_val, params)\n",
    "\n",
    "        if not params['dont_save_to_disk']:\n",
    "            save_dataframe_to_disk(df_meta, isplit, params)\n",
    "  \n",
    "if __name__==\"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e31523f6-5ebb-49a0-8137-fc05f4bae5e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def run_extract_clouds(params: dict):\n",
    "\n",
    "DATA_DIR_CLOUDLESS = DATA_DIR / 'cloudless/'\n",
    "DATA_DIR_CLOUDLESS_TIF = DATA_DIR / 'cloudless_tif/'\n",
    "\n",
    "outsize = [512, 512]\n",
    "interpolation_order = 1\n",
    "\n",
    "DATA_DIR_CLOUDLESS = DATA_DIR / 'cloudless/'\n",
    "DATA_DIR_CLOUDS    = DATA_DIR / 'clouds/'\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1ffff68c-a304-41d4-9ef5-309f042e72ac",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'numpy.dtype[float32]' object is not callable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_58682/1414155609.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0mTRAIN_LABELS\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDATA_DIR\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;34m\"train_labels/\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m \u001b[0mio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_pil_as_nparray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mTRAIN_FEATURES\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;34m'adwp/B02.tif'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m: 'numpy.dtype[float32]' object is not callable"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pandas_path as path\n",
    "from pathlib import Path\n",
    "from PIL import Image\n",
    "import glob\n",
    "import argparse\n",
    "import os\n",
    "\n",
    "from cloud_seg.utils import utils\n",
    "from cloud_seg.io import io\n",
    "\n",
    "DATA_DIR = Path.cwd().parent.resolve() / \"../data/\"\n",
    "DATA_DIR_CLOUDS = DATA_DIR / 'clouds/'\n",
    "DATA_DIR_CLOUDLESS = DATA_DIR / 'cloudless/'\n",
    "DATA_DIR_CLOUDLESS_TIF = DATA_DIR / 'cloudless_tif/'\n",
    "DATA_DIR_OUT = DATA_DIR / \"model_training/\"\n",
    "\n",
    "TRAIN_FEATURES = DATA_DIR / \"train_features/\"\n",
    "TRAIN_FEATURES_NEW = DATA_DIR / \"train_features_new/\"\n",
    "\n",
    "TRAIN_LABELS = DATA_DIR / \"train_labels/\"\n",
    "\n",
    "io.load_pil_as_nparray(TRAIN_FEATURES / 'adwp/B02.tif').dtype()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fff37078-4665-4dc5-98fc-3077ce4c137f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "CloudCover",
   "language": "python",
   "name": "cloud_cover"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
