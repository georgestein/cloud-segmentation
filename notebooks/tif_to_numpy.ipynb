{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "24195ab3-3987-4275-8688-f08fc6fc378c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import os\n",
    "os.environ['OPENBLAS_NUM_THREADS'] = '1'\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cc01a58a-3481-4c9c-b934-66881091609b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting ../scripts/tifs_to_big_npy.py\n"
     ]
    }
   ],
   "source": [
    "%%file ../scripts/tifs_to_big_npy.py\n",
    "\"\"\"\n",
    "Loop over chunks of size <chunksize> and save individual .tifs in various folders to\n",
    "single large numpy arrays.\n",
    "\n",
    "In order to facilitate faster data/label/prediction investigation\n",
    "\"\"\"\n",
    "import shutil\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import pandas_path as path\n",
    "from pathlib import Path\n",
    "from PIL import Image\n",
    "import torch\n",
    "import pytorch_lightning as pl\n",
    "\n",
    "import xarray\n",
    "import xrspatial.multispectral as ms\n",
    "\n",
    "import math\n",
    "import time\n",
    "import argparse\n",
    "\n",
    "import multiprocessing\n",
    "\n",
    "from cloud_seg.utils import chip_vis, utils\n",
    "from cloud_seg.io import io\n",
    "\n",
    "DATA_DIR = Path.cwd().parent.resolve() / \"data/\"\n",
    "DATA_DIR_CLOUDS = DATA_DIR / 'clouds/'\n",
    "DATA_DIR_CLOUDLESS = DATA_DIR / 'cloudless/'\n",
    "DATA_DIR_CLOUDLESS_MOST_SIMILAR = DATA_DIR / 'cloudless_most_similar/'\n",
    "DATA_DIR_CLOUDLESS_TIF = DATA_DIR / 'cloudless_tif/'\n",
    "\n",
    "DATA_DIR_OUT = DATA_DIR / \"big_numpy_arrays\"\n",
    "\n",
    "PREDICTION_DIR = Path.cwd().parent.resolve() / \"trained_models/unet/4band_originaldata_efficientnet-b0_dice__Normalize_VerticalFlip_HorizontalFlip_RandomRotate90/predictions/\"\n",
    "\n",
    "TRAIN_FEATURES = DATA_DIR / \"train_features\"\n",
    "TRAIN_FEATURES_NEW = DATA_DIR / \"train_features_new\"\n",
    "\n",
    "TRAIN_LABELS = DATA_DIR / \"train_labels\"\n",
    "\n",
    "BANDS = [\"B02\", \"B03\", \"B04\", \"B08\"]\n",
    "BANDS_NEW = []\n",
    "# BANDS_NEW = [\"B01\", \"B11\"]\n",
    "\n",
    "assert TRAIN_FEATURES.exists(), TRAIN_LABELS.exists()\n",
    "\n",
    "parser = argparse.ArgumentParser(description='runtime parameters')\n",
    "parser.add_argument(\"--bands\", nargs='+' , default=[\"B02\", \"B03\", \"B04\", \"B08\"],\n",
    "                    help=\"bands desired\")\n",
    "\n",
    "parser.add_argument(\"--bands_new\", nargs='+', default=None,\n",
    "                    help=\"additional bands to use beyond original four\")\n",
    "\n",
    "parser.add_argument(\"--chunksize\", type=int, default=1000,\n",
    "                    help=\"Chunksize for output arrays\") \n",
    "\n",
    "parser.add_argument(\"--max_pool_size\", type=int, default=32,\n",
    "                    help=\"Chunksize for output arrays\") \n",
    "                          \n",
    "parser.add_argument(\"-v\", \"--verbose\", action=\"store_true\",\n",
    "                    help=\"increase output verbosity\")\n",
    "\n",
    "params = vars(parser.parse_args())\n",
    "params['bands_use'] = sorted(params['bands'] + params['bands_new']) if params['bands_new'] is not None else params['bands']\n",
    "\n",
    "params['outsize'] = [512, 512]\n",
    "\n",
    "if params['verbose']: print(\"Parameters are: \", params)\n",
    "    \n",
    "train_meta = pd.read_csv(DATA_DIR / \"train_metadata.csv\")\n",
    "\n",
    "# how many different chip ids, locations, and datetimes are there?\n",
    "print(train_meta[[\"chip_id\", \"location\", \"datetime\"]].nunique())\n",
    "\n",
    "train_meta.head()\n",
    "\n",
    "train_meta = utils.add_paths(train_meta, TRAIN_FEATURES, TRAIN_LABELS, bands=params['bands'])\n",
    "\n",
    "if params['bands_new'] is not None:\n",
    "    # has_B01  = (TRAIN_FEATURES_NEW / train_meta[\"chip_id\"] / f\"B01.tif\").map(os.path.isfile)\n",
    "    # has_B11 = (TRAIN_FEATURES_NEW / train_meta[\"chip_id\"] / f\"B11.tif\").map(os.path.isfile)\n",
    "\n",
    "    # print('Fraction of chips that have B01, B11 = ', has_B01.sum()/has_B01.shape[0], has_B11.sum()/has_B11.shape[0])\n",
    "\n",
    "    # dm = has_B01 & has_B11\n",
    "    # train_meta = train_meta[dm]\n",
    "\n",
    "    train_meta = utils.add_paths(train_meta, TRAIN_FEATURES_NEW, bands=params['bands_new'])\n",
    "\n",
    "# Total number of chunks. Set as global variable\n",
    "params['nchunks'] = math.ceil(len(train_meta)/params['chunksize'])\n",
    "params['max_pool_size'] = min(params['nchunks'], params['max_pool_size'])\n",
    "\n",
    "def intersection_and_union(pred, true):\n",
    "    \"\"\"                                                                                                         \n",
    "    Calculates intersection and union for a batch of images.                                                    \n",
    "                                                                                                                \n",
    "    Args:                                                                                                       \n",
    "        pred (torch.Tensor): a tensor of predictions                                                            \n",
    "        true (torc.Tensor): a tensor of labels                                                                  \n",
    "                                                                                                                \n",
    "    Returns:                                                                                                    \n",
    "        intersection (int): total intersection of pixels                                                        \n",
    "        union (int): total union of pixels                                                                      \n",
    "    \"\"\"\n",
    "\n",
    "    # Intersection and union totals                                                                             \n",
    "    pred_flattened = pred.flatten()\n",
    "    true_flattened = true.flatten()\n",
    "\n",
    "    intersection = np.logical_and(true_flattened, pred_flattened)/pred_flattened.shape[0]\n",
    "    union = np.logical_or(true_flattened, pred_flattened)/pred_flattened.shape[0]\n",
    "\n",
    "    return float(np.sum(intersection)), float(np.sum(union))\n",
    "\n",
    "def load_image_to_array(chip_id, bands=[\"B02\", \"B03\", \"B04\", \"B08\"],\n",
    "               data_dir=TRAIN_FEATURES, data_dir_new=TRAIN_FEATURES_NEW):\n",
    "    \"\"\"Given the path to the directory of Sentinel-2 chip feature images,\n",
    "    plots the true color image\"\"\"\n",
    "    \n",
    "    original_bands=[\"B02\", \"B03\", \"B04\", \"B08\"]\n",
    "    \n",
    "    npixx = 512\n",
    "    npixy = 512\n",
    "    \n",
    "    # chip_image = np.zeros((len(want_bands), npix[0], npix[1]), dtype=np.uint16)\n",
    "    chip_image = {}\n",
    "\n",
    "    image_array = np.zeros((len(bands), npixx, npixy), dtype=np.float32)\n",
    "    for i, band in enumerate(bands):\n",
    "        if band in original_bands:\n",
    "            chip_dir = data_dir / chip_id\n",
    "        else:\n",
    "            chip_dir = data_dir_new / chip_id\n",
    "\n",
    "        image_array[i] = np.array(io.load_pil_as_nparray(chip_dir / f\"{band}.tif\")).astype(np.float32)\n",
    "  \n",
    "    return image_array\n",
    "\n",
    "\n",
    "# def tif_to_numpy(random_state, nplt=1, figsize=None):\n",
    "    \n",
    "def get_chips_in_npy(ichip_start, ichip_end, bands=[\"B02\", \"B03\", \"B04\", \"B08\"]):\n",
    "\n",
    "    npixx = 512\n",
    "    npixy = 512\n",
    "    nchips = ichip_end-ichip_start\n",
    "    images = np.zeros((nchips, len(bands), npixx, npixy), dtype=np.uint16)\n",
    "    labels = np.zeros((nchips, npixx, npixy), dtype=np.uint8)\n",
    "    preds = np.zeros((nchips, npixx, npixy), dtype=np.uint8)\n",
    "    \n",
    "    labels_mean = np.zeros(nchips, dtype=np.float32)\n",
    "    preds_mean  = np.zeros(nchips, dtype=np.float32)\n",
    "    intersection = np.zeros(nchips, dtype=np.float32)\n",
    "    union = np.zeros(nchips, dtype=np.float32)\n",
    "\n",
    "    chip_ids = []\n",
    "    for ichip, ichip_meta_loc in enumerate(range(ichip_start, ichip_end)):\n",
    "\n",
    "        chip = train_meta.iloc[ichip_meta_loc]\n",
    "        \n",
    "        chip_ids.append(chip.chip_id)\n",
    "        images[ichip] = load_image_to_array(chip.chip_id, bands=bands)  \n",
    "        labels[ichip] = np.array(Image.open(chip.label_path))\n",
    "        preds_i = np.array(Image.open(PREDICTION_DIR/f\"{chip.chip_id}.tif\"))\n",
    "        preds_i = (preds_i > 0.5)*1\n",
    "        preds[ichip] = preds_i.astype(np.int8)\n",
    "        \n",
    "        intersection[ichip], union[ichip] = intersection_and_union(preds[ichip], labels[ichip])\n",
    "        labels_mean[ichip] = np.mean(labels[ichip])\n",
    "        preds_mean[ichip] = np.mean(preds[ichip])\n",
    "\n",
    "    d = {}\n",
    "    d['chip_ids'] = chip_ids\n",
    "    d['images'] = images\n",
    "    d['labels'] = labels\n",
    "    d['preds'] = preds\n",
    "    d['labels_mean'] = labels_mean\n",
    "    d['preds_mean'] = preds_mean\n",
    "        \n",
    "    d['intersection'] = intersection\n",
    "    d['union'] = union\n",
    "\n",
    "    d['IoU'] = intersection/union\n",
    "\n",
    "    return d\n",
    "\n",
    "def run_on_chunk(ichunk):\n",
    "    \n",
    "    tstart = time.time()\n",
    "    ichip_start = ichunk*params['chunksize']\n",
    "    ichip_end = min(len(train_meta), (ichunk+1)*params['chunksize'])\n",
    "\n",
    "    print(f\"\\nRunning on chunk {ichunk} out of {params['nchunks']}. Index start:{ichip_start}, index end: {ichip_end}\")\n",
    "\n",
    "    data = get_chips_in_npy(ichip_start, ichip_end, bands=params['bands_use'])\n",
    "\n",
    "    print(\"data, label, prediction shape: \", data['images'].shape, data['labels'].shape, data['preds'].shape)\n",
    "\n",
    "    for k, v in data.items():\n",
    "        np.save(DATA_DIR_OUT / f\"{k}_{ichip_start:06d}_{ichip_end:06d}.npy\", v)\n",
    "\n",
    "    print(\"Time elapsed = \", time.time()-tstart)\n",
    "    \n",
    "def main():\n",
    "    \"\"\"\n",
    "    Loop over chunks of size <chunksize> and save individual .tifs in various folders to\n",
    "    single large numpy arrays.\n",
    "    \n",
    "    In order to facilitate faster data/label/prediction investigation\n",
    "    \"\"\"\n",
    "    \n",
    "#     # Simple threading with pool and .map\n",
    "    cpus = multiprocessing.cpu_count()\n",
    "    pool = multiprocessing.Pool(cpus if cpus < params['max_pool_size'] else params['max_pool_size'])\n",
    "    print(f\"Number of available cpus = {cpus}\")\n",
    "    \n",
    "    pool.map(run_on_chunk, range(params['nchunks']))\n",
    "        \n",
    "    # pool.close()\n",
    "    # pool.join()\n",
    "    # for ichunk in range(params['nchunks']):\n",
    "    #      run_on_chunk(ichunk)\n",
    "        \n",
    "if __name__=='__main__':\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "092f9dca-de31-47be-956d-83a2f7168701",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "CloudCover",
   "language": "python",
   "name": "cloud_cover"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
