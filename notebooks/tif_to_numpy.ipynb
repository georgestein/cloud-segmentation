{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "24195ab3-3987-4275-8688-f08fc6fc378c",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import os\n",
    "os.environ['OPENBLAS_NUM_THREADS'] = '1'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bec0613f-a243-4bce-817a-2875e921deb4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(-2.569640871417797,\n",
       " 32.84001110492555,\n",
       " -2.5233147610469233,\n",
       " 32.886073190963415)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import shutil\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import pandas_path as path\n",
    "from pathlib import Path\n",
    "from PIL import Image\n",
    "import torch\n",
    "import pytorch_lightning as pl\n",
    "\n",
    "import xarray\n",
    "import xrspatial.multispectral as ms\n",
    "import rasterio\n",
    "import pyproj\n",
    "\n",
    "import math\n",
    "import time\n",
    "import argparse\n",
    "import os \n",
    "\n",
    "import multiprocessing\n",
    "\n",
    "from cloud_seg.utils import chip_vis, utils\n",
    "from cloud_seg.io import io\n",
    "\n",
    "DATA_DIR = Path.cwd().parent.resolve() / \"data/\"\n",
    "DATA_DIR_CLOUDS = DATA_DIR / 'clouds/'\n",
    "DATA_DIR_CLOUDLESS = DATA_DIR / 'cloudless/'\n",
    "DATA_DIR_CLOUDLESS_MOST_SIMILAR = DATA_DIR / 'cloudless_most_similar/'\n",
    "DATA_DIR_CLOUDLESS_TIF = DATA_DIR / 'cloudless_tif/'\n",
    "\n",
    "DATA_DIR_OUT = DATA_DIR / \"big_numpy_arrays/\"\n",
    "DATA_DIR_OUT = DATA_DIR / \"big_numpy_arrays/nchips_100/\"\n",
    "# DATA_DIR_OUT = DATA_DIR / \"big_numpy_arrays/\"\n",
    "\n",
    "PREDICTION_DIR = Path.cwd().parent.resolve() / \"trained_models/unet/4band_originaldata_resnet18_bce_vfrc_customfeats_None_2022-01-17/predictions/\"\n",
    "\n",
    "TRAIN_FEATURES = DATA_DIR / \"train_features\"\n",
    "TRAIN_FEATURES_NEW = DATA_DIR / \"train_features_new\"\n",
    "\n",
    "TRAIN_LABELS = DATA_DIR / \"train_labels\"\n",
    "\n",
    "\n",
    "def lat_long_bounds(chip_id):\n",
    "    \"\"\"Given the path to a GeoTIFF, returns the image bounds in latitude and\n",
    "    longitude coordinates.\n",
    "\n",
    "    Returns points as a tuple of (left, bottom, right, top)\n",
    "    \"\"\"\n",
    "\n",
    "    chip_path = TRAIN_FEATURES / chip_id / \"B04.tif\"\n",
    "    with rasterio.open(chip_path) as chip:\n",
    "\n",
    "        # create a converter starting with the current projection\n",
    "        current_crs = pyproj.CRS(chip.meta[\"crs\"])\n",
    "        crs_transform = pyproj.Transformer.from_crs(current_crs, current_crs.geodetic_crs)\n",
    "\n",
    "        # returns left, bottom, right, top\n",
    "        left, bottom, right, top = crs_transform.transform_bounds(*chip.bounds)\n",
    "        \n",
    "    return left, bottom, right, top\n",
    "\n",
    "lat_long_bounds('adwp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cc01a58a-3481-4c9c-b934-66881091609b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting ../scripts/tifs_to_big_npy.py\n"
     ]
    }
   ],
   "source": [
    "%%file ../scripts/tifs_to_big_npy.py\n",
    "\"\"\"\n",
    "Loop over chunks of size <chunksize> and save individual .tifs in various folders to\n",
    "single large numpy arrays.\n",
    "\n",
    "In order to facilitate faster data/label/prediction investigation\n",
    "\"\"\"\n",
    "import shutil\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import pandas_path as path\n",
    "from pathlib import Path\n",
    "from PIL import Image\n",
    "import torch\n",
    "import pytorch_lightning as pl\n",
    "\n",
    "import xarray\n",
    "import xrspatial.multispectral as ms\n",
    "import rasterio\n",
    "import pyproj\n",
    "import rasterio.warp\n",
    "\n",
    "import math\n",
    "import time\n",
    "import argparse\n",
    "import os \n",
    "\n",
    "import multiprocessing\n",
    "\n",
    "from cloud_seg.utils import chip_vis, utils\n",
    "from cloud_seg.io import io\n",
    "\n",
    "DATA_DIR = Path.cwd().parent.resolve() / \"data/\"\n",
    "DATA_DIR_CLOUDS = DATA_DIR / 'clouds/'\n",
    "DATA_DIR_CLOUDLESS = DATA_DIR / 'cloudless/'\n",
    "DATA_DIR_CLOUDLESS_MOST_SIMILAR = DATA_DIR / 'cloudless_most_similar/'\n",
    "DATA_DIR_CLOUDLESS_TIF = DATA_DIR / 'cloudless_tif/'\n",
    "\n",
    "DATA_DIR_OUT = DATA_DIR / \"big_numpy_arrays/\"\n",
    "DATA_DIR_OUT = DATA_DIR / \"big_numpy_arrays/nchips_100/\"\n",
    "# DATA_DIR_OUT = DATA_DIR / \"big_numpy_arrays/\"\n",
    "\n",
    "PREDICTION_DIR = Path.cwd().parent.resolve() / \"trained_models/unet/4band_originaldata_resnet18_bce_vfrc_customfeats_None_2022-01-17/predictions/\"\n",
    "\n",
    "TRAIN_FEATURES = DATA_DIR / \"train_features\"\n",
    "TRAIN_FEATURES_NEW = DATA_DIR / \"train_features_new\"\n",
    "\n",
    "TRAIN_LABELS = DATA_DIR / \"train_labels\"\n",
    "\n",
    "BANDS = [\"B02\", \"B03\", \"B04\", \"B08\"]\n",
    "BANDS_NEW = []\n",
    "# BANDS_NEW = [\"B01\", \"B11\"]\n",
    "\n",
    "assert TRAIN_FEATURES.exists(), TRAIN_LABELS.exists()\n",
    "\n",
    "parser = argparse.ArgumentParser(description='runtime parameters')\n",
    "parser.add_argument(\"--bands\", nargs='+' , default=[\"B02\", \"B03\", \"B04\", \"B08\"],\n",
    "                    help=\"bands desired\")\n",
    "\n",
    "parser.add_argument(\"--bands_new\", nargs='+', default=None,\n",
    "                    help=\"additional bands to use beyond original four\")\n",
    "\n",
    "parser.add_argument(\"--chunksize\", type=int, default=1000,\n",
    "                    help=\"Chunksize for output arrays\") \n",
    "\n",
    "parser.add_argument(\"--max_pool_size\", type=int, default=64,\n",
    "                    help=\"Chunksize for output arrays\") \n",
    "\n",
    "parser.add_argument(\"--add_predictions\", action='store_true',\n",
    "                    help=\"Add unet predictions\") \n",
    "                                               \n",
    "parser.add_argument(\"-v\", \"--verbose\", action=\"store_true\",\n",
    "                    help=\"increase output verbosity\")\n",
    "\n",
    "params = vars(parser.parse_args())\n",
    "params['bands_use'] = sorted(params['bands'] + params['bands_new']) if params['bands_new'] is not None else params['bands']\n",
    "\n",
    "params['outsize'] = [512, 512]\n",
    "\n",
    "if params['verbose']: print(\"Parameters are: \", params)\n",
    "    \n",
    "df_meta = pd.read_csv(DATA_DIR / \"train_metadata.csv\")\n",
    "\n",
    "# Shuffle \n",
    "# df_meta = df_meta.sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "    \n",
    "# how many different chip ids, locations, and datetimes are there?\n",
    "print(df_meta[[\"chip_id\", \"location\", \"datetime\"]].nunique())\n",
    "\n",
    "df_meta.head()\n",
    "\n",
    "df_meta = utils.add_paths(df_meta, TRAIN_FEATURES, TRAIN_LABELS, bands=params['bands'])\n",
    "\n",
    "if params['bands_new'] is not None:\n",
    "\n",
    "    # ensure that data exists for any desired new bands beyond the 4 originally provided\n",
    "    for iband, band in enumerate(params['bands_new']):\n",
    "        band_has_data = (TRAIN_FEATURES_NEW / df_meta[\"chip_id\"] / f\"{band}.tif\").map(os.path.isfile)\n",
    "        if iband==0: \n",
    "            has_banddata_on_disk = band_has_data\n",
    "        else:\n",
    "            has_banddata_on_disk = band_has_data & has_banddata_on_disk\n",
    "        \n",
    "        if np.sum(band_has_data) == 0:\n",
    "            print(f\"Band {band} has no data\")\n",
    "    print('Fraction of chips that have new bands on disk = ', has_banddata_on_disk.sum()/has_banddata_on_disk.shape[0])\n",
    "\n",
    "    # Keep only files that have new bands on disk\n",
    "    df_meta = df_meta[has_banddata_on_disk]\n",
    "\n",
    "    df_meta = utils.add_paths(df_meta, TRAIN_FEATURES_NEW, bands=params['bands_new'])\n",
    "        \n",
    "# Total number of chunks. Set as global variable\n",
    "params['nchunks'] = math.ceil(len(df_meta)/params['chunksize'])\n",
    "params['max_pool_size'] = min(params['nchunks'], params['max_pool_size'])\n",
    "\n",
    "def intersection_and_union(pred, true):\n",
    "    \"\"\"                                                                                                         \n",
    "    Calculates intersection and union for a batch of images.                                                    \n",
    "                                                                                                                \n",
    "    Args:                                                                                                       \n",
    "        pred (torch.Tensor): a tensor of predictions                                                            \n",
    "        true (torc.Tensor): a tensor of labels                                                                  \n",
    "                                                                                                                \n",
    "    Returns:                                                                                                    \n",
    "        intersection (int): total intersection of pixels                                                        \n",
    "        union (int): total union of pixels                                                                      \n",
    "    \"\"\"\n",
    "\n",
    "    # Intersection and union totals                                                                             \n",
    "    pred_flattened = pred.flatten()\n",
    "    true_flattened = true.flatten()\n",
    "\n",
    "    intersection = np.logical_and(true_flattened, pred_flattened)/pred_flattened.shape[0]\n",
    "    union = np.logical_or(true_flattened, pred_flattened)/pred_flattened.shape[0]\n",
    "\n",
    "    return float(np.sum(intersection)), float(np.sum(union))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def lat_lon_bounds(filepath: os.PathLike):\n",
    "    \"\"\"Given the path to a GeoTIFF, returns the image bounds in latitude and\n",
    "    longitude coordinates.\n",
    "\n",
    "    Returns points as a tuple of (left, bottom, right, top)\n",
    "    \"\"\"\n",
    "    with rasterio.open(filepath) as im:\n",
    "        bounds = im.bounds\n",
    "        meta = im.meta\n",
    "    # create a converter starting with the current projection\n",
    "    \n",
    "    left, bottom, right, top = rasterio.warp.transform_bounds(\n",
    "        meta[\"crs\"],\n",
    "        4326,  # code for the lat-lon coordinate system\n",
    "        *bounds,\n",
    "    )\n",
    "    \n",
    "    lon = (right+left)/2\n",
    "    dlon = abs(right-left)\n",
    "    \n",
    "    lat = (top+bottom)/2\n",
    "    dlat = abs(top-bottom)\n",
    "     \n",
    "    return lat, lon, dlat, dlon\n",
    "\n",
    "# def lat_long_bounds(chip_path):\n",
    "#     \"\"\"Given the path to a GeoTIFF, returns the image bounds in latitude and\n",
    "#     longitude coordinates.\n",
    "\n",
    "#     Returns points as a tuple of (left, bottom, right, top)\n",
    "#     \"\"\"\n",
    "\n",
    "#     with rasterio.open(chip_path) as chip:\n",
    "\n",
    "#         # create a converter starting with the current projection\n",
    "#         current_crs = pyproj.CRS(chip.meta[\"crs\"])\n",
    "#         crs_transform = pyproj.Transformer.from_crs(current_crs, current_crs.geodetic_crs)\n",
    "\n",
    "#         # returns left, bottom, right, top\n",
    "#         left, bottom, right, top = crs_transform.transform_bounds(*chip.bounds)\n",
    "        \n",
    "#     lon = (right+left)/2\n",
    "#     dlon = abs(right-left)\n",
    "    \n",
    "#     lat = (top+bottom)/2\n",
    "#     dlat = abs(top-bottom)\n",
    "    \n",
    "#     return lat, lon, dlat, dlon\n",
    "\n",
    "def load_image_to_array(chip_id, bands=[\"B02\", \"B03\", \"B04\", \"B08\"],\n",
    "               data_dir=TRAIN_FEATURES, data_dir_new=TRAIN_FEATURES_NEW):\n",
    "    \"\"\"Given the path to the directory of Sentinel-2 chip feature images,\n",
    "    plots the true color image\"\"\"\n",
    "    \n",
    "    original_bands=[\"B02\", \"B03\", \"B04\", \"B08\"]\n",
    "    \n",
    "    npixx = 512\n",
    "    npixy = 512\n",
    "    \n",
    "    # chip_image = np.zeros((len(want_bands), npix[0], npix[1]), dtype=np.uint16)\n",
    "    chip_image = {}\n",
    "\n",
    "    image_array = np.zeros((len(bands), npixx, npixy), dtype=np.float32)\n",
    "    for i, band in enumerate(bands):\n",
    "        if band in original_bands:\n",
    "            chip_dir = data_dir / chip_id\n",
    "        else:\n",
    "            chip_dir = data_dir_new / chip_id\n",
    "\n",
    "        image_array[i] = np.array(io.load_pil_as_nparray(chip_dir / f\"{band}.tif\")).astype(np.float32)\n",
    "  \n",
    "    return image_array\n",
    "\n",
    "\n",
    "# def tif_to_numpy(random_state, nplt=1, figsize=None):\n",
    "    \n",
    "def get_chips_in_npy(ichip_start, ichip_end, bands=[\"B02\", \"B03\", \"B04\", \"B08\"]):\n",
    "\n",
    "    npixx = 512\n",
    "    npixy = 512\n",
    "    nchips = ichip_end-ichip_start\n",
    "    images = np.zeros((nchips, len(bands), npixx, npixy), dtype=np.uint16)\n",
    "    labels = np.zeros((nchips, npixx, npixy), dtype=np.uint8)\n",
    "    \n",
    "    labels_mean = np.zeros(nchips, dtype=np.float32)\n",
    "    \n",
    "    if params['add_predictions']:\n",
    "        preds = np.zeros((nchips, npixx, npixy), dtype=np.uint8)\n",
    "        preds_mean  = np.zeros(nchips, dtype=np.float32)\n",
    "        intersection = np.zeros(nchips, dtype=np.float32)\n",
    "        union = np.zeros(nchips, dtype=np.float32)\n",
    "\n",
    "    chip_ids    = []\n",
    "    chip_lat   = []\n",
    "    chip_lon = []\n",
    "    chip_dlat  = []\n",
    "    chip_dlon    = []\n",
    "    \n",
    "    for ichip, ichip_meta_loc in enumerate(range(ichip_start, ichip_end)):\n",
    "\n",
    "        chip = df_meta.iloc[ichip_meta_loc]\n",
    "        \n",
    "        chip_ids.append(chip.chip_id)\n",
    "        \n",
    "        # get lat lon\n",
    "        lat, lon, dlat, dlon = lat_lon_bounds(chip.B04_path)\n",
    "        chip_lat.append(lat)\n",
    "        chip_lon.append(lon)\n",
    "        chip_dlat.append(dlat)\n",
    "        chip_dlon.append(dlon)\n",
    "        \n",
    "        images[ichip] = load_image_to_array(chip.chip_id, bands=bands)  \n",
    "        labels[ichip] = np.array(Image.open(chip.label_path))\n",
    "        labels_mean[ichip] = np.mean(labels[ichip])\n",
    "\n",
    "        if params['add_predictions']:\n",
    "\n",
    "            preds_i = np.array(Image.open(PREDICTION_DIR/f\"{chip.chip_id}.tif\"))\n",
    "            preds_i = (preds_i > 0.5)*1\n",
    "            preds[ichip] = preds_i.astype(np.int8)\n",
    "\n",
    "            intersection[ichip], union[ichip] = intersection_and_union(preds[ichip], labels[ichip])\n",
    "            preds_mean[ichip] = np.mean(preds[ichip])\n",
    "\n",
    "    d = {}\n",
    "    \n",
    "    d['bands_use'] = params['bands_use']\n",
    "    d['chip_ids'] = chip_ids\n",
    "    d['lat'] =  chip_lat \n",
    "    d['lon'] =  chip_lon\n",
    "    d['dlat'] = chip_dlat \n",
    "    d['dlon'] = chip_dlon\n",
    "\n",
    "    d['images'] = images\n",
    "    d['labels'] = labels\n",
    "    d['labels_mean'] = labels_mean\n",
    "       \n",
    "    # Save bands seperately as well\n",
    "    for iband, band in enumerate(params['bands_use']):\n",
    "        d[f\"{band}\"] = images[:, iband]\n",
    "\n",
    "    if params['add_predictions']:\n",
    "\n",
    "        d['preds'] = preds\n",
    "        d['preds_mean'] = preds_mean\n",
    "\n",
    "        d['intersection'] = intersection\n",
    "        d['union'] = union\n",
    "\n",
    "        d['IoU'] = intersection/union\n",
    "\n",
    "    return d\n",
    "\n",
    "def run_on_chunk(ichunk):\n",
    "    \n",
    "    tstart = time.time()\n",
    "    ichip_start = ichunk*params['chunksize']\n",
    "    ichip_end = min(len(df_meta), (ichunk+1)*params['chunksize'])\n",
    "\n",
    "    print(f\"\\nRunning on chunk {ichunk} out of {params['nchunks']}. Index start:{ichip_start}, index end: {ichip_end}\")\n",
    "\n",
    "    data = get_chips_in_npy(ichip_start, ichip_end, bands=params['bands_use'])\n",
    "\n",
    "    print(\"data, label shape: \", data['images'].shape, data['labels'].shape)\n",
    "\n",
    "    for k, v in data.items():\n",
    "        np.save(DATA_DIR_OUT / f\"{k}_{ichip_start:06d}_{ichip_end:06d}.npy\", v)\n",
    "\n",
    "    print(\"Time elapsed = \", time.time()-tstart)\n",
    "    \n",
    "def main():\n",
    "    \"\"\"\n",
    "    Loop over chunks of size <chunksize> and save individual .tifs in various folders to\n",
    "    single large numpy arrays.\n",
    "    \n",
    "    In order to facilitate faster data/label/prediction investigation\n",
    "    \"\"\"\n",
    "    \n",
    "    if params['max_pool_size'] <= 1:\n",
    "        for i in range(1):#params['nchunks']):\n",
    "            run_on_chunk(i)\n",
    "            \n",
    "    else:\n",
    "        # Simple threading with pool and .map\n",
    "        cpus = multiprocessing.cpu_count()\n",
    "        pool = multiprocessing.Pool(cpus if cpus < params['max_pool_size'] else params['max_pool_size'])\n",
    "        print(f\"Number of available cpus = {cpus}\")\n",
    "\n",
    "        pool.map(run_on_chunk, range(params['nchunks']))\n",
    "\n",
    "        pool.close()\n",
    "        pool.join()\n",
    "    # for ichunk in range(params['nchunks']):\n",
    "    #      run_on_chunk(ichunk)\n",
    "        \n",
    "if __name__=='__main__':\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "092f9dca-de31-47be-956d-83a2f7168701",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "CloudCover",
   "language": "python",
   "name": "cloud_cover"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
