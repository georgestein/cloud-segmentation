{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "24195ab3-3987-4275-8688-f08fc6fc378c",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import os\n",
    "os.environ['OPENBLAS_NUM_THREADS'] = '1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "39761c39-92f0-4b1a-ab9a-b413fbd8bd74",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting ../scripts/pull_additional_chip_data.py\n"
     ]
    }
   ],
   "source": [
    "%%file ../scripts/pull_additional_chip_data.py\n",
    "\"\"\"Pull additional data from Microsoft's Planetary computer\"\"\"\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import skimage.transform as st\n",
    "\n",
    "import rioxarray\n",
    "import rasterio\n",
    "import rioxarray\n",
    "\n",
    "import sys\n",
    "import os\n",
    "import time\n",
    "from PIL import Image\n",
    "from pathlib import Path\n",
    "from pandas_path import path\n",
    "from tqdm import tqdm\n",
    "\n",
    "import multiprocessing\n",
    "import subprocess\n",
    "# from contextlib import redirect_stdout\n",
    "\n",
    "import argparse\n",
    "\n",
    "from cloud_seg.pc_apis import query_bands\n",
    "from cloud_seg.utils import utils\n",
    "\n",
    "label_str = 'train'\n",
    "\n",
    "# locations to various directories\n",
    "DATA_DIR = Path.cwd().parent.resolve() / \"data/\"\n",
    "DATA_DIR_OUT = DATA_DIR / \"cloudless/\"\n",
    "\n",
    "FEATURES = DATA_DIR / \"{:s}_features\".format(label_str)\n",
    "LABELS   = DATA_DIR / \"{:s}_labels\".format(label_str)\n",
    "METADATA = DATA_DIR / \"{:s}_metadata.csv\".format(label_str)\n",
    "\n",
    "### Load params and data at top of script, and not in main(), \n",
    "### as multiprocessing.pool does not like dictionary argments passed to map function\n",
    "\n",
    "# load the provided metadata\n",
    "df = pd.read_csv(METADATA)\n",
    "\n",
    "# add existing bands\n",
    "df = utils.add_paths(df, FEATURES, LABELS)\n",
    "\n",
    "parser = argparse.ArgumentParser(description='runtime parameters')\n",
    "parser.add_argument(\"--max_pool_size\", type=int, default=32,\n",
    "                    help=\"number of pooling threads to use\")\n",
    "\n",
    "parser.add_argument(\"--new_bands\", nargs='+' , default=[\"B02\", \"B03\", \"B04\", \"B08\"],\n",
    "                    help=\"bands desired\")\n",
    "parser.add_argument(\"--new_band_dirs\", nargs='+', default=[],\n",
    "                    help=\"directories to save bands in\")\n",
    "\n",
    "parser.add_argument(\"-v\", \"--verbose\", action=\"store_true\",\n",
    "                    help=\"increase output verbosity\")\n",
    "\n",
    "parser.add_argument(\"--collection\", type=str, default=\"sentinel-2-l2a\",\n",
    "                    help=\"planetary collection to search\")\n",
    "parser.add_argument(\"--query_range_minutes\", type=float, default=60 * 24 * 365 * 5,\n",
    "                    help=\"time range from original chip to query\")\n",
    "\n",
    "parser.add_argument(\"--want_closest\", action=\"store_true\",\n",
    "                    help=\"If true return only return closest chip to query (possibly query chip itself). \\\n",
    "                    Else return closest non-matching chips\")\n",
    "parser.add_argument(\"--max_cloud_cover\", type=float, default=5.0,\n",
    "                    help=\"only return chips with below this cloud cover\")\n",
    "parser.add_argument(\"--max_cloud_shadow_cover\", type=float, default=5.0,\n",
    "                    help=\"only return chips with below this cloud shadow cover\")\n",
    "parser.add_argument(\"--max_item_limit\", type=int, default=5,\n",
    "                    help=\"Maximum number of nearest items to return\")\n",
    "#     parser.add_argument(\"\", type=int, default=,\n",
    "#                         help=\"\")\n",
    "\n",
    "params = vars(parser.parse_args())\n",
    "if params['new_band_dirs'] == []:\n",
    "    # no specific output directories specified, default to band names\n",
    "    params['new_band_dirs'] = params['new_bands']\n",
    "\n",
    "params['DATA_DIR_OUT'] = DATA_DIR_OUT\n",
    "print(params)\n",
    "\n",
    "    \n",
    "class PystacAsset:\n",
    "    def __init__(self, df_chip, parameters: dict):\n",
    "\n",
    "        self.df_chip = df_chip\n",
    "        self.chip_id = df_chip.chip_id\n",
    "        \n",
    "        self.verbose = params.get(\"verbose\", True)\n",
    "        self.collection = params.get(\"collection\", \"sentinel-2-l2a\")\n",
    "        \n",
    "        self.new_bands = params.get(\"new_bands\", [\"B02\", \"B03\", \"B04\", \"B08\"])\n",
    "        self.new_band_dirs = params.get(\"new_band_dirs\", [\"B02\", \"B03\", \"B04\", \"B08\"])\n",
    "        self.DATA_DIR_OUT = params.get(\"DATA_DIR_OUT\", \"data/cloudless_test\")\n",
    "           \n",
    "        self.query_range_minutes = params.get(\"query_range_minutes\", 60 * 24 * 365 * 5)\n",
    "        self.want_closest = params.get(\"want_closest\", False)\n",
    "        self.max_cloud_cover = params.get(\"max_cloud_cover\", 5.0)\n",
    "        self.max_cloud_shadow_cover = params.get(\"max_cloud_shadow_cover\", 5.0)\n",
    "        self.max_item_limit = params.get(\"max_item_limit\", 5)\n",
    "\n",
    "        self.exists_on_disk = self.check_if_bands_on_disk()\n",
    "        \n",
    "    def check_if_bands_on_disk(self):\n",
    "        \"\"\"check if all desired new data already exists for this chip\"\"\"\n",
    "        exists_on_disk = True\n",
    "        for band, band_dir in zip(self.new_bands, self.new_band_dirs):\n",
    "            current_band_dir = os.path.join(self.DATA_DIR_OUT, f\"{self.chip_id}\")\n",
    "\n",
    "            if not os.path.isfile(os.path.join(current_band_dir, f\"{band_dir}.npz\")):\n",
    "                exists_on_disk = False\n",
    "\n",
    "        return exists_on_disk\n",
    "\n",
    "    def resize_images(self, images, interpolation_order=1):\n",
    "        \"\"\"resize all images to size of first in list\"\"\"\n",
    "        image_shapes = np.unique([i.shape for i in images])\n",
    "        image_shape_nearest = images[0].shape\n",
    "        image_dtype = images[0].dtype\n",
    "\n",
    "        if len(image_shapes) > 1:\n",
    "            for i in range(1, len(images)):\n",
    "                images[i] = st.resize(images[i].astype(np.float32), image_shape_nearest, order=interpolation_order)\n",
    "                images[i] = images[i].astype(image_dtype)\n",
    "\n",
    "        return images\n",
    "                \n",
    "    def save_assets_to_disk(self):\n",
    "        \n",
    "        if self.verbose: print('Saving to disk')\n",
    "\n",
    "        for band, band_dir in zip(self.new_bands, self.new_band_dirs):\n",
    "            \n",
    "            if self.want_closest:\n",
    "                band_dir = Path(self.DATA_DIR_OUT / f\"{band_dir}\")\n",
    "                band_image = Image.fromarray(self.assets[band])\n",
    "                # band_image.save(band_dir / f\"{row.chip_id}.tif\")  \n",
    "\n",
    "            else:\n",
    "                band_diri = Path(self.DATA_DIR_OUT / f\"{self.chip_id}\")\n",
    "                Path(band_diri).mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "                self.assets[band] = self.resize_images(self.assets[band])\n",
    "                \n",
    "                print(band_diri / f\"{band_dir}.npz\")\n",
    "                np.savez(\n",
    "                    band_diri / f\"{band_dir}.npz\",\n",
    "                    images=np.stack(self.assets[band], axis=0),\n",
    "                    times=self.assets[band + \"_time\"],\n",
    "                    dtimes=self.assets[band + \"_dtime\"],\n",
    "                    properties=self.assets[band + \"_properties\"],\n",
    "                )\n",
    "                \n",
    "    def get_assets_from_chip(self):\n",
    "\n",
    "        tstart = time.time()\n",
    "\n",
    "        print(f\"\\nFile {self.chip_id} doesn't exist\")\n",
    "\n",
    "        # Load extra bands from PySTAC\n",
    "        self.assets, self.items = query_bands.query_bands(\n",
    "            rasterio.open(self.df_chip.B04_path),\n",
    "            timestamp=self.df_chip.datetime,\n",
    "            asset_keys=self.new_bands,\n",
    "            collection=self.collection,\n",
    "            query_range_minutes=self.query_range_minutes,\n",
    "            verbose=self.verbose,\n",
    "            want_closest=self.want_closest,\n",
    "            max_cloud_cover=self.max_cloud_cover,\n",
    "            max_cloud_shadow_cover=self.max_cloud_shadow_cover,\n",
    "            max_item_limit=self.max_item_limit,\n",
    "        )\n",
    "\n",
    "        if self.verbose: print('Got assets')\n",
    "\n",
    "\n",
    "def download_assets(irow):\n",
    "    tstart = time.time()\n",
    "\n",
    "    row = df.iloc[irow]\n",
    "    \n",
    "    pystac_chip = PystacAsset(row, params)\n",
    "\n",
    "    if not pystac_chip.exists_on_disk:\n",
    "        \n",
    "        pystac_chip.get_assets_from_chip()\n",
    "        \n",
    "        pystac_chip.save_assets_to_disk()\n",
    "\n",
    "    tend = time.time()\n",
    "    if irow % 10 == 0:\n",
    "        print(\"Download time for chip was {:.03f} s\".format(tend-tstart))\n",
    "\n",
    "def main():\n",
    "    # Load params and data at top of script, and not in main(), \n",
    "    # as multiprocessing.pool does not like dictionary argments passed to map function\n",
    "    \n",
    "    cpus = multiprocessing.cpu_count()\n",
    "    pool = multiprocessing.Pool(cpus if cpus < params['max_pool_size'] else params['max_pool_size'])\n",
    "    print(f\"Number of available cpus = {cpus}\")\n",
    "    \n",
    "    pool.map(download_assets, range(len(df)))#.get()\n",
    "        \n",
    "    pool.close()\n",
    "    pool.join()\n",
    "\n",
    "if __name__==\"__main__\":\n",
    "\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "927446b9-1fd9-48f6-bd55-a8fa60c79fdc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "CloudCover",
   "language": "python",
   "name": "cloud_cover"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
